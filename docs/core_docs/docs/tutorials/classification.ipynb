{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cb6f552e-775f-4d84-bc7c-dca94c06a33c",
   "metadata": {},
   "source": [
    "---\n",
    "title: 标签分类\n",
    "sidebar_class_name: hidden\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0507a4b",
   "metadata": {},
   "source": [
    "# 将文本分类为标签\n",
    "\n",
    "标签分类是指使用以下类别对文档进行标注：\n",
    "\n",
    "- 情感\n",
    "- 语言\n",
    "- 风格（正式、非正式等）\n",
    "- 涉及主题\n",
    "- 政治倾向\n",
    "\n",
    "![图像描述](../../static/img/tagging.png)\n",
    "\n",
    "## 概述\n",
    "\n",
    "标签分类包含以下几个组成部分：\n",
    "\n",
    "* `function`：和[提取](/docs/tutorials/extraction)一样，标签分类使用[函数](https://openai.com/blog/function-calling-and-other-api-updates)来指定模型应该如何对文档进行标注\n",
    "* `schema`：定义我们希望如何对文档进行标注\n",
    "\n",
    "## 快速开始\n",
    "\n",
    "让我们来看一个使用工具调用在 LangChain 中进行标签分类的简单示例。我们将使用`.withStructuredOutput()`，该功能支持[选定的聊天模型](/docs/integrations/chat/)。\n",
    "\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4371c8-b1cd-4a61-a474-819204f2a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "// @lc-docs-hide-cell\n",
    "import { ChatOpenAI } from '@langchain/openai';\n",
    "\n",
    "const llm = new ChatOpenAI({\n",
    "  model: \"gpt-4o-mini\",\n",
    "  temperature: 0,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca3f93",
   "metadata": {},
   "source": [
    "让我们使用 [Zod](https://zod.dev) 定义一个包含一些属性及其预期类型的模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f3ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const taggingPrompt = ChatPromptTemplate.fromTemplate(\n",
    "    `从以下段落中提取所需信息。\n",
    "\n",
    "仅提取“分类”函数中提到的属性。\n",
    "\n",
    "段落：\n",
    "{input}\n",
    "`\n",
    ");\n",
    "\n",
    "const classificationSchema = z.object({\n",
    "    sentiment: z.string().describe(\"文本的情感倾向\"),\n",
    "    aggressiveness: z.number().int().describe(\n",
    "        \"文本的攻击性程度，范围从1到10\"\n",
    "    ),\n",
    "    language: z.string().describe(\"文本所使用的语言\"),\n",
    "});\n",
    "\n",
    "// 名称是可选的，但可以给模型提供更多关于你的模式代表什么的线索\n",
    "const llmWihStructuredOutput = llm.withStructuredOutput(classificationSchema, { name: \"extractor\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5509b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'positive', aggressiveness: 1, language: 'Spanish' }\n"
     ]
    }
   ],
   "source": [
    "const prompt1 = await taggingPrompt.invoke({\n",
    "  input: \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "})\n",
    "await llmWihStructuredOutput.invoke(prompt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921bb53",
   "metadata": {},
   "source": [
    "正如我们在示例中看到的，它正确地解释了我们的需求。\n",
    "\n",
    "结果会有所不同，例如我们可能会得到不同语言的情感结果（如'positive'、'enojado'等）。\n",
    "\n",
    "我们将在下一节中了解如何控制这些结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb2f83",
   "metadata": {},
   "source": [
    "## 更精细的控制\n",
    "\n",
    "精心定义的模式使我们能够更好地控制模型的输出。\n",
    "\n",
    "具体来说，我们可以定义：\n",
    "\n",
    "- 每个属性的可能值\n",
    "- 描述以确保模型理解该属性\n",
    "- 需要返回的属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef0b9a",
   "metadata": {},
   "source": [
    "现在我们重新声明我们的 Zod 模式，使用枚举来控制之前提到的每个方面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5f7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const classificationSchema2 = z.object({\n",
    "    sentiment: z.enum([\"happy\", \"neutral\", \"sad\"]).describe(\"文本的情感倾向\"),\n",
    "    aggressiveness: z.number().int().describe(\n",
    "        \"描述语句的攻击性程度，范围从1到5。数值越高越具攻击性\"\n",
    "    ),\n",
    "    language: z.enum([\"spanish\", \"english\", \"french\", \"german\", \"italian\"]).describe(\"文本所使用的语言\"),\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a5881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const taggingPrompt2 = ChatPromptTemplate.fromTemplate(\n",
    "`从以下段落中提取所需信息。\n",
    "\n",
    "仅提取“分类”函数中提到的属性。\n",
    "\n",
    "段落：\n",
    "{input}\n",
    "`\n",
    ")\n",
    "\n",
    "const llmWithStructuredOutput2 = llm.withStructuredOutput(classificationSchema2, { name: \"extractor\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded2332",
   "metadata": {},
   "source": [
    "现在答案将按照我们预期的方式进行限制！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b9d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'happy', aggressiveness: 1, language: 'spanish' }\n"
     ]
    }
   ],
   "source": [
    "const prompt2 = await taggingPrompt2.invoke({\n",
    "  input: \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "})\n",
    "await llmWithStructuredOutput2.invoke(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c12fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'sad', aggressiveness: 5, language: 'spanish' }\n"
     ]
    }
   ],
   "source": [
    "const prompt3 = await taggingPrompt2.invoke({\n",
    "  input: \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "})\n",
    "await llmWithStructuredOutput2.invoke(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdfcb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ sentiment: 'neutral', aggressiveness: 1, language: 'english' }\n"
     ]
    }
   ],
   "source": [
    "const prompt4 = await taggingPrompt2.invoke({\n",
    "  input: \"Weather is ok here, I can go outside without much more than a coat\"\n",
    "})\n",
    "await llmWithStructuredOutput2.invoke(prompt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b7389",
   "metadata": {},
   "source": [
    "通过 [LangSmith 跟踪链接](https://smith.langchain.com/public/455f5404-8784-49ce-8851-0619b99e936f/r)，我们可以查看其内部执行情况：\n",
    "\n",
    "![](../../static/img/classification_ls_trace.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}