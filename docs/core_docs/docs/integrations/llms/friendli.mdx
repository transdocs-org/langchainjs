# Friendli

> [Friendli](https://friendli.ai/) 通过可扩展、高效的部署选项提升 AI 应用性能并优化成本节省，专为高需求的 AI 工作负载而设计。

本教程将指导你将 `Friendli` 与 LangChain 集成。

## 安装配置

确保安装了 `@langchain/community`。

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/community @langchain/core
```

登录 [Friendli Suite](https://suite.friendli.ai/) 创建个人访问令牌，并将其设置为 `FRIENDLI_TOKEN` 环境变量。  
你也可以将团队 ID 设置为 `FRIENDLI_TEAM` 环境变量。

你可以通过选择要使用的模型来初始化 Friendli 的聊天模型。默认模型是 `mixtral-8x7b-instruct-v0-1`。你可以在 [docs.friendli.ai](https://docs.friendli.ai/guides/serverless_endpoints/pricing#text-generation-models) 查看可用模型。

## 使用方法

import CodeBlock from "@theme/CodeBlock";
import Example from "@examples/models/llm/friendli.ts";

<CodeBlock language="typescript">{Example}</CodeBlock>

## 相关内容

- LLM [概念指南](/docs/concepts/text_llms)
- LLM [操作指南](/docs/how_to/#llms)