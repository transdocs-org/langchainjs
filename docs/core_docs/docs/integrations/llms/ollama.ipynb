{
  "cells": [
    {
      "cell_type": "raw",
      "id": "67db2992",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "sidebar_label: Ollama\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9597802c",
      "metadata": {},
      "source": [
        "# Ollama\n",
        "\n",
        "```{=mdx}\n",
        "\n",
        ":::caution\n",
        "您当前所在的页面记录的是如何将 Ollama 模型用作[文本补全模型](/docs/concepts/text_llms)。Ollama 上许多流行的模型是[聊天补全模型](/docs/concepts/chat_models)。\n",
        "\n",
        "您可能需要查看[这个页面](/docs/integrations/chat/ollama/)。\n",
        ":::\n",
        "\n",
        "```\n",
        "\n",
        "这将帮助您使用 LangChain 开始使用 Ollama [文本补全模型 (LLMs)](/docs/concepts/text_llms)。有关 `Ollama` 功能和配置选项的详细文档，请参阅[API 参考](https://api.js.langchain.com/classes/langchain_ollama.Ollama.html)。\n",
        "\n",
        "## 概览\n",
        "### 集成详情\n",
        "\n",
        "[Ollama](https://ollama.ai/) 允许您本地运行开源大语言模型，例如 Llama 3。\n",
        "\n",
        "Ollama 将模型权重、配置和数据打包成一个由 Modelfile 定义的单一包。它优化了包括 GPU 使用在内的设置和配置细节。\n",
        "\n",
        "本示例介绍如何使用 LangChain 与运行中的 Ollama Llama 2 7b 实例进行交互。\n",
        "有关支持的模型及模型变体的完整列表，请参阅 [Ollama 模型库](https://github.com/jmorganca/ollama#model-library)。\n",
        "\n",
        "| 类 | 包 | 本地 | 可序列化 | [Python 支持](https://python.langchain.com/docs/integrations/llms/ollama/) | 包下载量 | 最新包 |\n",
        "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
        "| [`Ollama`](https://api.js.langchain.com/classes/langchain_ollama.Ollama.html) | [`@langchain/ollama`](https://npmjs.com/@langchain/ollama) | ✅ | ❌ | ✅ | ![NPM - 下载量](https://img.shields.io/npm/dm/@langchain/ollama?style=flat-square&label=%20&) | ![NPM - 版本](https://img.shields.io/npm/v/@langchain/ollama?style=flat-square&label=%20&) |\n",
        "\n",
        "## 安装准备\n",
        "\n",
        "要访问 Ollama 嵌入模型，您需要按照 [这些说明](https://github.com/jmorganca/ollama) 安装 Ollama，并安装 `@langchain/ollama` 集成包。\n",
        "\n",
        "### 凭据\n",
        "\n",
        "如果您希望自动追踪您的模型调用，也可以取消下面的注释来设置您的 [LangSmith](https://docs.smith.langchain.com/) API 密钥：\n",
        "\n",
        "```bash\n",
        "# export LANGSMITH_TRACING=\"true\"\n",
        "# export LANGSMITH_API_KEY=\"your-api-key\"\n",
        "```\n",
        "\n",
        "### 安装\n",
        "\n",
        "LangChain Ollama 集成位于 `@langchain/ollama` 包中：\n",
        "\n",
        "```{=mdx}\n",
        "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
        "\n",
        "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/ollama @langchain/core\n",
        "</Npm2Yarn>\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a760037",
      "metadata": {},
      "source": [
        "## 实例化\n",
        "\n",
        "现在我们可以实例化我们的模型对象并生成聊天补全："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a0562a13",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { Ollama } from \"@langchain/ollama\"\n",
        "\n",
        "const llm = new Ollama({\n",
        "  model: \"llama3\", // Default value\n",
        "  temperature: 0,\n",
        "  maxRetries: 2,\n",
        "  // other params...\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee90032",
      "metadata": {},
      "source": [
        "## 调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "035dea0f",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I think you meant to say \"Olivia\" instead of \"Ollama\". Olivia is not a well-known AI company, but there are several other AI companies with similar names. Here are a few examples:\n",
            "\n",
            "* Oliva AI: A startup that uses artificial intelligence to help businesses optimize their operations and improve customer experiences.\n",
            "* Olivia Technologies: A company that develops AI-powered solutions for industries such as healthcare, finance, and education.\n",
            "* Olivia.ai: A platform that uses AI to help businesses automate their workflows and improve productivity.\n",
            "\n",
            "If you meant something else by \"Ollama\", please let me know and I'll do my best to help!\n"
          ]
        }
      ],
      "source": [
        "const inputText = \"Ollama is an AI company that \"\n",
        "\n",
        "const completion = await llm.invoke(inputText)\n",
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add38532",
      "metadata": {},
      "source": [
        "## 链式调用\n",
        "\n",
        "我们可以将补全模型与提示模板以如下方式进行[链式调用](/docs/how_to/sequence/)："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "078e9db2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A programmer's passion!\n",
            "\n",
            "In German, you can express your love for programming with the following phrases:\n",
            "\n",
            "1. Ich liebe Programmieren: This is a direct translation of \"I love programming.\"\n",
            "2. Programmieren ist meine Leidenschaft: This means \"Programming is my passion.\"\n",
            "3. Ich bin total verliebt in Programmieren: This translates to \"I'm totally in love with programming.\"\n",
            "4. Programmieren macht mich glücklich: This phrase means \"Programming makes me happy\" or \"I'm joyful when programming.\"\n",
            "\n",
            "If you want to be more casual, you can use:\n",
            "\n",
            "1. Ich bin ein Programmier-Fan: This is a playful way to say \"I'm a fan of programming.\"\n",
            "2. Programmieren ist mein Ding: This translates to \"Programming is my thing\" or \"I'm all about programming.\"\n",
            "\n",
            "Remember that German has different forms for formal and informal speech, so adjust the phrases according to your relationship with the person you're speaking to!\n"
          ]
        }
      ],
      "source": [
        "import { PromptTemplate } from \"@langchain/core/prompts\"\n",
        "\n",
        "const prompt = PromptTemplate.fromTemplate(\"How to say {input} in {output_language}:\\n\")\n",
        "\n",
        "const chain = prompt.pipe(llm);\n",
        "await chain.invoke(\n",
        "  {\n",
        "    output_language: \"German\",\n",
        "    input: \"I love programming.\",\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99eef30",
      "metadata": {},
      "source": [
        "## 多模态模型\n",
        "\n",
        "Ollama 支持开源的多模态模型，例如 [LLaVA](https://ollama.ai/library/llava)，适用于 0.1.15 及以上版本。\n",
        "你可以将经过 base64 编码的图像数据绑定到具备多模态能力的模型中，作为上下文使用，示例如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ff218e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The image shows a hot dog placed inside what appears to be a bun that has been specially prepared to resemble a hot dog bun. This is an example of a creative or novelty food item, where the bread used for the bun looks similar to a cooked hot dog itself, playing on the name \"hot dog.\" The image also shows the typical garnishes like ketchup and mustard on the side. \n"
          ]
        }
      ],
      "source": [
        "import { Ollama } from \"@langchain/ollama\";\n",
        "import * as fs from \"node:fs/promises\";\n",
        "\n",
        "const imageData = await fs.readFile(\"../../../../../examples/hotdog.jpg\");\n",
        "\n",
        "const model = new Ollama({\n",
        "  model: \"llava\",\n",
        "}).bind({\n",
        "  images: [imageData.toString(\"base64\")],\n",
        "});\n",
        "\n",
        "const res = await model.invoke(\"What's in this image?\");\n",
        "console.log(res);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cac0a2dd",
      "metadata": {},
      "source": [
        "## 相关内容\n",
        "\n",
        "- 大型语言模型 [概念指南](/docs/concepts/text_llms)\n",
        "- 大型语言模型 [操作指南](/docs/how_to/#llms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bdfcef",
      "metadata": {},
      "source": [
        "## API 参考文档\n",
        "\n",
        "如需了解所有 `Ollama` 特性和配置的详细文档，请访问 [API 参考页面](https://api.js.langchain.com/classes/langchain_ollama.Ollama.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "e971737741ff4ec9aff7dc6155a1060a59a8a6d52c757dbbe66bf8ee389494b1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}