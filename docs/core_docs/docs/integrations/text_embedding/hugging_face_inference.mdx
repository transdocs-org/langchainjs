# HuggingFace 推理

此嵌入集成默认使用 `BAAI/bge-base-en-v1.5` 模型，通过 HuggingFace 推理 API 为给定文本生成嵌入。你也可以向构造函数传递不同的模型名称来使用其他模型。

## 安装设置

首先你需要安装 [`@langchain/community`](https://www.npmjs.com/package/@langchain/community) 包以及所需的对等依赖项：

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/community @langchain/core @huggingface/inference@4
```

## 使用方法

```typescript
import { HuggingFaceInferenceEmbeddings } from "@langchain/community/embeddings/hf";

const embeddings = new HuggingFaceInferenceEmbeddings({
  apiKey: "YOUR-API-KEY", // 默认取自 process.env.HUGGINGFACEHUB_API_KEY
  model: "MODEL-NAME", // 如果未提供，默认使用 `BAAI/bge-base-en-v1.5`
  provider: "MODEL-PROVIDER", // 如果未提供，默认使用 Hugging Face 推理 API 内部的自动选择机制
});
```

> **注意：**  
> 如果你不提供 `model`，将会记录一条警告信息，并使用默认模型 `BAAI/bge-base-en-v1.5`。
> 如果你不提供 `provider`，Hugging Face 将默认使用 `auto` 选择机制，根据你在 [https://hf.co/settings/inference-providers](https://hf.co/settings/inference-providers) 的设置为模型选择第一个可用的提供商。

> **提示：**  
> `hf-inference` 是 Hugging Face 直接托管模型的提供商名称。

## 相关内容

- 嵌入模型 [概念指南](/docs/concepts/embedding_models)
- 嵌入模型 [操作指南](/docs/how_to/#embedding-models)