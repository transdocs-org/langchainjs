{
  "cells": [
    {
      "cell_type": "raw",
      "id": "afaf8039",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "sidebar_label: Pinecone\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49f1e0d",
      "metadata": {},
      "source": [
        "# Pinecone\n",
        "\n",
        "本指南将帮助您开始使用由[Pinecone向量存储](/docs/integrations/vectorstores/pinecone)支持的检索器。如需了解所有功能和配置的详细文档，请前往[API参考](https://api.js.langchain.com/classes/langchain.retrievers_self_query.SelfQueryRetriever.html)。\n",
        "\n",
        "## 概述\n",
        "\n",
        "[自查询检索器](/docs/how_to/self_query/)通过根据输入查询动态生成元数据过滤器来检索文档。这允许检索器在获取结果时不仅考虑纯语义相似性，还考虑底层文档元数据。\n",
        "\n",
        "它使用一个名为`Translator`的模块，该模块根据有关元数据字段和特定向量存储支持的查询语言生成过滤器。\n",
        "\n",
        "### 集成详情\n",
        "\n",
        "| 底层向量存储 | 自托管 | 云服务 | 包 | [Python支持](https://python.langchain.com/docs/integrations/retrievers/self_query/pinecone/) |\n",
        "| :--- | :--- | :---: | :---: | :---: |\n",
        "[`PineconeStore`](https://api.js.langchain.com/classes/langchain_pinecone.PineconeStore.html) | ❌ | ✅ | [`@langchain/pinecone`](https://www.npmjs.com/package/@langchain/pinecone) | ✅ |\n",
        "\n",
        "## 安装与配置\n",
        "\n",
        "按照[此处](/docs/integrations/vectorstores/pinecone)所述设置一个Pinecone实例。请设置以下环境变量：\n",
        "\n",
        "```ts\n",
        "process.env.PINECONE_API_KEY = \"YOUR_API_KEY\";\n",
        "process.env.PINECONE_ENVIRONMENT = \"YOUR_ENVIRONMENT\";\n",
        "process.env.PINECONE_INDEX = \"YOUR_INDEX\";\n",
        "```\n",
        "\n",
        "如果您希望从单个查询中获得自动跟踪，也可以取消下面的注释来设置您的[LangSmith](https://docs.smith.langchain.com/) API密钥：\n",
        "\n",
        "```typescript\n",
        "// process.env.LANGSMITH_API_KEY = \"<YOUR API KEY HERE>\";\n",
        "// process.env.LANGSMITH_TRACING = \"true\";\n",
        "```\n",
        "\n",
        "### 安装\n",
        "\n",
        "向量存储位于`@langchain/pinecone`包中。您还需要安装`langchain`包以导入主要的`SelfQueryRetriever`类。\n",
        "\n",
        "此外，您还需要安装官方的Pinecone SDK（`@pinecone-database/pinecone@5`）。\n",
        "\n",
        "在本示例中，我们还将使用OpenAI嵌入，因此您需要安装`@langchain/openai`包并[获取API密钥](https://platform.openai.com)：\n",
        "\n",
        "```{=mdx}\n",
        "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
        "\n",
        "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/pinecone langchain @langchain/openai @langchain/core @pinecone-database/pinecone\n",
        "</Npm2Yarn>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38cde65-254d-4219-a441-068766c0d4b5",
      "metadata": {},
      "source": [
        "## 实例化\n",
        "\n",
        "首先，用一些包含元数据的文档初始化你的Pinecone向量存储："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e7fd15a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { Pinecone } from \"@pinecone-database/pinecone\";\n",
        "\n",
        "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
        "import { PineconeStore } from \"@langchain/pinecone\";\n",
        "import { Document } from \"@langchain/core/documents\";\n",
        "import type { AttributeInfo } from \"langchain/chains/query_constructor\";\n",
        "\n",
        "/**\n",
        " * First, we create a bunch of documents. You can load your own documents here instead.\n",
        " * Each document has a pageContent and a metadata field. Make sure your metadata matches the AttributeInfo below.\n",
        " */\n",
        "const docs = [\n",
        "  new Document({\n",
        "    pageContent:\n",
        "      \"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "    metadata: { year: 1993, rating: 7.7, genre: \"science fiction\" },\n",
        "  }),\n",
        "  new Document({\n",
        "    pageContent:\n",
        "      \"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "    metadata: { year: 2010, director: \"Christopher Nolan\", rating: 8.2 },\n",
        "  }),\n",
        "  new Document({\n",
        "    pageContent:\n",
        "      \"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "    metadata: { year: 2006, director: \"Satoshi Kon\", rating: 8.6 },\n",
        "  }),\n",
        "  new Document({\n",
        "    pageContent:\n",
        "      \"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "    metadata: { year: 2019, director: \"Greta Gerwig\", rating: 8.3 },\n",
        "  }),\n",
        "  new Document({\n",
        "    pageContent: \"Toys come alive and have a blast doing so\",\n",
        "    metadata: { year: 1995, genre: \"animated\" },\n",
        "  }),\n",
        "  new Document({\n",
        "    pageContent: \"Three men walk into the Zone, three men walk out of the Zone\",\n",
        "    metadata: {\n",
        "      year: 1979,\n",
        "      director: \"Andrei Tarkovsky\",\n",
        "      genre: \"science fiction\",\n",
        "      rating: 9.9,\n",
        "    },\n",
        "  }),\n",
        "];\n",
        "\n",
        "/**\n",
        " * Next, we define the attributes we want to be able to query on.\n",
        " * in this case, we want to be able to query on the genre, year, director, rating, and length of the movie.\n",
        " * We also provide a description of each attribute and the type of the attribute.\n",
        " * This is used to generate the query prompts.\n",
        " */\n",
        "const attributeInfo: AttributeInfo[] = [\n",
        "  {\n",
        "    name: \"genre\",\n",
        "    description: \"The genre of the movie\",\n",
        "    type: \"string or array of strings\",\n",
        "  },\n",
        "  {\n",
        "    name: \"year\",\n",
        "    description: \"The year the movie was released\",\n",
        "    type: \"number\",\n",
        "  },\n",
        "  {\n",
        "    name: \"director\",\n",
        "    description: \"The director of the movie\",\n",
        "    type: \"string\",\n",
        "  },\n",
        "  {\n",
        "    name: \"rating\",\n",
        "    description: \"The rating of the movie (1-10)\",\n",
        "    type: \"number\",\n",
        "  },\n",
        "  {\n",
        "    name: \"length\",\n",
        "    description: \"The length of the movie in minutes\",\n",
        "    type: \"number\",\n",
        "  },\n",
        "];\n",
        "\n",
        "/**\n",
        " * Next, we instantiate a vector store. This is where we store the embeddings of the documents.\n",
        " * We also need to provide an embeddings object. This is used to embed the documents.\n",
        " */\n",
        "\n",
        "const pinecone = new Pinecone();\n",
        "\n",
        "const pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);\n",
        "\n",
        "const embeddings = new OpenAIEmbeddings();\n",
        "const vectorStore = await PineconeStore.fromDocuments(docs, embeddings, {\n",
        "  pineconeIndex: pineconeIndex,\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f321c7bd",
      "metadata": {},
      "source": [
        "现在我们可以实例化我们的检索器：\n",
        "\n",
        "```{=mdx}\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"llm\" />\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "821ea7a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "// @lc-docs-hide-cell\n",
        "\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const llm = new ChatOpenAI({\n",
        "  model: \"gpt-4o\",\n",
        "  temperature: 0,\n",
        "});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "70cc8e65-2a02-408a-bbc6-8ef649057d82",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { SelfQueryRetriever } from \"langchain/retrievers/self_query\";\n",
        "import { PineconeTranslator } from \"@langchain/pinecone\";\n",
        "\n",
        "const selfQueryRetriever = SelfQueryRetriever.fromLLM({\n",
        "  llm: llm,\n",
        "  vectorStore: vectorStore,\n",
        "  /** A short summary of what the document contents represent. */\n",
        "  documentContents: \"Brief summary of a movie\",\n",
        "  attributeInfo: attributeInfo,\n",
        "  /**\n",
        "   * We need to create a basic translator that translates the queries into a\n",
        "   * filter format that the vector store can understand. We provide a basic translator\n",
        "   * translator here, but you can create your own translator by extending BaseTranslator\n",
        "   * abstract class. Note that the vector store needs to support filtering on the metadata\n",
        "   * attributes you want to query on.\n",
        "   */\n",
        "  structuredQueryTranslator: new PineconeTranslator(),\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5f2839-4020-424e-9fc9-07777eede442",
      "metadata": {},
      "source": [
        "## 使用方法\n",
        "\n",
        "现在，提出一个需要了解文档元数据才能回答的问题。你可以看到检索器将生成正确的结果："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "51a60dbe-9f2e-4e04-bb62-23968f17164a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  Document {\n",
            "    pageContent: 'A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea',\n",
            "    metadata: { director: 'Satoshi Kon', rating: 8.6, year: 2006 },\n",
            "    id: undefined\n",
            "  },\n",
            "  Document {\n",
            "    pageContent: 'Three men walk into the Zone, three men walk out of the Zone',\n",
            "    metadata: {\n",
            "      director: 'Andrei Tarkovsky',\n",
            "      genre: 'science fiction',\n",
            "      rating: 9.9,\n",
            "      year: 1979\n",
            "    },\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "await selfQueryRetriever.invoke(\n",
        "  \"Which movies are rated higher than 8.5?\"\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe8aad4-8626-4330-98a9-7ea1ca5d2e0e",
      "metadata": {},
      "source": [
        "## 在链式应用中的使用\n",
        "\n",
        "与其他检索器一样，Pinecone 自查询检索器可以通过[链式应用](/docs/how_to/sequence/)集成到LLM应用程序中。\n",
        "\n",
        "请注意，由于其返回的答案可能在很大程度上依赖于文档的元数据，我们以不同的格式返回检索到的文档，以便包含这些信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "23e11cc9-abd6-4855-a7eb-799f45ca01ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "import { RunnablePassthrough, RunnableSequence } from \"@langchain/core/runnables\";\n",
        "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
        "\n",
        "import type { Document } from \"@langchain/core/documents\";\n",
        "\n",
        "const prompt = ChatPromptTemplate.fromTemplate(`\n",
        "Answer the question based only on the context provided.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}`);\n",
        "\n",
        "const formatDocs = (docs: Document[]) => {\n",
        "  return docs.map((doc) => JSON.stringify(doc)).join(\"\\n\\n\");\n",
        "}\n",
        "\n",
        "// See https://js.langchain.com/docs/tutorials/rag\n",
        "const ragChain = RunnableSequence.from([\n",
        "  {\n",
        "    context: selfQueryRetriever.pipe(formatDocs),\n",
        "    question: new RunnablePassthrough(),\n",
        "  },\n",
        "  prompt,\n",
        "  llm,\n",
        "  new StringOutputParser(),\n",
        "]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d47c37dd-5c11-416c-a3b6-bec413cd70e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The movies rated higher than 8.5 are the ones directed by Satoshi Kon (rating: 8.6) and Andrei Tarkovsky (rating: 9.9).\n"
          ]
        }
      ],
      "source": [
        "await ragChain.invoke(\"Which movies are rated higher than 8.5?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52ef888",
      "metadata": {},
      "source": [
        "## 默认搜索参数\n",
        "\n",
        "你还可以在上述方法中传入一个 `searchParams` 字段，该字段提供默认的过滤器，这些过滤器将与任何生成的查询一并应用。过滤器的语法与底层 Pinecone 向量存储相同："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f6103afe",
      "metadata": {},
      "outputs": [],
      "source": [
        "const selfQueryRetrieverWithDefaultParams = SelfQueryRetriever.fromLLM({\n",
        "  llm: llm,\n",
        "  vectorStore: vectorStore,\n",
        "  documentContents: \"Brief summary of a movie\",\n",
        "  attributeInfo: attributeInfo,\n",
        "  structuredQueryTranslator: new PineconeTranslator(),\n",
        "  searchParams: {\n",
        "    filter: {\n",
        "      rating: {\n",
        "        $gt: 8.5,\n",
        "      },\n",
        "    },\n",
        "    mergeFiltersOperator: \"and\",\n",
        "  },\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "## API 参考文档\n",
        "\n",
        "如需详细了解所有 Pinecone 自查询检索器的功能和配置，请访问 [API 参考文档](https://api.js.langchain.com/classes/langchain.retrievers_self_query.SelfQueryRetriever.html)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}