{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e161a8a-fcf0-4d55-933e-da271ce28d7e",
      "metadata": {},
      "source": [
        "# 如何处理长文本\n",
        "\n",
        ":::info 预备知识\n",
        "\n",
        "本指南假定您熟悉以下内容：\n",
        "\n",
        "- [抽取](/docs/tutorials/extraction)\n",
        "\n",
        ":::\n",
        "\n",
        "在处理文件（如PDF）时，您很可能会遇到超出语言模型上下文窗口的文本。为了处理这些文本，可以考虑以下策略：\n",
        "\n",
        "1. **更换LLM** 选择一个支持更大上下文窗口的LLM。\n",
        "2. **暴力方法** 将文档分块，并从每个块中抽取内容。\n",
        "3. **RAG** 将文档分块，对块进行索引，并仅从看起来“相关”的一部分块中抽取内容。\n",
        "\n",
        "请注意，这些策略各有不同的权衡，最佳策略可能取决于您正在设计的应用程序！"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57969139-ad0a-487e-97d8-cb30e2af9742",
      "metadata": {},
      "source": [
        "## 设置\n",
        "\n",
        "首先，让我们安装一些必需的依赖项：\n",
        "\n",
        "```{=mdx}\n",
        "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
        "\n",
        "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/openai @langchain/core zod cheerio\n",
        "</Npm2Yarn>\n",
        "```\n",
        "\n",
        "接下来，我们需要一些示例数据！让我们下载一篇关于[维基百科上的汽车](https://en.wikipedia.org/wiki/Car)的文章，并将其加载为 LangChain 的 `Document`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "571aad22-2cec-4b9b-b656-5e4b81a1ec6c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[33m97336\u001b[39m"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\n",
        "// Only required in a Deno notebook environment to load the peer dep.\n",
        "import \"cheerio\";\n",
        "\n",
        "const loader = new CheerioWebBaseLoader(\n",
        "  \"https://en.wikipedia.org/wiki/Car\"\n",
        ");\n",
        "\n",
        "const docs = await loader.load();\n",
        "\n",
        "docs[0].pageContent.length;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3ffb8d-587a-4370-886a-e56e617bcb9c",
      "metadata": {},
      "source": [
        "## 定义模式\n",
        "\n",
        "在此，我们将定义一个模式，用于从文本中提取关键发展信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a3b288ed-87a6-4af0-aac8-20921dc370d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { z } from \"zod\";\n",
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const keyDevelopmentSchema = z.object({\n",
        "  year: z.number().describe(\"The year when there was an important historic development.\"),\n",
        "  description: z.string().describe(\"What happened in this year? What was the development?\"),\n",
        "  evidence: z.string().describe(\"Repeat verbatim the sentence(s) from which the year and description information were extracted\"),\n",
        "}).describe(\"Information about a development in the history of cars.\");\n",
        "\n",
        "const extractionDataSchema = z.object({\n",
        "  key_developments: z.array(keyDevelopmentSchema),\n",
        "}).describe(\"Extracted information about key developments in the history of cars\");\n",
        "\n",
        "const SYSTEM_PROMPT_TEMPLATE = [\n",
        "  \"You are an expert at identifying key historic development in text.\",\n",
        "  \"Only extract important historic developments. Extract nothing if no important information can be found in the text.\"\n",
        "].join(\"\\n\");\n",
        "\n",
        "// Define a custom prompt to provide instructions and any additional context.\n",
        "// 1) You can add examples into the prompt template to improve extraction quality\n",
        "// 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
        "//    about the document from which the text was extracted.)\n",
        "const prompt = ChatPromptTemplate.fromMessages([\n",
        "  [\n",
        "    \"system\",\n",
        "    SYSTEM_PROMPT_TEMPLATE,\n",
        "  ],\n",
        "  // Keep on reading through this use case to see how to use examples to improve performance\n",
        "  // MessagesPlaceholder('examples'),\n",
        "  [\"human\", \"{text}\"],\n",
        "]);\n",
        "\n",
        "// We will be using tool calling mode, which\n",
        "// requires a tool calling capable model.\n",
        "const llm = new ChatOpenAI({\n",
        "  model: \"gpt-4-0125-preview\",\n",
        "  temperature: 0,\n",
        "});\n",
        "\n",
        "const extractionChain = prompt.pipe(llm.withStructuredOutput(extractionDataSchema));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13aebafb-26b5-42b2-ae8e-9c05cd56e5c5",
      "metadata": {},
      "source": [
        "## 暴力方法\n",
        "\n",
        "将文档拆分为多个块，使每个块都适合LLM的上下文窗口。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "27b8a373-14b3-45ea-8bf5-9749122ad927",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { TokenTextSplitter } from \"langchain/text_splitter\";\n",
        "\n",
        "const textSplitter = new TokenTextSplitter({\n",
        "  chunkSize: 2000,\n",
        "  chunkOverlap: 20,\n",
        "});\n",
        "\n",
        "// Note that this method takes an array of docs\n",
        "const splitDocs = await textSplitter.splitDocuments(docs);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b43d7e0-3c85-4d97-86c7-e8c984b60b0a",
      "metadata": {},
      "source": [
        "对所有可运行对象上的 `.batch` 方法进行使用，以在每个块上**并行**运行提取操作！\n",
        "\n",
        ":::{.callout-tip}\n",
        "通常可以使用 `.batch()` 来并行化提取操作！\n",
        "\n",
        "如果模型是通过 API 暴露的，则这可能会加快提取流程。\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ba766b5-8d6c-48e6-8d69-f391a66b65d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Limit just to the first 3 chunks\n",
        "// so the code can be re-run quickly\n",
        "const firstFewTexts = splitDocs.slice(0, 3).map((doc) => doc.pageContent);\n",
        "\n",
        "const extractionChainParams = firstFewTexts.map((text) => {\n",
        "  return { text };\n",
        "});\n",
        "\n",
        "const results = await extractionChain.batch(extractionChainParams, { maxConcurrency: 5 });"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67da8904-e927-406b-a439-2a16f6087ccf",
      "metadata": {},
      "source": [
        "### 合并结果\n",
        "\n",
        "从各个数据块中提取数据后，我们需要将这些提取结果合并在一起。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "30b35897-4d94-44ad-80c6-446eff61b76b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\n",
              "  { year: \u001b[33m0\u001b[39m, description: \u001b[32m\"\"\u001b[39m, evidence: \u001b[32m\"\"\u001b[39m },\n",
              "  {\n",
              "    year: \u001b[33m1769\u001b[39m,\n",
              "    description: \u001b[32m\"French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle.\"\u001b[39m,\n",
              "    evidence: \u001b[32m\"French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769.\"\u001b[39m\n",
              "  },\n",
              "  {\n",
              "    year: \u001b[33m1808\u001b[39m,\n",
              "    description: \u001b[32m\"French-born Swiss inventor François Isaac de Rivaz designed and constructed the first internal combu\"\u001b[39m... 25 more characters,\n",
              "    evidence: \u001b[32m\"French-born Swiss inventor François Isaac de Rivaz designed and constructed the first internal combu\"\u001b[39m... 33 more characters\n",
              "  },\n",
              "  {\n",
              "    year: \u001b[33m1886\u001b[39m,\n",
              "    description: \u001b[32m\"German inventor Carl Benz patented his Benz Patent-Motorwagen, inventing the modern car—a practical,\"\u001b[39m... 40 more characters,\n",
              "    evidence: \u001b[32m\"The modern car—a practical, marketable automobile for everyday use—was invented in 1886, when German\"\u001b[39m... 56 more characters\n",
              "  },\n",
              "  {\n",
              "    year: \u001b[33m1908\u001b[39m,\n",
              "    description: \u001b[32m\"The 1908 Model T, an American car manufactured by the Ford Motor Company, became one of the first ca\"\u001b[39m... 28 more characters,\n",
              "    evidence: \u001b[32m\"One of the first cars affordable by the masses was the 1908 Model T, an American car manufactured by\"\u001b[39m... 24 more characters\n",
              "  }\n",
              "]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "const keyDevelopments = results.flatMap((result) => result.key_developments);\n",
        "\n",
        "keyDevelopments.slice(0, 20);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48afd4a7-abcd-48b4-8ff1-6ca485f529e3",
      "metadata": {},
      "source": [
        "## 基于RAG的方法\n",
        "\n",
        "另一个简单的思路是将文本分块，但与从每个文本块中提取信息不同，我们只需关注最相关的文本块。\n",
        "\n",
        ":::{.callout-caution}\n",
        "识别哪些文本块是相关的可能会有难度。\n",
        "\n",
        "例如，在我们此处使用的`car`文章中，大部分文章内容都包含关键的发展信息。因此，通过使用\n",
        "**RAG**，我们可能会遗漏大量相关信息。\n",
        "\n",
        "我们建议您对自己的使用场景进行实验，以确定这种方法是否有效。\n",
        ":::\n",
        "\n",
        "下面是一个简单示例，该示例依赖于内存中的演示 `MemoryVectorStore` 向量存储。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aaf37c82-625b-4fa1-8e88-73303f08ac16",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
        "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
        "\n",
        "// Only load the first 10 docs for speed in this demo use-case\n",
        "const vectorstore = await MemoryVectorStore.fromDocuments(\n",
        "  splitDocs.slice(0, 10),\n",
        "  new OpenAIEmbeddings()\n",
        ");\n",
        "\n",
        "// Only extract from top document\n",
        "const retriever = vectorstore.asRetriever({ k: 1 });"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "013ecad9-f80f-477c-b954-494b46a02a07",
      "metadata": {},
      "source": [
        "在这种情况下，RAG提取器仅查看最相关的文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "47aad00b-7013-4f7f-a1b0-02ef269093bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { RunnableSequence } from \"@langchain/core/runnables\";\n",
        "\n",
        "const ragExtractor = RunnableSequence.from([\n",
        "  {\n",
        "    text: retriever.pipe((docs) => docs[0].pageContent)\n",
        "  },\n",
        "  extractionChain,\n",
        "]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "68f2de01-0cd8-456e-a959-db236189d41b",
      "metadata": {},
      "outputs": [],
      "source": [
        "const ragExtractorResults = await ragExtractor.invoke(\"Key developments associated with cars\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "56f434ea-1869-4192-914e-3ccf64e72f75",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\n",
              "  {\n",
              "    year: \u001b[33m2020\u001b[39m,\n",
              "    description: \u001b[32m\"The lifetime of a car built in the 2020s is expected to be about 16 years, or about 2 million km (1.\"\u001b[39m... 33 more characters,\n",
              "    evidence: \u001b[32m\"The lifetime of a car built in the 2020s is expected to be about 16 years, or about 2 millionkm (1.2\"\u001b[39m... 31 more characters\n",
              "  },\n",
              "  {\n",
              "    year: \u001b[33m2030\u001b[39m,\n",
              "    description: \u001b[32m\"All fossil fuel vehicles will be banned in Amsterdam from 2030.\"\u001b[39m,\n",
              "    evidence: \u001b[32m\"all fossil fuel vehicles will be banned in Amsterdam from 2030.\"\u001b[39m\n",
              "  },\n",
              "  {\n",
              "    year: \u001b[33m2020\u001b[39m,\n",
              "    description: \u001b[32m\"In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year.\"\u001b[39m,\n",
              "    evidence: \u001b[32m\"In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year.\"\u001b[39m\n",
              "  }\n",
              "]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ragExtractorResults.key_developments;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf36e626-cf5d-4324-ba29-9bd602be9b97",
      "metadata": {},
      "source": [
        "## 常见问题\n",
        "\n",
        "不同的方法在成本、速度和准确性方面各有优缺点。\n",
        "\n",
        "请注意以下问题：\n",
        "\n",
        "* 内容分块意味着如果信息分布在多个块中，LLM可能无法提取信息。\n",
        "* 过大的块重叠可能导致相同信息被提取两次，因此要做好去重准备！\n",
        "* LLM可能会生成虚假数据。如果在大段文本中查找单一事实并使用暴力方法，最终可能会得到更多伪造的数据。\n",
        "\n",
        "## 下一步\n",
        "\n",
        "现在你已经了解了如何通过少量示例提升信息提取质量。\n",
        "\n",
        "接下来，请查看本节中其他指南，例如[一些通过示例提升信息提取质量的技巧](/docs/how_to/extraction_examples)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nb_converter": "script",
      "pygments_lexer": "typescript",
      "version": "5.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}