{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2195672-0cab-4967-ba8a-c6544635547d",
      "metadata": {},
      "source": [
        "# 如何处理多个检索器\n",
        "\n",
        ":::info 预备知识\n",
        "\n",
        "本指南假定您熟悉以下内容：\n",
        "\n",
        "- [查询分析](/docs/tutorials/rag#query-analysis)\n",
        "\n",
        ":::\n",
        "\n",
        "有时，查询分析技术可能会允许选择使用哪个检索器。要使用此功能，您需要添加一些逻辑来选择要使用的检索器。我们将展示一个简单的示例（使用模拟数据），说明如何实现这一点。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4079b57-4369-49c9-b2ad-c809b5408d7e",
      "metadata": {},
      "source": [
        "## 安裝\n",
        "\n",
        "### 安裝依賴項\n",
        "\n",
        "```{=mdx}\n",
        "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
        "\n",
        "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/community @langchain/openai @langchain/core zod chromadb\n",
        "</Npm2Yarn>\n",
        "```\n",
        "\n",
        "### 設定環境變數\n",
        "\n",
        "```\n",
        "OPENAI_API_KEY=your-api-key\n",
        "\n",
        "# 選用，使用 LangSmith 以獲得最佳的可觀測性\n",
        "LANGSMITH_API_KEY=your-api-key\n",
        "LANGSMITH_TRACING=true\n",
        "\n",
        "# 如果你不在無伺服器環境中，可減少追蹤延遲\n",
        "# LANGCHAIN_CALLBACKS_BACKGROUND=true\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c20b48b8-16d7-4089-bc17-f2d240b3935a",
      "metadata": {},
      "source": [
        "### 创建索引\n",
        "\n",
        "我们将在虚假信息上创建一个向量存储。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f621694",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { Chroma } from \"@langchain/community/vectorstores/chroma\"\n",
        "import { OpenAIEmbeddings } from \"@langchain/openai\"\n",
        "import \"chromadb\";\n",
        "\n",
        "const texts = [\"Harrison worked at Kensho\"]\n",
        "const embeddings = new OpenAIEmbeddings({ model: \"text-embedding-3-small\" })\n",
        "const vectorstore = await Chroma.fromTexts(texts, {}, embeddings, {\n",
        "  collectionName: \"harrison\"\n",
        "})\n",
        "const retrieverHarrison = vectorstore.asRetriever(1)\n",
        "\n",
        "const textsAnkush = [\"Ankush worked at Facebook\"]\n",
        "const embeddingsAnkush = new OpenAIEmbeddings({ model: \"text-embedding-3-small\" })\n",
        "const vectorstoreAnkush = await Chroma.fromTexts(textsAnkush, {}, embeddingsAnkush, {\n",
        "  collectionName: \"ankush\"\n",
        "})\n",
        "const retrieverAnkush = vectorstoreAnkush.asRetriever(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57396e23-c192-4d97-846b-5eacea4d6b8d",
      "metadata": {},
      "source": [
        "## 查询分析\n",
        "\n",
        "我们将使用函数调用来结构化输出。我们会让其返回多个查询。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0b51dd76-820d-41a4-98c8-893f6fe0d1ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { z } from \"zod\";\n",
        "\n",
        "const searchSchema = z.object({\n",
        "    query: z.string().describe(\"Query to look up\"),\n",
        "    person: z.string().describe(\"Person to look things up for. Should be `HARRISON` or `ANKUSH`.\")\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c79210",
      "metadata": {},
      "source": [
        "```{=mdx}\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"llm\" />\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678a1ed0",
      "metadata": {},
      "outputs": [],
      "source": [
        "// @lc-docs-hide-cell\n",
        "import { ChatOpenAI } from '@langchain/openai';\n",
        "\n",
        "const llm = new ChatOpenAI({\n",
        "  model: \"gpt-4o\",\n",
        "  temperature: 0,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "783c03c3-8c72-4f88-9cf4-5829ce6745d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "import { RunnableSequence, RunnablePassthrough } from \"@langchain/core/runnables\";\n",
        "\n",
        "const system = `You have the ability to issue search queries to get information to help answer user information.`\n",
        "const prompt = ChatPromptTemplate.fromMessages(\n",
        "[\n",
        "    [\"system\", system],\n",
        "    [\"human\", \"{question}\"],\n",
        "]\n",
        ")\n",
        "const llmWithTools = llm.withStructuredOutput(searchSchema, {\n",
        "name: \"Search\"\n",
        "})\n",
        "const queryAnalyzer = RunnableSequence.from([\n",
        "    {\n",
        "        question: new RunnablePassthrough(),\n",
        "    },\n",
        "    prompt,\n",
        "    llmWithTools\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9564078",
      "metadata": {},
      "source": [
        "我们可以看到，这允许在检索器之间进行路由"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bc1d3863",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{ query: \u001b[32m\"workplace of Harrison\"\u001b[39m, person: \u001b[32m\"HARRISON\"\u001b[39m }"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await queryAnalyzer.invoke(\"where did Harrison Work\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "af62af17-4f90-4dbd-a8b4-dfff51f1db95",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{ query: \u001b[32m\"Workplace of Ankush\"\u001b[39m, person: \u001b[32m\"ANKUSH\"\u001b[39m }"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await queryAnalyzer.invoke(\"where did ankush Work\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7c65b2f-7881-45fc-a47b-a4eaaf48245f",
      "metadata": {},
      "source": [
        "## 使用查询分析进行检索\n",
        "\n",
        "那么我们如何在链中包含这一点呢？我们只需要一些简单的逻辑来选择检索器并传入搜索查询"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4ec0c7fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "const retrievers = {\n",
        "    HARRISON: retrieverHarrison,\n",
        "    ANKUSH: retrieverAnkush,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8dac7866",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { RunnableConfig, RunnableLambda } from \"@langchain/core/runnables\";\n",
        "\n",
        "const chain = async (question: string, config?: RunnableConfig) => {\n",
        "    const response = await queryAnalyzer.invoke(question, config);\n",
        "    const retriever = retrievers[response.person];\n",
        "    return retriever.invoke(response.query, config);\n",
        "}\n",
        "\n",
        "const customChain = new RunnableLambda({ func: chain });"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "232ad8a7-7990-4066-9228-d35a555f7293",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ Document { pageContent: \u001b[32m\"Harrison worked at Kensho\"\u001b[39m, metadata: {} } ]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await customChain.invoke(\"where did Harrison Work\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "28e14ba5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ Document { pageContent: \u001b[32m\"Ankush worked at Facebook\"\u001b[39m, metadata: {} } ]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await customChain.invoke(\"where did ankush Work\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc898f9c",
      "metadata": {},
      "source": [
        "## 下一步",
        "\n",
        "你现在已经了解了一些在查询分析系统中处理多个检索器的技术。\n",
        "\n",
        "接下来，查看本节中其他一些查询分析指南，例如[如何处理未生成查询的情况](/docs/how_to/query_no_queries)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nb_converter": "script",
      "pygments_lexer": "typescript",
      "version": "5.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}