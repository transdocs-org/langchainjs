{
  "cells": [
    {
      "cell_type": "raw",
      "id": "0e77c293-4049-43be-ba49-ff9daeefeee7",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 4\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14d3fd06",
      "metadata": {},
      "source": [
        "# 如何进行按用户检索\n",
        "\n",
        ":::info 前提条件\n",
        "\n",
        "本指南假定您已熟悉以下内容：\n",
        "\n",
        "- [检索增强生成](/docs/tutorials/rag/)\n",
        "\n",
        ":::\n",
        "\n",
        "在构建检索应用程序时，您通常需要为多个用户设计和开发。这意味着您可能不仅为一个用户存储数据，而是为许多不同的用户存储数据，而且他们不应该能够看到彼此的数据。因此，您需要能够配置检索链，使其仅检索特定的信息。这通常包括以下两个步骤。\n",
        "\n",
        "**步骤 1：确保您使用的检索器支持多个用户**\n",
        "\n",
        "目前，LangChain 中没有统一的标志或过滤器来实现此目的。相反，每个向量存储和检索器可能有自己的实现方式，并且名称也可能不同（如命名空间、多租户等）。对于向量存储，这通常作为在 `similaritySearch` 期间传递的关键字参数暴露出来。通过阅读文档或源代码，弄清楚您使用的检索器是否支持多个用户，如果支持，了解如何使用它。\n",
        "\n",
        "**步骤 2：将该参数添加为链的可配置字段**\n",
        "\n",
        "LangChain 的 `config` 对象会被传递到每个可运行对象中。在这里，您可以将任何您想要的字段添加到 `configurable` 对象中。稍后，在链内部我们可以提取这些字段。\n",
        "\n",
        "**步骤 3：使用该可配置字段调用链**\n",
        "\n",
        "现在，在运行时您可以使用该可配置字段调用此链。\n",
        "\n",
        "## 代码示例\n",
        "\n",
        "让我们来看一个在代码中具体实现的例子。在此示例中我们将使用 Pinecone。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ccbef7",
      "metadata": {},
      "source": [
        "## 安裝設定\n",
        "\n",
        "### 安裝依賴\n",
        "\n",
        "```{=mdx}\n",
        "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
        "\n",
        "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/pinecone @langchain/openai @langchain/core @pinecone-database/pinecone\n",
        "</Npm2Yarn>\n",
        "```\n",
        "\n",
        "### 設定環境變數\n",
        "\n",
        "在此範例中，我們會使用 OpenAI 和 Pinecone：\n",
        "\n",
        "```env\n",
        "OPENAI_API_KEY=your-api-key\n",
        "\n",
        "PINECONE_API_KEY=your-api-key\n",
        "PINECONE_INDEX=your-index-name\n",
        "\n",
        "# 選用項目，使用 LangSmith 以獲得最佳的可觀察性\n",
        "LANGSMITH_API_KEY=your-api-key\n",
        "LANGSMITH_TRACING=true\n",
        "\n",
        "# 如果您不在無伺服器環境中，可減少追蹤延遲\n",
        "# LANGCHAIN_CALLBACKS_BACKGROUND=true\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7345de3c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ \u001b[32m\"77b8f174-9d89-4c6c-b2ab-607fe3913b2d\"\u001b[39m ]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
        "import { PineconeStore } from \"@langchain/pinecone\";\n",
        "import { Pinecone } from \"@pinecone-database/pinecone\";\n",
        "import { Document } from \"@langchain/core/documents\";\n",
        "\n",
        "const embeddings = new OpenAIEmbeddings();\n",
        "\n",
        "const pinecone = new Pinecone();\n",
        "\n",
        "const pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX);\n",
        "\n",
        "/**\n",
        " * Pinecone allows you to partition the records in an index into namespaces. \n",
        " * Queries and other operations are then limited to one namespace, \n",
        " * so different requests can search different subsets of your index.\n",
        " * Read more about namespaces here: https://docs.pinecone.io/guides/indexes/use-namespaces\n",
        " * \n",
        " * NOTE: If you have namespace enabled in your Pinecone index, you must provide the namespace when creating the PineconeStore.\n",
        " */\n",
        "const namespace = \"pinecone\";\n",
        "\n",
        "const vectorStore = await PineconeStore.fromExistingIndex(\n",
        "  new OpenAIEmbeddings(),\n",
        "  { pineconeIndex, namespace },\n",
        ");\n",
        "\n",
        "await vectorStore.addDocuments(\n",
        "  [new Document({ pageContent: \"i worked at kensho\" })],\n",
        "  { namespace: \"harrison\" },\n",
        ");\n",
        "\n",
        "await vectorStore.addDocuments(\n",
        "  [new Document({ pageContent: \"i worked at facebook\" })],\n",
        "  { namespace: \"ankush\" },\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c11920",
      "metadata": {},
      "source": [
        "`namespace` 的 pinecone 参数可用于分隔文档"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c2a39fa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ Document { pageContent: \u001b[32m\"i worked at facebook\"\u001b[39m, metadata: {} } ]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "// This will only get documents for Ankush\n",
        "const ankushRetriever = vectorStore.asRetriever({\n",
        "  filter: {\n",
        "    namespace: \"ankush\",\n",
        "  },\n",
        "});\n",
        "\n",
        "await ankushRetriever.invoke(\n",
        "  \"where did i work?\",\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "56393baa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ Document { pageContent: \u001b[32m\"i worked at kensho\"\u001b[39m, metadata: {} } ]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "// This will only get documents for Harrison\n",
        "const harrisonRetriever = vectorStore.asRetriever({\n",
        "  filter: {\n",
        "    namespace: \"harrison\",\n",
        "  },\n",
        "});\n",
        "\n",
        "await harrisonRetriever.invoke(\n",
        "  \"where did i work?\",\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ae97ed",
      "metadata": {},
      "source": [
        "我们现在可以创建将用于执行问答的链。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "44a865f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "import {\n",
        "  RunnableBinding,\n",
        "  RunnableLambda,\n",
        "  RunnablePassthrough,\n",
        "} from \"@langchain/core/runnables\";\n",
        "import { ChatOpenAI, OpenAIEmbeddings } from \"@langchain/openai\";\n",
        "\n",
        "const template = `Answer the question based only on the following context:\n",
        "{context}\n",
        "Question: {question}`;\n",
        "\n",
        "const prompt = ChatPromptTemplate.fromTemplate(template);\n",
        "\n",
        "const model = new ChatOpenAI({\n",
        "  model: \"gpt-3.5-turbo-0125\",\n",
        "  temperature: 0,\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d481b70",
      "metadata": {},
      "source": [
        "现在我们可以使用可配置的检索器来创建链。它是可配置的\n",
        "因为我们能够定义任意对象，并将其传递给链。随后，\n",
        "我们从中提取可配置对象并将其传递给向量存储。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "210b0446",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { RunnablePassthrough, RunnableSequence } from \"@langchain/core/runnables\";\n",
        "\n",
        "const chain = RunnableSequence.from([\n",
        "  RunnablePassthrough.assign({\n",
        "    context: async (input: { question: string }, config) => {\n",
        "      if (!config || !(\"configurable\" in config)) {\n",
        "        throw new Error(\"No config\");\n",
        "      }\n",
        "      const { configurable } = config;\n",
        "      const documents = await vectorStore.asRetriever(configurable).invoke(\n",
        "        input.question,\n",
        "        config,\n",
        "      );\n",
        "      return documents.map((doc) => doc.pageContent).join(\"\\n\\n\");\n",
        "    },\n",
        "  }),\n",
        "  prompt,\n",
        "  model,\n",
        "  new StringOutputParser(),\n",
        "]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f6458c3",
      "metadata": {},
      "source": [
        "我们现在可以使用可配置选项调用链。`search_kwargs` 是配置字段的id\n",
        "其值是用于Pinecone的搜索kwargs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a38037b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[32m\"The user worked at Kensho.\"\u001b[39m"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await chain.invoke(\n",
        "  { question: \"where did the user work?\"},\n",
        "  { configurable: { filter: { namespace: \"harrison\" } } },\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0ff4f5f2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[32m\"The user worked at Facebook.\"\u001b[39m"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await chain.invoke(\n",
        "  { question: \"where did the user work?\"},\n",
        "  { configurable: { filter: { namespace: \"ankush\" } } },\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb27b941602401d91542211134fc71a",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "有关更多可支持多用户的向量存储实现，请参考特定的页面，例如 [Milvus](/docs/integrations/vectorstores/milvus)。\n",
        "\n",
        "## 下一步\n",
        "\n",
        "现在您已经了解了一种支持从多个用户数据中进行检索的方法。\n",
        "\n",
        "接下来，请查看有关RAG的其他操作指南，例如 [返回来源](/docs/how_to/qa_sources)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nb_converter": "script",
      "pygments_lexer": "typescript",
      "version": "5.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}