{
  "cells": [
    {
      "cell_type": "raw",
      "id": "8165bd4c",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "keywords: [memory]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47033eb",
      "metadata": {},
      "source": [
        "# 如何添加消息历史\n",
        "\n",
        ":::info 前提条件\n",
        "\n",
        "本指南假定您熟悉以下概念：\n",
        "\n",
        "- [链式运行](/docs/how_to/sequence/)\n",
        "- [提示模板](/docs/concepts/prompt_templates)\n",
        "- [聊天消息](/docs/concepts/messages)\n",
        "\n",
        ":::\n",
        "\n",
        "```{=mdx}\n",
        ":::note\n",
        "\n",
        "本指南之前介绍了 [RunnableWithMessageHistory](https://api.js.langchain.com/classes/_langchain_core.runnables.RunnableWithMessageHistory.html) 抽象。您可以在 [v0.2 文档](https://js.langchain.com/v0.2/docs/how_to/message_history/) 中查看该版本的指南。\n",
        "\n",
        "LangGraph 实现相较于 `RunnableWithMessageHistory` 提供了许多优势，包括持久化应用程序状态的任意组件的能力（而不仅仅是消息）。\n",
        "\n",
        ":::\n",
        "```\n",
        "\n",
        "\n",
        "在构建聊天机器人时，将对话状态传递到链中并从中取出至关重要。LangGraph 实现了一个内置的持久化层，允许链状态自动在内存中或外部后端（如 SQLite、Postgres 或 Redis）中持久化。详细信息可以在 LangGraph 持久化文档中找到。\n",
        "\n",
        "在本指南中，我们演示了如何通过将任意 LangChain 可运行对象包装在一个最小的 LangGraph 应用程序中来添加持久化功能。这使我们能够持久化消息历史和链状态的其他元素，简化多轮应用程序的开发。它还支持多个线程，使单个应用程序可以分别与多个用户进行交互。\n",
        "\n",
        "## 准备工作\n",
        "\n",
        "```{=mdx}\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/core @langchain/langgraph\n",
        "</Npm2Yarn>\n",
        "```\n",
        "\n",
        "我们还设置一个聊天模型，用于以下示例。\n",
        "\n",
        "```{=mdx}\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"llm\" />\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8a4e4708",
      "metadata": {},
      "outputs": [],
      "source": [
        "// @lc-docs-hide-cell\n",
        "\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const llm = new ChatOpenAI({\n",
        "  model: \"gpt-4o\",\n",
        "  temperature: 0,\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6121bc-2080-4ccc-acf0-f77de4bc951d",
      "metadata": {},
      "source": [
        "## 示例：消息输入\n",
        "\n",
        "为[聊天模型](/docs/concepts/chat_models)添加记忆提供了一个简单的示例。聊天模型接受消息列表作为输入，并输出一条消息。LangGraph 包含一个内置的 `MessagesState`，我们可以为此目的使用它。\n",
        "\n",
        "下面，我们：\n",
        "1. 将图状态定义为消息列表；\n",
        "2. 向图中添加一个调用聊天模型的节点；\n",
        "3. 使用内存检查点存储运行之间的消息来编译该图。\n",
        "\n",
        ":::info\n",
        "\n",
        "LangGraph 应用程序的输出是其[状态](https://langchain-ai.github.io/langgraphjs/concepts/low_level/)。\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f691a73a-a866-4354-9fff-8315605e2b8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { START, END, MessagesAnnotation, StateGraph, MemorySaver } from \"@langchain/langgraph\";\n",
        "\n",
        "// Define the function that calls the model\n",
        "const callModel = async (state: typeof MessagesAnnotation.State) => {\n",
        "  const response = await llm.invoke(state.messages);\n",
        "  // Update message history with response:\n",
        "  return { messages: response };\n",
        "};\n",
        "\n",
        "// Define a new graph\n",
        "const workflow = new StateGraph(MessagesAnnotation)\n",
        "  // Define the (single) node in the graph\n",
        "  .addNode(\"model\", callModel)\n",
        "  .addEdge(START, \"model\")\n",
        "  .addEdge(\"model\", END);\n",
        "\n",
        "// Add memory\n",
        "const memory = new MemorySaver();\n",
        "const app = workflow.compile({ checkpointer: memory });"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b396a8-f81e-4139-b4b2-75adf61d8179",
      "metadata": {},
      "source": [
        "运行应用程序时，我们会传入一个指定`thread_id`的配置对象。该ID用于区分对话线程（例如，不同用户之间的对话）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e4309511-2140-4d91-8f5f-ea3661e6d179",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { v4 as uuidv4 } from \"uuid\";\n",
        "\n",
        "const config = { configurable: { thread_id: uuidv4() } }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108c45a2-4971-4120-ba64-9a4305a414bb",
      "metadata": {},
      "source": [
        "然后我们可以调用该应用程序："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "72a5ff6c-501f-4151-8dd9-f600f70554be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessage {\n",
            "  \"id\": \"chatcmpl-ABTqCeKnMQmG9IH8dNF5vPjsgXtcM\",\n",
            "  \"content\": \"Hi Bob! How can I assist you today?\",\n",
            "  \"additional_kwargs\": {},\n",
            "  \"response_metadata\": {\n",
            "    \"tokenUsage\": {\n",
            "      \"completionTokens\": 10,\n",
            "      \"promptTokens\": 12,\n",
            "      \"totalTokens\": 22\n",
            "    },\n",
            "    \"finish_reason\": \"stop\",\n",
            "    \"system_fingerprint\": \"fp_e375328146\"\n",
            "  },\n",
            "  \"tool_calls\": [],\n",
            "  \"invalid_tool_calls\": [],\n",
            "  \"usage_metadata\": {\n",
            "    \"input_tokens\": 12,\n",
            "    \"output_tokens\": 10,\n",
            "    \"total_tokens\": 22\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const input = [\n",
        "  {\n",
        "    role: \"user\",\n",
        "    content: \"Hi! I'm Bob.\",\n",
        "  }\n",
        "]\n",
        "const output = await app.invoke({ messages: input }, config)\n",
        "// The output contains all messages in the state.\n",
        "// This will log the last message in the conversation.\n",
        "console.log(output.messages[output.messages.length - 1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5931fb35-0fac-40e7-8ac6-b14cb4e926cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessage {\n",
            "  \"id\": \"chatcmpl-ABTqD5jrJXeKCpvoIDp47fvgw2OPn\",\n",
            "  \"content\": \"Your name is Bob. How can I help you today, Bob?\",\n",
            "  \"additional_kwargs\": {},\n",
            "  \"response_metadata\": {\n",
            "    \"tokenUsage\": {\n",
            "      \"completionTokens\": 14,\n",
            "      \"promptTokens\": 34,\n",
            "      \"totalTokens\": 48\n",
            "    },\n",
            "    \"finish_reason\": \"stop\",\n",
            "    \"system_fingerprint\": \"fp_e375328146\"\n",
            "  },\n",
            "  \"tool_calls\": [],\n",
            "  \"invalid_tool_calls\": [],\n",
            "  \"usage_metadata\": {\n",
            "    \"input_tokens\": 34,\n",
            "    \"output_tokens\": 14,\n",
            "    \"total_tokens\": 48\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const input2 = [\n",
        "  {\n",
        "    role: \"user\",\n",
        "    content: \"What's my name?\",\n",
        "  }\n",
        "]\n",
        "const output2 = await app.invoke({ messages: input2 }, config)\n",
        "console.log(output2.messages[output2.messages.length - 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91de6d12-881d-4d23-a421-f2e3bf829b79",
      "metadata": {},
      "source": [
        "请注意，不同线程的状态是相互分离的。如果我们使用新的 `thread_id` 向线程发出相同的查询，模型会表示它不知道答案："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "6f12c26f-8913-4484-b2c5-b49eda2e6d7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessage {\n",
            "  \"id\": \"chatcmpl-ABTqDkctxwmXjeGOZpK6Km8jdCqdl\",\n",
            "  \"content\": \"I'm sorry, but I don't have access to personal information about users. How can I assist you today?\",\n",
            "  \"additional_kwargs\": {},\n",
            "  \"response_metadata\": {\n",
            "    \"tokenUsage\": {\n",
            "      \"completionTokens\": 21,\n",
            "      \"promptTokens\": 11,\n",
            "      \"totalTokens\": 32\n",
            "    },\n",
            "    \"finish_reason\": \"stop\",\n",
            "    \"system_fingerprint\": \"fp_52a7f40b0b\"\n",
            "  },\n",
            "  \"tool_calls\": [],\n",
            "  \"invalid_tool_calls\": [],\n",
            "  \"usage_metadata\": {\n",
            "    \"input_tokens\": 11,\n",
            "    \"output_tokens\": 21,\n",
            "    \"total_tokens\": 32\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const config2 = { configurable: { thread_id: uuidv4() } }\n",
        "const input3 = [\n",
        "  {\n",
        "    role: \"user\",\n",
        "    content: \"What's my name?\",\n",
        "  }\n",
        "]\n",
        "const output3 = await app.invoke({ messages: input3 }, config2)\n",
        "console.log(output3.messages[output3.messages.length - 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6749ea95-3382-4843-bb96-cfececb9e4e5",
      "metadata": {},
      "source": [
        "## 示例：对象输入\n",
        "\n",
        "LangChain 可运行对象通常通过单个对象参数中不同的键接受多个输入。一个常见的例子是带有多个参数的提示模板。\n",
        "\n",
        "之前我们的可运行对象是一个聊天模型，这里我们将提示模板和聊天模型串联在一起。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6e7a402a-0994-4fc5-a607-fb990a248aa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
        "\n",
        "const prompt = ChatPromptTemplate.fromMessages([\n",
        "  [\"system\", \"Answer in {language}.\"],\n",
        "  new MessagesPlaceholder(\"messages\"),\n",
        "])\n",
        "\n",
        "const runnable = prompt.pipe(llm);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f83107bd-ae61-45e1-a57e-94ab043aad4b",
      "metadata": {},
      "source": [
        "在此场景中，我们定义图状态包含这些参数（除了消息历史）。\n",
        "\n",
        "请注意以下状态中的定义：\n",
        "- 对 `messages` 列表的更新会追加消息；\n",
        "- 对 `language` 字符串的更新会覆盖该字符串。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "267429ea-be0f-4f80-8daf-c63d881a1436",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { START, END, StateGraph, MemorySaver, MessagesAnnotation, Annotation } from \"@langchain/langgraph\";\n",
        "\n",
        "// Define the State\n",
        "// highlight-next-line\n",
        "const GraphAnnotation = Annotation.Root({\n",
        "  // highlight-next-line\n",
        "  language: Annotation<string>(),\n",
        "  // Spread `MessagesAnnotation` into the state to add the `messages` field.\n",
        "  // highlight-next-line\n",
        "  ...MessagesAnnotation.spec,\n",
        "})\n",
        "\n",
        "\n",
        "// Define the function that calls the model\n",
        "const callModel2 = async (state: typeof GraphAnnotation.State) => {\n",
        "  const response = await runnable.invoke(state);\n",
        "  // Update message history with response:\n",
        "  return { messages: [response] };\n",
        "};\n",
        "\n",
        "const workflow2 = new StateGraph(GraphAnnotation)\n",
        "  .addNode(\"model\", callModel2)\n",
        "  .addEdge(START, \"model\")\n",
        "  .addEdge(\"model\", END);\n",
        "\n",
        "const app2 = workflow2.compile({ checkpointer: new MemorySaver() });"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "f3844fb4-58d7-43c8-b427-6d9f64d7411b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessage {\n",
            "  \"id\": \"chatcmpl-ABTqFnCASRB5UhZ7XAbbf5T0Bva4U\",\n",
            "  \"content\": \"Lo siento, pero no tengo suficiente información para saber tu nombre. ¿Cómo te llamas?\",\n",
            "  \"additional_kwargs\": {},\n",
            "  \"response_metadata\": {\n",
            "    \"tokenUsage\": {\n",
            "      \"completionTokens\": 19,\n",
            "      \"promptTokens\": 19,\n",
            "      \"totalTokens\": 38\n",
            "    },\n",
            "    \"finish_reason\": \"stop\",\n",
            "    \"system_fingerprint\": \"fp_e375328146\"\n",
            "  },\n",
            "  \"tool_calls\": [],\n",
            "  \"invalid_tool_calls\": [],\n",
            "  \"usage_metadata\": {\n",
            "    \"input_tokens\": 19,\n",
            "    \"output_tokens\": 19,\n",
            "    \"total_tokens\": 38\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const config3 = { configurable: { thread_id: uuidv4() } }\n",
        "const input4 = {\n",
        "  messages: [\n",
        "    {\n",
        "      role: \"user\",\n",
        "      content: \"What's my name?\",\n",
        "    }\n",
        "  ],\n",
        "  language: \"Spanish\",\n",
        "} \n",
        "const output4 = await app2.invoke(input4, config3)\n",
        "console.log(output4.messages[output4.messages.length - 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df47824-ef18-4a6e-a416-345ec9203f88",
      "metadata": {},
      "source": [
        "## 管理消息历史记录",
        "\n",
        "消息历史记录（以及应用程序状态的其他元素）可以通过 `.getState` 访问："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "1cbd6d82-43c1-4d11-98af-5c3ad9cd9b3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language: Spanish\n",
            "[\n",
            "  HumanMessage {\n",
            "    \"content\": \"What's my name?\",\n",
            "    \"additional_kwargs\": {},\n",
            "    \"response_metadata\": {}\n",
            "  },\n",
            "  AIMessage {\n",
            "    \"id\": \"chatcmpl-ABTqFnCASRB5UhZ7XAbbf5T0Bva4U\",\n",
            "    \"content\": \"Lo siento, pero no tengo suficiente información para saber tu nombre. ¿Cómo te llamas?\",\n",
            "    \"additional_kwargs\": {},\n",
            "    \"response_metadata\": {\n",
            "      \"tokenUsage\": {\n",
            "        \"completionTokens\": 19,\n",
            "        \"promptTokens\": 19,\n",
            "        \"totalTokens\": 38\n",
            "      },\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"system_fingerprint\": \"fp_e375328146\"\n",
            "    },\n",
            "    \"tool_calls\": [],\n",
            "    \"invalid_tool_calls\": []\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "const state = (await app2.getState(config3)).values\n",
        "\n",
        "console.log(`Language: ${state.language}`);\n",
        "console.log(state.messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acfbccda-0bd6-4c4d-ae6e-8118520314e1",
      "metadata": {},
      "source": [
        "我们还可以通过 `.updateState` 来更新状态。例如，我们可以手动添加一条新消息："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e98310d7-8ab1-461d-94a7-dd419494ab8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "const _ = await app2.updateState(config3, { messages: [{ role: \"user\", content: \"test\" }]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "74ab3691-6f3b-49c5-aad0-2a90fc2a1e6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language: Spanish\n",
            "[\n",
            "  HumanMessage {\n",
            "    \"content\": \"What's my name?\",\n",
            "    \"additional_kwargs\": {},\n",
            "    \"response_metadata\": {}\n",
            "  },\n",
            "  AIMessage {\n",
            "    \"id\": \"chatcmpl-ABTqFnCASRB5UhZ7XAbbf5T0Bva4U\",\n",
            "    \"content\": \"Lo siento, pero no tengo suficiente información para saber tu nombre. ¿Cómo te llamas?\",\n",
            "    \"additional_kwargs\": {},\n",
            "    \"response_metadata\": {\n",
            "      \"tokenUsage\": {\n",
            "        \"completionTokens\": 19,\n",
            "        \"promptTokens\": 19,\n",
            "        \"totalTokens\": 38\n",
            "      },\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"system_fingerprint\": \"fp_e375328146\"\n",
            "    },\n",
            "    \"tool_calls\": [],\n",
            "    \"invalid_tool_calls\": []\n",
            "  },\n",
            "  HumanMessage {\n",
            "    \"content\": \"test\",\n",
            "    \"additional_kwargs\": {},\n",
            "    \"response_metadata\": {}\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "const state2 = (await app2.getState(config3)).values\n",
        "\n",
        "console.log(`Language: ${state2.language}`);\n",
        "console.log(state2.messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a1ea00-d7ff-4f18-b9ec-9aec5909d027",
      "metadata": {},
      "source": [
        "有关管理状态（包括删除消息）的详细信息，请参阅 LangGraph 文档：\n",
        "\n",
        "- [如何删除消息](https://langchain-ai.github.io/langgraphjs/how-tos/delete-messages/)\n",
        "- [如何查看和更新过去的图状态](https://langchain-ai.github.io/langgraphjs/how-tos/time-travel/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}