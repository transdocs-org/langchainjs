{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b5ee5b75-6876-4d62-9ade-5a7a808ae5a2",
      "metadata": {},
      "source": [
        "# 如何修剪消息\n",
        "\n",
        ":::info 预备知识\n",
        "\n",
        "本指南假设您熟悉以下概念：\n",
        "\n",
        "- [消息](/docs/concepts/messages)\n",
        "- [聊天模型](/docs/concepts/chat_models)\n",
        "- [链式调用](/docs/how_to/sequence/)\n",
        "- [聊天历史](/docs/concepts/chat_history)\n",
        "\n",
        "本指南中的方法还需要 `@langchain/core>=0.2.8`。\n",
        "有关安装说明，请参见[安装指南](/docs/how_to/installation/#installing-integration-packages)。\n",
        "\n",
        ":::\n",
        "\n",
        "所有模型都有有限的上下文窗口，这意味着它们作为输入接受的token数量是有限的。如果您有非常长的消息，或者某个链/代理积累了很长的消息历史，则需要管理传递给模型的消息的长度。\n",
        "\n",
        "`trimMessages` 工具提供了一些基本策略，用于将消息列表修剪为特定的token长度。\n",
        "\n",
        "## 获取最后 `maxTokens` 个token\n",
        "\n",
        "要获取消息列表中最后的 `maxTokens` 个token，可以设置 `strategy: \"last\"`。请注意，对于 `tokenCounter`，我们可以传入一个函数（更多内容见下文）或一个语言模型（因为语言模型具有消息token计数方法）。当您修剪消息是为了适应特定模型的上下文窗口时，传入该模型是合理的选择："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c974633b-3bd0-4844-8a8f-85e3e25f13fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"role\": \"human\",\n",
            "  \"content\": \"and who is harrison chasing anyways\"\n",
            "}\n",
            "\n",
            "{\n",
            "  \"role\": \"ai\",\n",
            "  \"content\": \"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last cup of coffee in the office!\"\n",
            "}\n",
            "\n",
            "{\n",
            "  \"role\": \"human\",\n",
            "  \"content\": \"what do you call a speechless parrot\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import { AIMessage, HumanMessage, SystemMessage, trimMessages } from \"@langchain/core/messages\";\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const messages = [\n",
        "    new SystemMessage(\"you're a good assistant, you always respond with a joke.\"),\n",
        "    new HumanMessage(\"i wonder why it's called langchain\"),\n",
        "    new AIMessage(\n",
        "        'Well, I guess they thought \"WordRope\" and \"SentenceString\" just didn\\'t have the same ring to it!'\n",
        "    ),\n",
        "    new HumanMessage(\"and who is harrison chasing anyways\"),\n",
        "    new AIMessage(\n",
        "        \"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last cup of coffee in the office!\"\n",
        "    ),\n",
        "    new HumanMessage(\"what do you call a speechless parrot\"),\n",
        "];\n",
        "\n",
        "const trimmed = await trimMessages(\n",
        "    messages,\n",
        "    {\n",
        "        maxTokens: 45,\n",
        "        strategy: \"last\",\n",
        "        tokenCounter: new ChatOpenAI({ model: \"gpt-4\" }),\n",
        "    }\n",
        ");\n",
        "\n",
        "console.log(trimmed.map((x) => JSON.stringify({\n",
        "    role: x._getType(),\n",
        "    content: x.content,\n",
        "}, null, 2)).join(\"\\n\\n\"));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f46654-c4b2-4136-b995-91c3febe5bf9",
      "metadata": {},
      "source": [
        "如果我们想要始终保留初始的系统消息，可以指定 `includeSystem: true`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "589b0223-3a73-44ec-8315-2dba3ee6117d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  SystemMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: \"you're a good assistant, you always respond with a joke.\",\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: \"you're a good assistant, you always respond with a joke.\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  },\n",
            "  AIMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'Hmmm let me think.\\n' +\n",
            "        '\\n' +\n",
            "        \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'Hmmm let me think.\\n' +\n",
            "      '\\n' +\n",
            "      \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined,\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    usage_metadata: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'what do you call a speechless parrot',\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'what do you call a speechless parrot',\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "await trimMessages(\n",
        "    messages,\n",
        "    {\n",
        "        maxTokens: 45,\n",
        "        strategy: \"last\",\n",
        "        tokenCounter: new ChatOpenAI({ model: \"gpt-4\" }),\n",
        "        includeSystem: true\n",
        "    }\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a8b542c-04d1-4515-8d82-b999ea4fac4f",
      "metadata": {},
      "source": [
        "如果我们希望允许拆分消息的内容，可以指定 `allowPartial: true`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8c46a209-dddd-4d01-81f6-f6ae55d3225c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  SystemMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: \"you're a good assistant, you always respond with a joke.\",\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: \"you're a good assistant, you always respond with a joke.\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  },\n",
            "  AIMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'Hmmm let me think.\\n' +\n",
            "        '\\n' +\n",
            "        \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'Hmmm let me think.\\n' +\n",
            "      '\\n' +\n",
            "      \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined,\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    usage_metadata: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'what do you call a speechless parrot',\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'what do you call a speechless parrot',\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "await trimMessages(\n",
        "    messages,\n",
        "    {\n",
        "        maxTokens: 50,\n",
        "        strategy: \"last\",\n",
        "        tokenCounter: new ChatOpenAI({ model: \"gpt-4\" }),\n",
        "        includeSystem: true,\n",
        "        allowPartial: true\n",
        "    }\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306adf9c-41cd-495c-b4dc-e4f43dd7f8f8",
      "metadata": {},
      "source": [
        "如果我们需要确保我们的第一条消息（不包括系统消息）始终是特定类型，我们可以指定 `startOn`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "878a730b-fe44-4e9d-ab65-7b8f7b069de8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  SystemMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: \"you're a good assistant, you always respond with a joke.\",\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: \"you're a good assistant, you always respond with a joke.\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'and who is harrison chasing anyways',\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'and who is harrison chasing anyways',\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  },\n",
            "  AIMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'Hmmm let me think.\\n' +\n",
            "        '\\n' +\n",
            "        \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'Hmmm let me think.\\n' +\n",
            "      '\\n' +\n",
            "      \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined,\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    usage_metadata: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'what do you call a speechless parrot',\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'what do you call a speechless parrot',\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "await trimMessages(\n",
        "    messages,\n",
        "    {\n",
        "        maxTokens: 60,\n",
        "        strategy: \"last\",\n",
        "        tokenCounter: new ChatOpenAI({ model: \"gpt-4\" }),\n",
        "        includeSystem: true,\n",
        "        startOn: \"human\"\n",
        "    }\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5d391d-235b-4091-b2de-c22866b478f3",
      "metadata": {},
      "source": [
        "## 获取前 `maxTokens` 个 token\n",
        "\n",
        "通过指定 `strategy: \"first\"`，我们可以执行相反的操作，即获取最开始的 `maxTokens` 个 token："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5f56ae54-1a39-4019-9351-3b494c003d5b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  SystemMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: \"you're a good assistant, you always respond with a joke.\",\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: \"you're a good assistant, you always respond with a joke.\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: \"i wonder why it's called langchain\",\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: \"i wonder why it's called langchain\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "await trimMessages(\n",
        "    messages,\n",
        "    {\n",
        "        maxTokens: 45,\n",
        "        strategy: \"first\",\n",
        "        tokenCounter: new ChatOpenAI({ model: \"gpt-4\" }),\n",
        "    }\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab70bf70-1e5a-4d51-b9b8-a823bf2cf532",
      "metadata": {},
      "source": [
        "## 编写自定义的token计数器\n",
        "\n",
        "我们可以编写一个自定义的token计数器函数，该函数接收一个消息列表并返回一个整数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1c1c3b1e-2ece-49e7-a3b6-e69877c1633b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  AIMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'Hmmm let me think.\\n' +\n",
            "        '\\n' +\n",
            "        \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'Hmmm let me think.\\n' +\n",
            "      '\\n' +\n",
            "      \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined,\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    usage_metadata: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'what do you call a speechless parrot',\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'what do you call a speechless parrot',\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import { encodingForModel } from '@langchain/core/utils/tiktoken';\n",
        "import { BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage, MessageContent, MessageContentText } from '@langchain/core/messages';\n",
        "\n",
        "async function strTokenCounter(messageContent: MessageContent): Promise<number> {\n",
        "    if (typeof messageContent === 'string') {\n",
        "        return (\n",
        "            await encodingForModel(\"gpt-4\")\n",
        "          ).encode(messageContent).length;\n",
        "    } else {\n",
        "        if (messageContent.every((x) => x.type === \"text\" && x.text)) {\n",
        "            return (\n",
        "                await encodingForModel(\"gpt-4\")\n",
        "              ).encode((messageContent as MessageContentText[]).map(({ text }) => text).join(\"\")).length;\n",
        "        }\n",
        "        throw new Error(`Unsupported message content ${JSON.stringify(messageContent)}`);\n",
        "    }\n",
        "}\n",
        "\n",
        "async function tiktokenCounter(messages: BaseMessage[]): Promise<number> {\n",
        "  let numTokens = 3; // every reply is primed with <|start|>assistant<|message|>\n",
        "  const tokensPerMessage = 3;\n",
        "  const tokensPerName = 1;\n",
        "\n",
        "  for (const msg of messages) {\n",
        "    let role: string;\n",
        "    if (msg instanceof HumanMessage) {\n",
        "      role = 'user';\n",
        "    } else if (msg instanceof AIMessage) {\n",
        "      role = 'assistant';\n",
        "    } else if (msg instanceof ToolMessage) {\n",
        "      role = 'tool';\n",
        "    } else if (msg instanceof SystemMessage) {\n",
        "      role = 'system';\n",
        "    } else {\n",
        "      throw new Error(`Unsupported message type ${msg.constructor.name}`);\n",
        "    }\n",
        "\n",
        "    numTokens += tokensPerMessage + (await strTokenCounter(role)) + (await strTokenCounter(msg.content));\n",
        "\n",
        "    if (msg.name) {\n",
        "      numTokens += tokensPerName + (await strTokenCounter(msg.name));\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return numTokens;\n",
        "}\n",
        "\n",
        "await trimMessages(messages, {\n",
        "  maxTokens: 45,\n",
        "  strategy: 'last',\n",
        "  tokenCounter: tiktokenCounter,\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2a672b-c007-47c5-9105-617944dc0a6a",
      "metadata": {},
      "source": [
        "## 链式调用\n",
        "\n",
        "`trimMessages` 可以以命令式（如上所示）或声明式的方式使用，便于与其他组件在链式结构中组合使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "96aa29b2-01e0-437c-a1ab-02fb0141cb57",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessage {\n",
            "  lc_serializable: true,\n",
            "  lc_kwargs: {\n",
            "    content: 'Thanks! I do try to keep things light. But for a more serious answer, \"LangChain\" is likely named to reflect its focus on language processing and the way it connects different components or models together—essentially forming a \"chain\" of linguistic operations. The \"Lang\" part emphasizes its focus on language, while \"Chain\" highlights the interconnected workflows it aims to facilitate.',\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
            "    response_metadata: {}\n",
            "  },\n",
            "  lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "  content: 'Thanks! I do try to keep things light. But for a more serious answer, \"LangChain\" is likely named to reflect its focus on language processing and the way it connects different components or models together—essentially forming a \"chain\" of linguistic operations. The \"Lang\" part emphasizes its focus on language, while \"Chain\" highlights the interconnected workflows it aims to facilitate.',\n",
            "  name: undefined,\n",
            "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
            "  response_metadata: {\n",
            "    tokenUsage: { completionTokens: 77, promptTokens: 59, totalTokens: 136 },\n",
            "    finish_reason: 'stop'\n",
            "  },\n",
            "  id: undefined,\n",
            "  tool_calls: [],\n",
            "  invalid_tool_calls: [],\n",
            "  usage_metadata: { input_tokens: 59, output_tokens: 77, total_tokens: 136 }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "import { trimMessages } from \"@langchain/core/messages\";\n",
        "\n",
        "const llm = new ChatOpenAI({ model: \"gpt-4o\" })\n",
        "\n",
        "// Notice we don't pass in messages. This creates\n",
        "// a RunnableLambda that takes messages as input\n",
        "const trimmer = trimMessages({\n",
        "    maxTokens: 45,\n",
        "    strategy: \"last\",\n",
        "    tokenCounter: llm,\n",
        "    includeSystem: true,\n",
        "})\n",
        "\n",
        "const chain = trimmer.pipe(llm);\n",
        "await chain.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d91d390-e7f7-467b-ad87-d100411d7a21",
      "metadata": {},
      "source": [
        "查看 [LangSmith 追踪](https://smith.langchain.com/public/3793312c-a74b-4e77-92b4-f91b3d74ac5f/r)，我们可以看到在消息传递给模型之前，它们首先会被裁剪。\n",
        "\n",
        "仅查看裁剪器时，我们可以看到它是一个 Runnable 对象，可以像所有 Runnable 一样被调用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1ff02d0a-353d-4fac-a77c-7c2c5262abd9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  SystemMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: \"you're a good assistant, you always respond with a joke.\",\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: \"you're a good assistant, you always respond with a joke.\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  },\n",
            "  AIMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'Hmmm let me think.\\n' +\n",
            "        '\\n' +\n",
            "        \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'Hmmm let me think.\\n' +\n",
            "      '\\n' +\n",
            "      \"Why, he's probably chasing after the last cup of coffee in the office!\",\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined,\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    usage_metadata: undefined\n",
            "  },\n",
            "  HumanMessage {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      content: 'what do you call a speechless parrot',\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {}\n",
            "    },\n",
            "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "    content: 'what do you call a speechless parrot',\n",
            "    name: undefined,\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: {},\n",
            "    id: undefined\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "await trimmer.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4720c8-4062-4ebc-9385-58411202ce6e",
      "metadata": {},
      "source": [
        "## 与 ChatMessageHistory 一起使用\n",
        "\n",
        "当 [处理聊天历史记录](/docs/how_to/message_history/) 时，修剪消息尤其有用，因为聊天记录可能会变得任意长："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a9517858-fc2f-4dc3-898d-bf98a0e905a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessage {\n",
            "  lc_serializable: true,\n",
            "  lc_kwargs: {\n",
            "    content: 'A \"polly-no-want-a-cracker\"!',\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
            "    response_metadata: {}\n",
            "  },\n",
            "  lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "  content: 'A \"polly-no-want-a-cracker\"!',\n",
            "  name: undefined,\n",
            "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
            "  response_metadata: {\n",
            "    tokenUsage: { completionTokens: 11, promptTokens: 57, totalTokens: 68 },\n",
            "    finish_reason: 'stop'\n",
            "  },\n",
            "  id: undefined,\n",
            "  tool_calls: [],\n",
            "  invalid_tool_calls: [],\n",
            "  usage_metadata: { input_tokens: 57, output_tokens: 11, total_tokens: 68 }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import { InMemoryChatMessageHistory } from \"@langchain/core/chat_history\";\n",
        "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
        "import { HumanMessage, trimMessages } from \"@langchain/core/messages\";\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const chatHistory = new InMemoryChatMessageHistory(messages.slice(0, -1))\n",
        "\n",
        "const dummyGetSessionHistory = async (sessionId: string) => {\n",
        "    if (sessionId !== \"1\") {\n",
        "        throw new Error(\"Session not found\");\n",
        "      }\n",
        "      return chatHistory;\n",
        "  }\n",
        "\n",
        "  const llm = new ChatOpenAI({ model: \"gpt-4o\" });\n",
        "\n",
        "  const trimmer = trimMessages({\n",
        "    maxTokens: 45,\n",
        "    strategy: \"last\",\n",
        "    tokenCounter: llm,\n",
        "    includeSystem: true,\n",
        "  });\n",
        "\n",
        "const chain = trimmer.pipe(llm);\n",
        "const chainWithHistory = new RunnableWithMessageHistory({\n",
        "    runnable: chain,\n",
        "    getMessageHistory: dummyGetSessionHistory,\n",
        "})\n",
        "await chainWithHistory.invoke(\n",
        "    [new HumanMessage(\"what do you call a speechless parrot\")],\n",
        "    { configurable: { sessionId: \"1\"} },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556b7b4c-43cb-41de-94fc-1a41f4ec4d2e",
      "metadata": {},
      "source": [
        "查看[LangSmith 跟踪](https://smith.langchain.com/public/cfc76880-5895-4852-b7d0-12916448bdb2/r)，我们可以看到我们检索到了所有消息，但在消息传递给模型之前，它们会被裁剪，仅保留系统消息和最后一条用户消息。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75dc7b84-b92f-44e7-8beb-ba22398e4efb",
      "metadata": {},
      "source": [
        "## API 参考\n",
        "\n",
        "有关所有参数的完整描述，请前往 [API 参考](https://api.js.langchain.com/functions/langchain_core.messages.trimMessages.html)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}