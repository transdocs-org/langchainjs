---
sidebar_position: 2
---

# 如何嵌入文本数据

:::info
前往 [集成](/docs/integrations/text_embedding) 查看与文本嵌入提供商集成的文档。
:::

:::info 前提条件

本指南假设您熟悉以下概念：

- [嵌入](/docs/concepts/embedding_models)

:::

嵌入会创建一段文本的向量表示。这非常有用，因为它意味着我们可以在向量空间中思考文本，并执行诸如语义搜索之类的事情，即在向量空间中查找最相似的文本片段。

LangChain 中的基础 Embeddings 类公开了两种方法：一种用于嵌入文档，另一种用于嵌入查询。前者接收多个文本作为输入，而后者接收单个文本。之所以将这两个方法分开，是因为某些嵌入提供商会对文档（用于搜索）和查询（搜索本身）采用不同的嵌入方法。

## 入门

以下是使用 OpenAI 嵌入的示例。嵌入有时会对查询和文档采用不同的嵌入方法，因此嵌入类暴露了 `embedQuery` 和 `embedDocuments` 方法。

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/openai @langchain/core
```

## 入门

```typescript
import { OpenAIEmbeddings } from "@langchain/openai";

const embeddings = new OpenAIEmbeddings();
```

## 嵌入查询

```typescript
const res = await embeddings.embedQuery("Hello world");
/*
[
   -0.004845875,   0.004899438,  -0.016358767,  -0.024475135, -0.017341806,
    0.012571548,  -0.019156644,   0.009036391,  -0.010227379, -0.026945334,
    0.022861943,   0.010321903,  -0.023479493, -0.0066544134,  0.007977734,
   0.0026371893,   0.025206111,  -0.012048521,   0.012943339,  0.013094575,
   -0.010580265,  -0.003509951,   0.004070787,   0.008639394, -0.020631202,
  ... 1511 more items
]
*/
```

## 嵌入文档

```typescript
const documentRes = await embeddings.embedDocuments(["Hello world", "Bye bye"]);
/*
[
  [
    -0.004845875,   0.004899438,  -0.016358767,  -0.024475135, -0.017341806,
      0.012571548,  -0.019156644,   0.009036391,  -0.010227379, -0.026945334,
      0.022861943,   0.010321903,  -0.023479493, -0.0066544134,  0.007977734,
    0.0026371893,   0.025206111,  -0.012048521,   0.012943339,  0.013094575,
    -0.010580265,  -0.003509951,   0.004070787,   0.008639394, -0.020631202,
    ... 1511 more items
  ]
  [
      -0.009446913,  -0.013253193,   0.013174579,  0.0057552797,  -0.038993083,
      0.0077763423,    -0.0260478, -0.0114384955, -0.0022683728,  -0.016509168,
      0.041797023,    0.01787183,    0.00552271, -0.0049789557,   0.018146982,
      -0.01542166,   0.033752076,   0.006112323,   0.023872782,  -0.016535373,
      -0.006623321,   0.016116094, -0.0061090477, -0.0044155475,  -0.016627092,
    ... 1511 more items
  ]
]
*/
```

## 下一步

现在您已经了解了如何将嵌入模型用于查询和文本。

接下来，查看如何 [通过缓存避免重复计算嵌入](/docs/how_to/caching_embeddings)，或者完整的 [检索增强生成教程](/docs/tutorials/rag)。