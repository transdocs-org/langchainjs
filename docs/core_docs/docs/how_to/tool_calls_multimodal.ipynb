{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4facdf7f-680e-4d28-908b-2b8408e2a741",
      "metadata": {},
      "source": [
        "# 如何使用多模态数据调用工具\n",
        "\n",
        ":::info 预备知识\n",
        "\n",
        "本指南假定您熟悉以下概念：\n",
        "\n",
        "- [聊天模型](/docs/concepts/chat_models)\n",
        "- [LangChain 工具](/docs/concepts/tools)\n",
        "\n",
        ":::\n",
        "\n",
        "在这里，我们演示如何使用多模态数据（如图像）调用工具。\n",
        "\n",
        "某些多模态模型，例如可以对图像或音频进行推理的模型，也支持[工具调用](/docs/concepts/#tool-calling)功能。\n",
        "\n",
        "要使用此类模型调用工具，只需以[常规方式](/docs/how_to/tool_calling)将工具绑定到模型，并使用所需类型的内容块（例如包含图像数据的内容块）调用模型即可。\n",
        "\n",
        "下面，我们演示使用 [OpenAI](/docs/integrations/platforms/openai) 和 [Anthropic](/docs/integrations/platforms/anthropic) 的示例。在所有情况下，我们将使用相同的图像和工具。首先选择一个图像，并构建一个占位符工具，该工具期望输入字符串 \"sunny\"、\"cloudy\" 或 \"rainy\"。我们将要求模型描述图像中的天气。\n",
        "\n",
        ":::note\n",
        "`tool` 函数在 `@langchain/core` 版本 0.2.7 及以上中可用。\n",
        "\n",
        "如果您使用的是 core 的旧版本，则应使用 [`DynamicStructuredTool`](https://api.js.langchain.com/classes/langchain_core.tools.DynamicStructuredTool.html) 实例化并使用它。\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0d9fd81a-b7f0-445a-8e3d-cfc2d31fdd59",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { tool } from \"@langchain/core/tools\";\n",
        "import { z } from \"zod\";\n",
        "\n",
        "const imageUrl = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\";\n",
        "\n",
        "const weatherTool = tool(async ({ weather }) => {\n",
        "  console.log(weather);\n",
        "  return weather;\n",
        "}, {\n",
        "  name: \"multiply\",\n",
        "  description: \"Describe the weather\",\n",
        "  schema: z.object({\n",
        "    weather: z.enum([\"sunny\", \"cloudy\", \"rainy\"])\n",
        "  }),\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8656018e-c56d-47d2-b2be-71e87827f90a",
      "metadata": {},
      "source": [
        "## OpenAI\n",
        "\n",
        "对于OpenAI，我们可以将图像URL直接作为类型为\"image_url\"的内容块输入："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a8819cf3-5ddc-44f0-889a-19ca7b7fe77e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    name: \"multiply\",\n",
            "    args: { weather: \"sunny\" },\n",
            "    id: \"call_ZaBYUggmrTSuDjcuZpMVKpMR\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import { HumanMessage } from \"@langchain/core/messages\";\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const model = new ChatOpenAI({\n",
        "  model: \"gpt-4o\",\n",
        "}).bindTools([weatherTool]);\n",
        "\n",
        "const message = new HumanMessage({\n",
        "  content: [\n",
        "    {\n",
        "      type: \"text\",\n",
        "      text: \"describe the weather in this image\"\n",
        "    },\n",
        "    {\n",
        "      type: \"image_url\",\n",
        "      image_url: {\n",
        "        url: imageUrl\n",
        "      }\n",
        "    }\n",
        "  ],\n",
        "});\n",
        "\n",
        "const response = await model.invoke([message]);\n",
        "\n",
        "console.log(response.tool_calls);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5738224-1109-4bf8-8976-ff1570dd1d46",
      "metadata": {},
      "source": [
        "请注意，我们在模型响应中以LangChain的[标准格式](/docs/how_to/tool_calling)恢复带有解析参数的工具调用。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cee63ff-e09f-4dd8-8323-912edbde94f6",
      "metadata": {},
      "source": [
        "## Anthropic\n",
        "\n",
        "对于Anthropic，我们可以将一个base64编码的图像格式化为类型为\"image\"的内容块，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d90c4590-71c8-42b1-99ff-03a9eca8082e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    name: \"multiply\",\n",
            "    args: { weather: \"sunny\" },\n",
            "    id: \"toolu_01HLY1KmXZkKMn7Ar4ZtFuAM\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import * as fs from \"node:fs/promises\";\n",
        "\n",
        "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
        "import { HumanMessage } from \"@langchain/core/messages\";\n",
        "\n",
        "const imageData = await fs.readFile(\"../../data/sunny_day.jpeg\");\n",
        "\n",
        "const model = new ChatAnthropic({\n",
        "  model: \"claude-3-sonnet-20240229\",\n",
        "}).bindTools([weatherTool]);\n",
        "\n",
        "const message = new HumanMessage({\n",
        "  content: [\n",
        "    {\n",
        "      type: \"text\",\n",
        "      text: \"describe the weather in this image\",\n",
        "    },\n",
        "    {\n",
        "      type: \"image_url\",\n",
        "      image_url: {\n",
        "        url: `data:image/jpeg;base64,${imageData.toString(\"base64\")}`,\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "});\n",
        "\n",
        "const response = await model.invoke([message]);\n",
        "\n",
        "console.log(response.tool_calls);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a66b7d2f",
      "metadata": {},
      "source": [
        "## 谷歌生成式人工智能\n",
        "\n",
        "对于谷歌生成式人工智能（GenAI），我们可以将经过 base64 编码的图像格式化为类型为 \"image\" 的内容块，如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f8184909",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ { name: 'multiply', args: { weather: 'sunny' } } ]\n"
          ]
        }
      ],
      "source": [
        "import { ChatGoogleGenerativeAI } from \"@langchain/google-genai\";\n",
        "import axios from \"axios\";\n",
        "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
        "import { HumanMessage } from \"@langchain/core/messages\";\n",
        "\n",
        "const axiosRes = await axios.get(imageUrl, { responseType: \"arraybuffer\" });\n",
        "const base64 = btoa(\n",
        "  new Uint8Array(axiosRes.data).reduce(\n",
        "    (data, byte) => data + String.fromCharCode(byte),\n",
        "    ''\n",
        "  )\n",
        ");\n",
        "\n",
        "const model = new ChatGoogleGenerativeAI({ model: \"gemini-1.5-pro-latest\" }).bindTools([weatherTool]);\n",
        "\n",
        "const prompt = ChatPromptTemplate.fromMessages([\n",
        "  [\"system\", \"describe the weather in this image\"],\n",
        "  new MessagesPlaceholder(\"message\")\n",
        "]);\n",
        "\n",
        "const response = await prompt.pipe(model).invoke({\n",
        "  message: new HumanMessage({\n",
        "    content: [{\n",
        "      type: \"media\",\n",
        "      mimeType: \"image/jpeg\",\n",
        "      data: base64,\n",
        "    }]\n",
        "  })\n",
        "});\n",
        "console.log(response.tool_calls);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5dd4ef4",
      "metadata": {},
      "source": [
        "### 音频输入\n",
        "\n",
        "Google的Gemini还支持音频输入。在下一个示例中，我们将看到如何将音频文件传递给模型，并以结构化格式获取摘要。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c04c883e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    name: 'summary_tool',\n",
            "    args: { summary: 'The video shows a person clapping their hands.' }\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import { SystemMessage } from \"@langchain/core/messages\";\n",
        "import { tool } from \"@langchain/core/tools\";\n",
        "\n",
        "const summaryTool = tool((input) => {\n",
        "  return input.summary;\n",
        "}, {\n",
        "  name: \"summary_tool\",\n",
        "  description: \"Log the summary of the content\",\n",
        "  schema: z.object({\n",
        "    summary: z.string().describe(\"The summary of the content to log\")\n",
        "  }),\n",
        "});\n",
        "\n",
        "const audioUrl = \"https://www.pacdv.com/sounds/people_sound_effects/applause-1.wav\";\n",
        "\n",
        "const axiosRes = await axios.get(audioUrl, { responseType: \"arraybuffer\" });\n",
        "const base64 = btoa(\n",
        "  new Uint8Array(axiosRes.data).reduce(\n",
        "    (data, byte) => data + String.fromCharCode(byte),\n",
        "    ''\n",
        "  )\n",
        ");\n",
        "\n",
        "const model = new ChatGoogleGenerativeAI({ model: \"gemini-1.5-pro-latest\" }).bindTools([summaryTool]);\n",
        "\n",
        "const response = await model.invoke([\n",
        "  new SystemMessage(\"Summarize this content. always use the summary_tool in your response\"),\n",
        "  new HumanMessage({\n",
        "  content: [{\n",
        "    type: \"media\",\n",
        "    mimeType: \"audio/wav\",\n",
        "    data: base64,\n",
        "  }]\n",
        "})]);\n",
        "\n",
        "console.log(response.tool_calls);"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}