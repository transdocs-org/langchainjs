{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 如何从工具中流式传输事件\n",
        "\n",
        "```{=mdx}\n",
        ":::info 预备知识\n",
        "\n",
        "本指南假定您熟悉以下概念：\n",
        "- [LangChain 工具](/docs/concepts/tools)\n",
        "- [自定义工具](/docs/how_to/custom_tools)\n",
        "- [使用流式事件](/docs/how_to/streaming/#using-stream-events)\n",
        "- [在自定义工具中访问 RunnableConfig](/docs/how_to/tool_configure/)\n",
        "\n",
        ":::\n",
        "```\n",
        "\n",
        "如果您有调用聊天模型、检索器或其他可运行对象的工具，您可能希望访问这些可运行对象的内部事件或使用额外属性配置它们。本指南将向您展示如何正确手动传递参数，以便您可以使用 [.streamEvents()](/docs/how_to/streaming/#using-stream-events) 方法实现此目的。\n",
        "\n",
        "```{=mdx}\n",
        ":::caution 兼容性\n",
        "\n",
        "为了支持更广泛的 JavaScript 环境，基础 LangChain 包默认不会自动将配置传播到子可运行对象。这包括 .streamEvents() 所需的回调。这是您可能无法看到自定义可运行对象或工具发出事件的常见原因。\n",
        "\n",
        "您需要手动将 RunnableConfig 对象传播到子可运行对象。有关手动传播配置的示例，请参见下面 RunnableLambda 的 bar 实现。\n",
        "\n",
        "本指南还要求 @langchain/core>=0.2.16。\n",
        ":::\n",
        "```\n",
        "\n",
        "假设您有一个自定义工具，它调用了一个链，该链通过提示聊天模型仅返回10个单词，然后反转输出来压缩其输入。首先，以一种简单的方式定义它：\n",
        "\n",
        "```{=mdx}\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"model\" />\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
        "const model = new ChatAnthropic({\n",
        "  model: \"claude-3-5-sonnet-20240620\",\n",
        "  temperature: 0,\n",
        "});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import { z } from \"zod\";\n",
        "import { tool } from \"@langchain/core/tools\";\n",
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
        "\n",
        "const specialSummarizationTool = tool(async (input) => {\n",
        "  const prompt = ChatPromptTemplate.fromTemplate(\n",
        "    \"You are an expert writer. Summarize the following text in 10 words or less:\\n\\n{long_text}\"\n",
        "  );\n",
        "  const reverse = (x: string) => {\n",
        "    return x.split(\"\").reverse().join(\"\");\n",
        "  };\n",
        "  const chain = prompt\n",
        "    .pipe(model)\n",
        "    .pipe(new StringOutputParser())\n",
        "    .pipe(reverse);\n",
        "  const summary = await chain.invoke({ long_text: input.long_text });\n",
        "  return summary;\n",
        "}, {\n",
        "  name: \"special_summarization_tool\",\n",
        "  description: \"A tool that summarizes input text using advanced techniques.\",\n",
        "  schema: z.object({\n",
        "    long_text: z.string(),\n",
        "  }),\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "直接调用工具也能正常工作："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".yad noitaudarg rof tiftuo sesoohc yrraB ;scisyhp seifed eeB\n"
          ]
        }
      ],
      "source": [
        "const LONG_TEXT = `\n",
        "NARRATOR:\n",
        "(Black screen with text; The sound of buzzing bees can be heard)\n",
        "According to all known laws of aviation, there is no way a bee should be able to fly. Its wings are too small to get its fat little body off the ground. The bee, of course, flies anyway because bees don't care what humans think is impossible.\n",
        "BARRY BENSON:\n",
        "(Barry is picking out a shirt)\n",
        "Yellow, black. Yellow, black. Yellow, black. Yellow, black. Ooh, black and yellow! Let's shake it up a little.\n",
        "JANET BENSON:\n",
        "Barry! Breakfast is ready!\n",
        "BARRY:\n",
        "Coming! Hang on a second.`;\n",
        "\n",
        "await specialSummarizationTool.invoke({ long_text: LONG_TEXT });"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "但如果你想访问聊天模型的原始输出而非完整工具，你可以尝试使用 [`streamEvents()`](/docs/how_to/streaming/#using-stream-events) 方法，并查找 `on_chat_model_end` 事件。以下是其工作原理："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "const stream = await specialSummarizationTool.streamEvents(\n",
        "  { long_text: LONG_TEXT },\n",
        "  { version: \"v2\" },\n",
        ");\n",
        "\n",
        "for await (const event of stream) {\n",
        "  if (event.event === \"on_chat_model_end\") {\n",
        "    // Never triggers!\n",
        "    console.log(event);\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "请注意，子运行中没有发出聊天模型事件！\n",
        "\n",
        "这是因为上面的示例未将工具的配置对象传递到内部链中。要解决此问题，请重新定义你的工具，使其接收一个特殊参数，该参数的类型为 `RunnableConfig`（更多详细信息请参见[此指南](/docs/how_to/tool_configure)）。在执行内部链时，还需要将该参数传递进去："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "const specialSummarizationToolWithConfig = tool(async (input, config) => {\n",
        "  const prompt = ChatPromptTemplate.fromTemplate(\n",
        "    \"You are an expert writer. Summarize the following text in 10 words or less:\\n\\n{long_text}\"\n",
        "  );\n",
        "  const reverse = (x: string) => {\n",
        "    return x.split(\"\").reverse().join(\"\");\n",
        "  };\n",
        "  const chain = prompt\n",
        "    .pipe(model)\n",
        "    .pipe(new StringOutputParser())\n",
        "    .pipe(reverse);\n",
        "  // Pass the \"config\" object as an argument to any executed runnables\n",
        "  const summary = await chain.invoke({ long_text: input.long_text }, config);\n",
        "  return summary;\n",
        "}, {\n",
        "  name: \"special_summarization_tool\",\n",
        "  description: \"A tool that summarizes input text using advanced techniques.\",\n",
        "  schema: z.object({\n",
        "    long_text: z.string(),\n",
        "  }),\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在使用你的新工具尝试与之前相同的 `.streamEvents()` 调用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  event: 'on_chat_model_end',\n",
            "  data: {\n",
            "    output: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'Bee defies physics; Barry chooses outfit for graduation day.',\n",
            "      name: undefined,\n",
            "      additional_kwargs: [Object],\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: [Object]\n",
            "    },\n",
            "    input: { messages: [Array] }\n",
            "  },\n",
            "  run_id: '27ac7b2e-591c-4adc-89ec-64d96e233ec8',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const stream = await specialSummarizationToolWithConfig.streamEvents(\n",
        "  { long_text: LONG_TEXT },\n",
        "  { version: \"v2\" },\n",
        ");\n",
        "\n",
        "for await (const event of stream) {\n",
        "  if (event.event === \"on_chat_model_end\") {\n",
        "    // Never triggers!\n",
        "    console.log(event);\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "太棒了！这次有一个事件被触发了。\n",
        "\n",
        "对于流式传输，如果可能的话，`.streamEvents()` 会自动调用链中启用流式传输的内部可运行对象，因此如果你希望获得聊天模型生成的 token 流，只需筛选 `on_chat_model_stream` 事件即可，无需其他更改："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'Bee',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' def',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'ies physics',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ';',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' Barry',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' cho',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'oses outfit',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' for',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' graduation',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' day',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '.',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: {},\n",
            "      id: undefined,\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: '938c0469-83c6-4dbd-862e-cd73381165de',\n",
            "  name: 'ChatAnthropic',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'anthropic',\n",
            "    ls_model_name: 'claude-3-5-sonnet-20240620',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 0,\n",
            "    ls_max_tokens: 2048,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const stream = await specialSummarizationToolWithConfig.streamEvents(\n",
        "  { long_text: LONG_TEXT },\n",
        "  { version: \"v2\" },\n",
        ");\n",
        "\n",
        "for await (const event of stream) {\n",
        "  if (event.event === \"on_chat_model_stream\") {\n",
        "    // Never triggers!\n",
        "    console.log(event);\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 自动传递配置（高级）\n",
        "\n",
        "如果你使用过 [LangGraph](https://langchain-ai.github.io/langgraphjs/)，你可能已经注意到在嵌套调用中无需手动传递配置。这是因为 LangGraph 利用了一个名为 [`async_hooks`](https://nodejs.org/api/async_hooks.html) 的 API，但在许多（但并非所有）环境中并不支持该功能。\n",
        "\n",
        "如果需要，你可以通过运行以下代码来全局导入并启用 `AsyncLocalStorage`，以启用自动配置传递功能："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\n",
        "import { AsyncLocalStorage } from \"async_hooks\";\n",
        "\n",
        "AsyncLocalStorageProviderSingleton.initializeGlobalInstance(\n",
        "  new AsyncLocalStorage()\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 下一步\n",
        "\n",
        "现在你已经了解了如何在工具内部流式传输事件。接下来，请查看以下指南以了解更多关于使用工具的内容：\n",
        "\n",
        "- 将 [运行时值传递给工具](/docs/how_to/tool_runtime)\n",
        "- 将 [工具结果返回给模型](/docs/how_to/tool_results_pass_to_model)\n",
        "- [分派自定义回调事件](/docs/how_to/callbacks_custom_events)\n",
        "\n",
        "你还可以查看一些更具体的工具调用用法：\n",
        "\n",
        "- 构建 [使用工具的链和代理](/docs/how_to#tools)\n",
        "- 从模型获取 [结构化输出](/docs/how_to/structured_output/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}