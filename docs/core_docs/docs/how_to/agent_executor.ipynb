{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4c03f40-1328-412d-8a48-1db0cd481b77",
      "metadata": {},
      "source": [
        "# 如何使用传统的LangChain代理（AgentExecutor）\n",
        "\n",
        ":::info 预备知识\n",
        "\n",
        "本指南假定您熟悉以下概念：\n",
        "\n",
        "- [工具](/docs/concepts/tools)\n",
        "\n",
        ":::\n",
        "\n",
        "语言模型本身无法执行操作 - 它们只是输出文本。\n",
        "代理是一种系统，它使用LLM作为推理引擎来确定要执行哪些操作以及这些操作的输入应该是什么。\n",
        "这些操作的结果随后可以反馈给代理，代理将确定是否需要执行更多操作，或者是否可以结束。\n",
        "\n",
        "在本教程中，我们将构建一个可以与多个不同工具交互的代理：一个是本地数据库，另一个是搜索引擎。您可以向这个代理提问，观察它调用工具，并与它进行对话。\n",
        "\n",
        ":::{.callout-important}\n",
        "本节将介绍使用LangChain代理进行构建。LangChain代理适合入门，但超过一定阶段后，您可能需要它们无法提供的灵活性和控制力。对于使用更高级的代理，我们建议查看[LangGraph](https://langchain-ai.github.io/langgraphjs)。\n",
        ":::\n",
        "\n",
        "## 概念\n",
        "\n",
        "我们将介绍的概念包括：\n",
        "- 使用[语言模型](/docs/concepts/chat_models)，特别是它们的工具调用能力\n",
        "- 创建一个[检索器](/docs/concepts/retrievers)，以向我们的代理暴露特定信息\n",
        "- 使用搜索[工具](/docs/concepts/tools)在线查找内容\n",
        "- [`聊天历史`](/docs/concepts/chat_history)，这允许聊天机器人“记住”过去的交互，并在回应后续问题时考虑这些信息。\n",
        "- 使用[LangSmith](/docs/concepts/#langsmith)调试和追踪您的应用程序\n",
        "\n",
        "## 准备工作\n",
        "\n",
        "### Jupyter Notebook\n",
        "\n",
        "本指南（以及文档中的大多数其他指南）使用[Jupyter笔记本](https://jupyter.org/)，并假定读者也使用。Jupyter笔记本非常适合学习如何操作LLM系统，因为很多时候可能会出错（意外输出、API中断等），而在交互式环境中进行指南是更好地理解它们的好方法。\n",
        "\n",
        "这个及其他教程可能最适合在Jupyter笔记本中运行。有关安装说明，请参见[此处](https://jupyter.org/install)。\n",
        "\n",
        "### 安装\n",
        "\n",
        "要安装LangChain（以及web加载器的`cheerio`），运行：\n",
        "\n",
        "```{=mdx}\n",
        "import Npm2Yarn from '@theme/Npm2Yarn';\n",
        "\n",
        "<Npm2Yarn>\n",
        "  langchain @langchain/core cheerio\n",
        "</Npm2Yarn>\n",
        "```\n",
        "\n",
        "更多详细信息，请参阅我们的[安装指南](/docs/how_to/installation/)。\n",
        "\n",
        "### LangSmith\n",
        "\n",
        "使用LangChain构建的许多应用程序将包含多个步骤，涉及多次调用LLM。\n",
        "随着这些应用程序变得越来越复杂，能够检查您的链或代理内部到底发生了什么变得至关重要。\n",
        "最好的方法是使用[LangSmith](https://smith.langchain.com)。\n",
        "\n",
        "在上方链接注册后，请确保设置您的环境变量以开始记录追踪：\n",
        "\n",
        "```shell\n",
        "export LANGSMITH_TRACING=\"true\"\n",
        "export LANGSMITH_API_KEY=\"...\"\n",
        "\n",
        "# 如果您不在无服务器环境中，请减少追踪延迟\n",
        "# export LANGCHAIN_CALLBACKS_BACKGROUND=true\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c335d1bf",
      "metadata": {},
      "source": [
        "## 定义工具\n",
        "\n",
        "我们首先需要创建我们想要使用的工具。我们将使用两个工具：[Tavily](/docs/integrations/tools/tavily_search)（用于在线搜索），然后是我们将创建的本地索引的检索器\n",
        "\n",
        "### [Tavily](/docs/integrations/tools/tavily_search)\n",
        "\n",
        "LangChain中有一个内置工具，可以方便地将Tavily搜索引擎作为工具使用。\n",
        "请注意，这需要一个API密钥——他们有免费的层级，但如果您没有或者不想创建一个，您可以随时跳过此步骤。\n",
        "\n",
        "一旦您创建了API密钥，您需要将其导出为：\n",
        "\n",
        "```bash\n",
        "export TAVILY_API_KEY=\"...\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9cc86c0b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[32m`[{\"title\":\"Weather in San Francisco\",\"url\":\"https://www.weatherapi.com/\",\"content\":\"{'location': {'n`\u001b[39m... 1358 more characters"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import \"cheerio\"; // This is required in notebooks to use the `CheerioWebBaseLoader`\n",
        "import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\"\n",
        "\n",
        "const search = new TavilySearchResults({\n",
        "  maxResults: 2\n",
        "});\n",
        "\n",
        "await search.invoke(\"what is the weather in SF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8097977",
      "metadata": {},
      "source": [
        "### 检索器\n",
        "\n",
        "我们还将基于我们自己的某些数据创建一个检索器。有关每个步骤的更深入解释，请参阅[本教程](/docs/tutorials/rag)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9c9ce713",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document {\n",
              "  pageContent: \u001b[32m'description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": '\u001b[39m... 891 more characters,\n",
              "  metadata: {\n",
              "    source: \u001b[32m\"https://docs.smith.langchain.com/overview\"\u001b[39m,\n",
              "    loc: { lines: { from: \u001b[33m4\u001b[39m, to: \u001b[33m4\u001b[39m } }\n",
              "  },\n",
              "  id: \u001b[90mundefined\u001b[39m\n",
              "}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\n",
        "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
        "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
        "import { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\n",
        "\n",
        "const loader = new CheerioWebBaseLoader(\"https://docs.smith.langchain.com/overview\");\n",
        "const docs = await loader.load();\n",
        "const splitter = new RecursiveCharacterTextSplitter(\n",
        "  {\n",
        "    chunkSize: 1000,\n",
        "    chunkOverlap: 200\n",
        "  }\n",
        ");\n",
        "const documents = await splitter.splitDocuments(docs);\n",
        "const vectorStore = await MemoryVectorStore.fromDocuments(documents, new OpenAIEmbeddings());\n",
        "const retriever = vectorStore.asRetriever();\n",
        "\n",
        "(await retriever.invoke(\"how to upload a dataset\"))[0];"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04aeca39",
      "metadata": {},
      "source": [
        "现在我们已经填充了将要进行检索的索引，可以轻松地将其转换为一个工具（代理正确使用所需的格式）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7280b031",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { z } from \"zod\";\n",
        "import { tool } from \"@langchain/core/tools\";\n",
        "\n",
        "const retrieverTool = tool(async ({ input }, config) => {\n",
        "  const docs = await retriever.invoke(input, config);\n",
        "  return docs.map((doc) => doc.pageContent).join(\"\\n\\n\");\n",
        "}, {\n",
        "  name: \"langsmith_search\",\n",
        "  description:\n",
        "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
        "  schema: z.object({\n",
        "    input: z.string()\n",
        "  }),\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b47c1d",
      "metadata": {},
      "source": [
        "### 工具\n",
        "\n",
        "既然我们已经创建了这两个对象，我们现在可以创建一个工具列表，供后续使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b8e8e710",
      "metadata": {},
      "outputs": [],
      "source": [
        "const tools = [search, retrieverTool];"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00068b0",
      "metadata": {},
      "source": [
        "## 使用语言模型\n",
        "\n",
        "接下来，让我们学习如何通过调用工具来使用语言模型。LangChain 支持许多不同的语言模型，你可以根据需要进行替换——在下方选择你要使用的模型！\n",
        "\n",
        "```{=mdx}\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs openaiParams={`{ model: \"gpt-4\" }`} />\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642ed8bf",
      "metadata": {},
      "source": [
        "你可以通过传入消息列表来调用语言模型。默认情况下，响应是一个 `content` 字符串。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "def033a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "// @lc-docs-hide-cell\n",
        "\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const model = new ChatOpenAI({ model: \"gpt-4o-mini\", temperature: 0 })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c96c960b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[32m\"Hello! How can I assist you today?\"\u001b[39m"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "const response = await model.invoke([{\n",
        "  role: \"user\",\n",
        "  content: \"hi!\"\n",
        "}]);\n",
        "\n",
        "response.content;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47bf8210",
      "metadata": {},
      "source": [
        "我们现在可以看看如何让此模型能够调用工具。为了实现这一点，我们使用 `.bind` 方法，使语言模型了解这些工具"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ba692a74",
      "metadata": {},
      "outputs": [],
      "source": [
        "const modelWithTools = model.bindTools(tools);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd920b69",
      "metadata": {},
      "source": [
        "现在我们可以调用模型了。让我们首先用一条普通消息调用它，看看它是如何响应的。我们可以同时查看`content`字段和`tool_calls`字段。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b6a7e925",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: Hello! How can I assist you today?\n",
            "Tool calls: \n"
          ]
        }
      ],
      "source": [
        "const responseWithTools = await modelWithTools.invoke([{\n",
        "  role: \"user\",\n",
        "  content: \"Hi!\"\n",
        "}])\n",
        "\n",
        "console.log(`Content: ${responseWithTools.content}`)\n",
        "console.log(`Tool calls: ${responseWithTools.tool_calls}`)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c81e76",
      "metadata": {},
      "source": [
        "现在，让我们尝试用一些需要调用工具的输入来调用它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "688b465d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: \n",
            "Tool calls: [\n",
            "  {\n",
            "    \"name\": \"tavily_search_results_json\",\n",
            "    \"args\": {\n",
            "      \"input\": \"current weather in San Francisco\"\n",
            "    },\n",
            "    \"type\": \"tool_call\",\n",
            "    \"id\": \"call_gtJ5rrjXswO8EIvePrxyGQbR\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "const responseWithToolCalls = await modelWithTools.invoke([{\n",
        "  role: \"user\",\n",
        "  content: \"What's the weather in SF?\"\n",
        "}])\n",
        "\n",
        "console.log(`Content: ${responseWithToolCalls.content}`)\n",
        "console.log(`Tool calls: ${JSON.stringify(responseWithToolCalls.tool_calls, null, 2)}`)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c4bcd3",
      "metadata": {},
      "source": [
        "我们可以看到现在没有内容，但有一个工具调用！它要求我们调用 Tavily 搜索工具。\n",
        "\n",
        "这还没有真正调用该工具——它只是告诉我们应该调用。为了实际调用它，我们需要创建我们的代理。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ccec80",
      "metadata": {},
      "source": [
        "## 创建代理\n",
        "\n",
        "既然我们已经定义了工具和LLM，现在可以创建代理了。我们将使用一个工具调用代理——有关此类代理以及其他选项的更多信息，请参阅[此指南](/docs/concepts/agents/)。\n",
        "\n",
        "我们可以首先选择用于引导代理的提示词："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "af83d3e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  SystemMessagePromptTemplate {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      prompt: PromptTemplate {\n",
            "        lc_serializable: true,\n",
            "        lc_kwargs: {\n",
            "          inputVariables: [],\n",
            "          templateFormat: \"f-string\",\n",
            "          template: \"You are a helpful assistant\"\n",
            "        },\n",
            "        lc_runnable: true,\n",
            "        name: undefined,\n",
            "        lc_namespace: [ \"langchain_core\", \"prompts\", \"prompt\" ],\n",
            "        inputVariables: [],\n",
            "        outputParser: undefined,\n",
            "        partialVariables: undefined,\n",
            "        templateFormat: \"f-string\",\n",
            "        template: \"You are a helpful assistant\",\n",
            "        validateTemplate: true,\n",
            "        additionalContentFields: undefined\n",
            "      }\n",
            "    },\n",
            "    lc_runnable: true,\n",
            "    name: undefined,\n",
            "    lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
            "    inputVariables: [],\n",
            "    additionalOptions: {},\n",
            "    prompt: PromptTemplate {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: {\n",
            "        inputVariables: [],\n",
            "        templateFormat: \"f-string\",\n",
            "        template: \"You are a helpful assistant\"\n",
            "      },\n",
            "      lc_runnable: true,\n",
            "      name: undefined,\n",
            "      lc_namespace: [ \"langchain_core\", \"prompts\", \"prompt\" ],\n",
            "      inputVariables: [],\n",
            "      outputParser: undefined,\n",
            "      partialVariables: undefined,\n",
            "      templateFormat: \"f-string\",\n",
            "      template: \"You are a helpful assistant\",\n",
            "      validateTemplate: true,\n",
            "      additionalContentFields: undefined\n",
            "    },\n",
            "    messageClass: undefined,\n",
            "    chatMessageClass: undefined\n",
            "  },\n",
            "  MessagesPlaceholder {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: { variableName: \"chat_history\", optional: true },\n",
            "    lc_runnable: true,\n",
            "    name: undefined,\n",
            "    lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
            "    variableName: \"chat_history\",\n",
            "    optional: true\n",
            "  },\n",
            "  HumanMessagePromptTemplate {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: {\n",
            "      prompt: PromptTemplate {\n",
            "        lc_serializable: true,\n",
            "        lc_kwargs: {\n",
            "          inputVariables: [Array],\n",
            "          templateFormat: \"f-string\",\n",
            "          template: \"{input}\"\n",
            "        },\n",
            "        lc_runnable: true,\n",
            "        name: undefined,\n",
            "        lc_namespace: [ \"langchain_core\", \"prompts\", \"prompt\" ],\n",
            "        inputVariables: [ \"input\" ],\n",
            "        outputParser: undefined,\n",
            "        partialVariables: undefined,\n",
            "        templateFormat: \"f-string\",\n",
            "        template: \"{input}\",\n",
            "        validateTemplate: true,\n",
            "        additionalContentFields: undefined\n",
            "      }\n",
            "    },\n",
            "    lc_runnable: true,\n",
            "    name: undefined,\n",
            "    lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
            "    inputVariables: [ \"input\" ],\n",
            "    additionalOptions: {},\n",
            "    prompt: PromptTemplate {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: {\n",
            "        inputVariables: [ \"input\" ],\n",
            "        templateFormat: \"f-string\",\n",
            "        template: \"{input}\"\n",
            "      },\n",
            "      lc_runnable: true,\n",
            "      name: undefined,\n",
            "      lc_namespace: [ \"langchain_core\", \"prompts\", \"prompt\" ],\n",
            "      inputVariables: [ \"input\" ],\n",
            "      outputParser: undefined,\n",
            "      partialVariables: undefined,\n",
            "      templateFormat: \"f-string\",\n",
            "      template: \"{input}\",\n",
            "      validateTemplate: true,\n",
            "      additionalContentFields: undefined\n",
            "    },\n",
            "    messageClass: undefined,\n",
            "    chatMessageClass: undefined\n",
            "  },\n",
            "  MessagesPlaceholder {\n",
            "    lc_serializable: true,\n",
            "    lc_kwargs: { variableName: \"agent_scratchpad\", optional: true },\n",
            "    lc_runnable: true,\n",
            "    name: undefined,\n",
            "    lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
            "    variableName: \"agent_scratchpad\",\n",
            "    optional: true\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "\n",
        "const prompt = ChatPromptTemplate.fromMessages([\n",
        "  [\"system\", \"You are a helpful assistant\"],\n",
        "  [\"placeholder\", \"{chat_history}\"],\n",
        "  [\"human\", \"{input}\"],\n",
        "  [\"placeholder\", \"{agent_scratchpad}\"],\n",
        "]);\n",
        "\n",
        "console.log(prompt.promptMessages);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8014c9d",
      "metadata": {},
      "source": [
        "现在，我们可以使用LLM、提示词和工具来初始化代理。代理负责接收输入并决定采取什么操作。关键的是，代理不会执行这些操作——这些操作是由AgentExecutor（下一步）完成的。关于如何理解这些组件的更多信息，请参阅我们的[概念指南](/docs/concepts/agents)。\n",
        "\n",
        "请注意，我们传递的是`model`而不是`modelWithTools`。这是因为`createToolCallingAgent`将在底层为我们调用`.bind`方法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "89cf72b4-6046-4b47-8f27-5522d8cb8036",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { createToolCallingAgent } from \"langchain/agents\";\n",
        "\n",
        "const agent = await createToolCallingAgent({ llm: model, tools, prompt })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a58c9f8",
      "metadata": {},
      "source": [
        "最后，我们将代理（大脑）与AgentExecutor中的工具结合在一起（它将重复调用代理并执行工具）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ce33904a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { AgentExecutor } from \"langchain/agents\";\n",
        "\n",
        "const agentExecutor = new AgentExecutor({\n",
        "  agent,\n",
        "  tools\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4df0e06",
      "metadata": {},
      "source": [
        "## 运行智能体\n",
        "\n",
        "现在我们可以在一些查询上运行该智能体！请注意，目前这些查询都是**无状态**的（它不会记住之前的交互）。\n",
        "\n",
        "首先，我们来看看在不需要调用工具的情况下它是如何响应的："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "114ba50d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{ input: \u001b[32m\"hi!\"\u001b[39m, output: \u001b[32m\"Hello! How can I assist you today?\"\u001b[39m }"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await agentExecutor.invoke({ input: \"hi!\" })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71493a42",
      "metadata": {},
      "source": [
        "为了准确了解幕后发生的事情（并确保它没有调用工具），我们可以查看[LangSmith 跟踪](https://smith.langchain.com/public/b8051e80-14fd-4931-be0f-6416280bc500/r)\n",
        "\n",
        "现在我们尝试在一个应该调用检索器的示例上运行它"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3fa4780a",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  input: \u001b[32m\"how can langsmith help with testing?\"\u001b[39m,\n",
              "  output: \u001b[32m\"LangSmith can assist with testing in several ways, particularly for applications built using large l\"\u001b[39m... 1474 more characters\n",
              "}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await agentExecutor.invoke({ input: \"how can langsmith help with testing?\" })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d94242",
      "metadata": {},
      "source": [
        "让我们看一下 [LangSmith 追踪](https://smith.langchain.com/public/35bd4f0f-aa2f-4ac2-b9a9-89ce0ca306ca/r)，以确认它是否真的调用了该工具。\n",
        "\n",
        "现在让我们尝试一个需要调用搜索工具的例子："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "77c2f769",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  input: \u001b[32m\"whats the weather in sf?\"\u001b[39m,\n",
              "  output: \u001b[32m\"The current weather in San Francisco is as follows:\\n\"\u001b[39m +\n",
              "    \u001b[32m\"\\n\"\u001b[39m +\n",
              "    \u001b[32m\"- **Temperature**: 15.6°C (60.1°F)\\n\"\u001b[39m +\n",
              "    \u001b[32m\"- **Conditio\"\u001b[39m... 303 more characters\n",
              "}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await agentExecutor.invoke({ input: \"whats the weather in sf?\" })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c174f838",
      "metadata": {},
      "source": [
        "我们可以查看 [LangSmith 跟踪](https://smith.langchain.com/public/dfde6f46-0e7b-4dfe-813c-87d7bfb2ade5/r)，以确保它有效地调用了搜索工具。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022cbc8a",
      "metadata": {},
      "source": [
        "## 添加内存\n",
        "\n",
        "如前所述，此代理是无状态的。这意味着它不会记住之前的交互。为了赋予它记忆功能，我们需要传入之前的 `chat_history`。\n",
        "\n",
        "**注意**：由于我们使用的提示，输入变量需要称为 `chat_history`。如果我们使用不同的提示，可以更改变量名。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c4073e35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  input: \u001b[32m\"hi! my name is bob\"\u001b[39m,\n",
              "  chat_history: [],\n",
              "  output: \u001b[32m\"Hello Bob! How can I assist you today?\"\u001b[39m\n",
              "}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "// Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
        "await agentExecutor.invoke({ input: \"hi! my name is bob\", chat_history: [] })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "550e0c6e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  chat_history: [\n",
              "    { role: \u001b[32m\"user\"\u001b[39m, content: \u001b[32m\"hi! my name is bob\"\u001b[39m },\n",
              "    {\n",
              "      role: \u001b[32m\"assistant\"\u001b[39m,\n",
              "      content: \u001b[32m\"Hello Bob! How can I assist you today?\"\u001b[39m\n",
              "    }\n",
              "  ],\n",
              "  input: \u001b[32m\"what's my name?\"\u001b[39m,\n",
              "  output: \u001b[32m\"Your name is Bob. How can I help you today, Bob?\"\u001b[39m\n",
              "}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await agentExecutor.invoke(\n",
        "  {\n",
        "    chat_history: [\n",
        "      { role: \"user\", content: \"hi! my name is bob\" },\n",
        "      { role: \"assistant\", content: \"Hello Bob! How can I assist you today?\" },\n",
        "    ],\n",
        "    input: \"what's my name?\",\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b3bcf2",
      "metadata": {},
      "source": [
        "如果我们想自动跟踪这些消息，可以将其包装在RunnableWithMessageHistory中。\n",
        "\n",
        "由于我们有多个输入，我们需要指定两件事情：\n",
        "\n",
        "- `inputMessagesKey`：用于添加到对话历史记录的输入键。\n",
        "- `historyMessagesKey`：将加载的消息添加到的目标键。\n",
        "\n",
        "有关如何使用此功能的更多信息，请参阅[此指南](/docs/how_to/message_history)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8edd96e6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  input: \u001b[32m\"hi! I'm bob\"\u001b[39m,\n",
              "  chat_history: [\n",
              "    HumanMessage {\n",
              "      \"content\": \"hi! I'm bob\",\n",
              "      \"additional_kwargs\": {},\n",
              "      \"response_metadata\": {}\n",
              "    },\n",
              "    AIMessage {\n",
              "      \"content\": \"Hello Bob! How can I assist you today?\",\n",
              "      \"additional_kwargs\": {},\n",
              "      \"response_metadata\": {},\n",
              "      \"tool_calls\": [],\n",
              "      \"invalid_tool_calls\": []\n",
              "    }\n",
              "  ],\n",
              "  output: \u001b[32m\"Hello Bob! How can I assist you today?\"\u001b[39m\n",
              "}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import { ChatMessageHistory } from \"@langchain/community/stores/message/in_memory\";\n",
        "import { BaseChatMessageHistory } from \"@langchain/core/chat_history\";\n",
        "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
        "\n",
        "const store = {};\n",
        "\n",
        "function getMessageHistory(sessionId: string): BaseChatMessageHistory {\n",
        "  if (!(sessionId in store)) {\n",
        "    store[sessionId] = new ChatMessageHistory();\n",
        "  }\n",
        "  return store[sessionId];\n",
        "}\n",
        "\n",
        "const agentWithChatHistory = new RunnableWithMessageHistory({\n",
        "  runnable: agentExecutor,\n",
        "  getMessageHistory,\n",
        "  inputMessagesKey: \"input\",\n",
        "  historyMessagesKey: \"chat_history\",\n",
        "})\n",
        "\n",
        "await agentWithChatHistory.invoke(\n",
        "  { input: \"hi! I'm bob\" },\n",
        "  { configurable: { sessionId: \"<foo>\" }},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ae627966",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  input: \u001b[32m\"what's my name?\"\u001b[39m,\n",
              "  chat_history: [\n",
              "    HumanMessage {\n",
              "      \"content\": \"hi! I'm bob\",\n",
              "      \"additional_kwargs\": {},\n",
              "      \"response_metadata\": {}\n",
              "    },\n",
              "    AIMessage {\n",
              "      \"content\": \"Hello Bob! How can I assist you today?\",\n",
              "      \"additional_kwargs\": {},\n",
              "      \"response_metadata\": {},\n",
              "      \"tool_calls\": [],\n",
              "      \"invalid_tool_calls\": []\n",
              "    },\n",
              "    HumanMessage {\n",
              "      \"content\": \"what's my name?\",\n",
              "      \"additional_kwargs\": {},\n",
              "      \"response_metadata\": {}\n",
              "    },\n",
              "    AIMessage {\n",
              "      \"content\": \"Your name is Bob! How can I help you today, Bob?\",\n",
              "      \"additional_kwargs\": {},\n",
              "      \"response_metadata\": {},\n",
              "      \"tool_calls\": [],\n",
              "      \"invalid_tool_calls\": []\n",
              "    }\n",
              "  ],\n",
              "  output: \u001b[32m\"Your name is Bob! How can I help you today, Bob?\"\u001b[39m\n",
              "}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await agentWithChatHistory.invoke(\n",
        "  { input: \"what's my name?\" },\n",
        "  { configurable: { sessionId: \"<foo>\" }},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de2798e",
      "metadata": {},
      "source": [
        "示例 LangSmith 追踪：https://smith.langchain.com/public/98c8d162-60ae-4493-aa9f-992d87bd0429/r"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c029798f",
      "metadata": {},
      "source": [
        "## 下一步\n",
        "\n",
        "本快速入门到此结束！我们介绍了如何创建一个简单的智能体（agent）。智能体是一个复杂的主题，还有很多内容需要学习！\n",
        "\n",
        ":::{.callout-important}\n",
        "本节介绍了使用 LangChain 智能体进行构建。LangChain 智能体适合入门使用，但在达到一定阶段后，你可能会需要它们无法提供的灵活性和控制能力。对于更高级的智能体开发，我们建议你查看 [LangGraph](https://langchain-ai.github.io/langgraphjs)。\n",
        "\n",
        "你也可以查看[这份迁移到 LangGraph 的指南](/docs/how_to/migrate_agent)。\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nb_converter": "script",
      "pygments_lexer": "typescript",
      "version": "5.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}