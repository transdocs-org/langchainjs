{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# å¦‚ä½•æµå¼ä¼ è¾“\n",
        "\n",
        ":::info é¢„å¤‡çŸ¥è¯†\n",
        "\n",
        "æœ¬æŒ‡å—å‡å®šæ‚¨ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š\n",
        "\n",
        "- [èŠå¤©æ¨¡å‹](/docs/concepts/chat_models)\n",
        "- [LangChain è¡¨è¾¾è¯­è¨€](/docs/concepts/lcel)\n",
        "- [è¾“å‡ºè§£æå™¨](/docs/concepts/output_parsers)\n",
        "\n",
        ":::\n",
        "\n",
        "æµå¼ä¼ è¾“å¯¹äºä½¿åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨ç¨‹åºå¯¹æœ€ç»ˆç”¨æˆ·å…·æœ‰å“åº”æ€§è‡³å…³é‡è¦ã€‚\n",
        "\n",
        "åƒ LLMã€è§£æå™¨ã€æç¤ºè¯ã€æ£€ç´¢å™¨å’Œä»£ç†è¿™æ ·çš„é‡è¦ LangChain åŸè¯­å®ç°äº† LangChain çš„ Runnable æ¥å£ã€‚\n",
        "\n",
        "è¯¥æ¥å£æä¾›äº†ä¸¤ç§é€šç”¨çš„æµå¼ä¼ è¾“æ–¹æ³•ï¼š\n",
        "\n",
        "- `.stream()`ï¼šæµå¼ä¼ è¾“çš„é»˜è®¤å®ç°ï¼Œç”¨äºä»é“¾ä¸­æµå¼ä¼ è¾“æœ€ç»ˆè¾“å‡ºã€‚\n",
        "- `streamEvents()` å’Œ `streamLog()`ï¼šè¿™äº›æ–¹æ³•å¯ä»¥åŒæ—¶æµå¼ä¼ è¾“é“¾ä¸­çš„ä¸­é—´æ­¥éª¤å’Œæœ€ç»ˆè¾“å‡ºã€‚\n",
        "\n",
        "è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸¤ç§æ–¹æ³•ï¼\n",
        "\n",
        ":::info\n",
        "æœ‰å…³ LangChain ä¸­æµå¼ä¼ è¾“æŠ€æœ¯çš„æ›´é«˜å±‚æ¬¡æ¦‚è¿°ï¼Œè¯·å‚é˜…[æ¦‚å¿µæŒ‡å—çš„è¿™ä¸€éƒ¨åˆ†](/docs/concepts/streaming)ã€‚\n",
        ":::\n",
        "\n",
        "# ä½¿ç”¨ Stream\n",
        "\n",
        "æ‰€æœ‰ `Runnable` å¯¹è±¡éƒ½å®ç°äº†ä¸€ä¸ªåä¸º stream çš„æ–¹æ³•ã€‚\n",
        "\n",
        "è¿™äº›æ–¹æ³•æ—¨åœ¨ä»¥åˆ†å—çš„å½¢å¼æµå¼ä¼ è¾“æœ€ç»ˆè¾“å‡ºï¼Œä¸€æ—¦æœ‰å¯ç”¨çš„åˆ†å—å°±ç«‹å³ç”Ÿæˆè¯¥åˆ†å—ã€‚\n",
        "\n",
        "åªæœ‰å½“ç¨‹åºä¸­çš„æ‰€æœ‰æ­¥éª¤éƒ½çŸ¥é“å¦‚ä½•å¤„ç†**è¾“å…¥æµ**æ—¶ï¼Œæ‰èƒ½å®ç°æµå¼ä¼ è¾“ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œé€ä¸ªå¤„ç†è¾“å…¥åˆ†å—ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è¾“å‡ºåˆ†å—ã€‚\n",
        "\n",
        "è¿™ç§å¤„ç†çš„å¤æ‚æ€§å¯èƒ½å„ä¸ç›¸åŒï¼Œä»åƒè¾“å‡ºç”± LLM ç”Ÿæˆçš„ token è¿™æ ·ç®€å•çš„ä»»åŠ¡ï¼Œåˆ°åƒåœ¨å®Œæ•´ JSON å®Œæˆä¹‹å‰æµå¼ä¼ è¾“ JSON éƒ¨åˆ†è¿™æ ·æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚\n",
        "\n",
        "æ¢ç´¢æµå¼ä¼ è¾“çš„æœ€ä½³èµ·ç‚¹æ˜¯ LLM åº”ç”¨ä¸­æœ€é‡è¦çš„ç»„ä»¶ä¹‹ä¸€ â€”â€” æ¨¡å‹æœ¬èº«ï¼\n",
        "\n",
        "## LLM å’ŒèŠå¤©æ¨¡å‹\n",
        "\n",
        "å¤§å‹è¯­è¨€æ¨¡å‹å¯èƒ½éœ€è¦å‡ ç§’é’Ÿæ‰èƒ½ç”Ÿæˆå¯¹æŸ¥è¯¢çš„å®Œæ•´å“åº”ã€‚è¿™è¿œæ…¢äºåº”ç”¨ç¨‹åºå¯¹æœ€ç»ˆç”¨æˆ·å…·æœ‰å“åº”æ€§çš„**~200-300 æ¯«ç§’**é˜ˆå€¼ã€‚\n",
        "\n",
        "è®©åº”ç”¨ç¨‹åºæ„Ÿè§‰æ›´å…·å“åº”æ€§çš„å…³é”®ç­–ç•¥æ˜¯æ˜¾ç¤ºä¸­é—´è¿›åº¦ï¼›ä¾‹å¦‚ï¼Œé€ä¸ª token åœ°æµå¼ä¼ è¾“æ¨¡å‹çš„è¾“å‡ºã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import \"dotenv/config\";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=mdx}\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs />\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// @lc-docs-hide-cell\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const model = new ChatOpenAI({\n",
        "  model: \"gpt-4o\",\n",
        "  temperature: 0,\n",
        "});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|\n",
            "Hello|\n",
            "!|\n",
            " I'm|\n",
            " a|\n",
            " large|\n",
            " language|\n",
            " model|\n",
            " developed|\n",
            " by|\n",
            " Open|\n",
            "AI|\n",
            " called|\n",
            " GPT|\n",
            "-|\n",
            "4|\n",
            ",|\n",
            " based|\n",
            " on|\n",
            " the|\n",
            " Gener|\n",
            "ative|\n",
            " Pre|\n",
            "-trained|\n",
            " Transformer|\n",
            " architecture|\n",
            ".|\n",
            " I'm|\n",
            " designed|\n",
            " to|\n",
            " understand|\n",
            " and|\n",
            " generate|\n",
            " human|\n",
            "-like|\n",
            " text|\n",
            " based|\n",
            " on|\n",
            " the|\n",
            " input|\n",
            " I|\n",
            " receive|\n",
            ".|\n",
            " My|\n",
            " primary|\n",
            " function|\n",
            " is|\n",
            " to|\n",
            " assist|\n",
            " with|\n",
            " answering|\n",
            " questions|\n",
            ",|\n",
            " providing|\n",
            " information|\n",
            ",|\n",
            " and|\n",
            " engaging|\n",
            " in|\n",
            " various|\n",
            " types|\n",
            " of|\n",
            " conversations|\n",
            ".|\n",
            " While|\n",
            " I|\n",
            " don't|\n",
            " have|\n",
            " personal|\n",
            " experiences|\n",
            " or|\n",
            " emotions|\n",
            ",|\n",
            " I'm|\n",
            " trained|\n",
            " on|\n",
            " diverse|\n",
            " datasets|\n",
            " that|\n",
            " enable|\n",
            " me|\n",
            " to|\n",
            " provide|\n",
            " useful|\n",
            " and|\n",
            " relevant|\n",
            " information|\n",
            " across|\n",
            " a|\n",
            " wide|\n",
            " array|\n",
            " of|\n",
            " topics|\n",
            ".|\n",
            " How|\n",
            " can|\n",
            " I|\n",
            " assist|\n",
            " you|\n",
            " today|\n",
            "?|\n",
            "|\n",
            "|\n"
          ]
        }
      ],
      "source": [
        "const stream = await model.stream(\"Hello! Tell me about yourself.\");\n",
        "const chunks = [];\n",
        "for await (const chunk of stream) {\n",
        "  chunks.push(chunk);\n",
        "  console.log(`${chunk.content}|`)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å…¶ä¸­ä¸€ä¸ªåŸå§‹æ•°æ®å—ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessageChunk {\n",
            "  lc_serializable: true,\n",
            "  lc_kwargs: {\n",
            "    content: '',\n",
            "    tool_call_chunks: [],\n",
            "    additional_kwargs: {},\n",
            "    id: 'chatcmpl-9lO8YUEcX7rqaxxevelHBtl1GaWoo',\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: [],\n",
            "    response_metadata: {}\n",
            "  },\n",
            "  lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "  content: '',\n",
            "  name: undefined,\n",
            "  additional_kwargs: {},\n",
            "  response_metadata: { prompt: 0, completion: 0, finish_reason: null },\n",
            "  id: 'chatcmpl-9lO8YUEcX7rqaxxevelHBtl1GaWoo',\n",
            "  tool_calls: [],\n",
            "  invalid_tool_calls: [],\n",
            "  tool_call_chunks: [],\n",
            "  usage_metadata: undefined\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "chunks[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªåä¸º `AIMessageChunk` çš„å¯¹è±¡ã€‚è¿™ä¸ª chunk ä»£è¡¨äº† `AIMessage` çš„ä¸€éƒ¨åˆ†ã€‚\n",
        "\n",
        "æ¶ˆæ¯å—åœ¨è®¾è®¡ä¸Šæ˜¯å¯ç´¯åŠ çš„â€”â€”å¯ä»¥ç®€å•åœ°ä½¿ç”¨ `.concat()` æ–¹æ³•å°†å®ƒä»¬ç›¸åŠ ï¼Œä»¥è·å¾—åˆ°ç›®å‰ä¸ºæ­¢çš„å“åº”çŠ¶æ€ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIMessageChunk {\n",
            "  lc_serializable: true,\n",
            "  lc_kwargs: {\n",
            "    content: \"Hello! I'm a\",\n",
            "    additional_kwargs: {},\n",
            "    response_metadata: { prompt: 0, completion: 0, finish_reason: null },\n",
            "    tool_call_chunks: [],\n",
            "    id: 'chatcmpl-9lO8YUEcX7rqaxxevelHBtl1GaWoo',\n",
            "    tool_calls: [],\n",
            "    invalid_tool_calls: []\n",
            "  },\n",
            "  lc_namespace: [ 'langchain_core', 'messages' ],\n",
            "  content: \"Hello! I'm a\",\n",
            "  name: undefined,\n",
            "  additional_kwargs: {},\n",
            "  response_metadata: { prompt: 0, completion: 0, finish_reason: null },\n",
            "  id: 'chatcmpl-9lO8YUEcX7rqaxxevelHBtl1GaWoo',\n",
            "  tool_calls: [],\n",
            "  invalid_tool_calls: [],\n",
            "  tool_call_chunks: [],\n",
            "  usage_metadata: undefined\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "let finalChunk = chunks[0];\n",
        "\n",
        "for (const chunk of chunks.slice(1, 5)) {\n",
        "  finalChunk = finalChunk.concat(chunk);\n",
        "}\n",
        "\n",
        "finalChunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## é“¾ï¼ˆChainsï¼‰\n",
        "\n",
        "å®é™…ä¸Šï¼Œå‡ ä¹æ‰€æœ‰LLMåº”ç”¨ç¨‹åºéƒ½åŒ…å«å¤šä¸ªæ­¥éª¤ï¼Œè€Œä¸ä»…ä»…æ˜¯è°ƒç”¨è¯­è¨€æ¨¡å‹ã€‚\n",
        "\n",
        "è®©æˆ‘ä»¬ä½¿ç”¨`LangChainè¡¨è¾¾å¼è¯­è¨€`ï¼ˆ`LCEL`ï¼‰æ„å»ºä¸€ä¸ªç®€å•çš„é“¾ï¼Œå°†æç¤ºï¼ˆpromptï¼‰ã€æ¨¡å‹å’Œè§£æå™¨ï¼ˆparserï¼‰ç»„åˆåœ¨ä¸€èµ·ï¼Œå¹¶éªŒè¯æµå¼ä¼ è¾“æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚\n",
        "\n",
        "æˆ‘ä»¬å°†ä½¿ç”¨`StringOutputParser`æ¥è§£ææ¨¡å‹çš„è¾“å‡ºã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå¯ä»¥ä»`AIMessageChunk`ä¸­æå–å†…å®¹å­—æ®µï¼Œä»è€Œè·å–æ¨¡å‹è¿”å›çš„`token`ã€‚\n",
        "\n",
        ":::{.callout-tip}\n",
        "LCELæ˜¯ä¸€ç§å£°æ˜å¼æ–¹æ³•ï¼Œé€šè¿‡å°†ä¸åŒçš„LangChainåŸºæœ¬ç»„ä»¶ä¸²è”èµ·æ¥ï¼Œä»¥æŒ‡å®šä¸€ä¸ªâ€œç¨‹åºâ€ã€‚ä½¿ç”¨LCELåˆ›å»ºçš„é“¾å¯ä»¥è‡ªåŠ¨å®ç°æµï¼ˆstreamï¼‰åŠŸèƒ½ï¼Œä»è€Œå…è®¸æµå¼ä¼ è¾“æœ€ç»ˆè¾“å‡ºã€‚äº‹å®ä¸Šï¼Œä½¿ç”¨LCELåˆ›å»ºçš„é“¾å®ç°äº†å®Œæ•´çš„æ ‡å‡†Runnableæ¥å£ã€‚\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|\n",
            "Sure|\n",
            ",|\n",
            " here's|\n",
            " a|\n",
            " joke|\n",
            " for|\n",
            " you|\n",
            ":\n",
            "\n",
            "|\n",
            "Why|\n",
            " did|\n",
            " the|\n",
            " par|\n",
            "rot|\n",
            " sit|\n",
            " on|\n",
            " the|\n",
            " stick|\n",
            "?\n",
            "\n",
            "|\n",
            "Because|\n",
            " it|\n",
            " wanted|\n",
            " to|\n",
            " be|\n",
            " a|\n",
            " \"|\n",
            "pol|\n",
            "ly|\n",
            "-stick|\n",
            "-al|\n",
            "\"|\n",
            " observer|\n",
            "!|\n",
            "|\n",
            "|\n"
          ]
        }
      ],
      "source": [
        "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "\n",
        "const prompt = ChatPromptTemplate.fromTemplate(\"Tell me a joke about {topic}\");\n",
        "\n",
        "const parser = new StringOutputParser();\n",
        "\n",
        "const chain = prompt.pipe(model).pipe(parser);\n",
        "\n",
        "const stream = await chain.stream({\n",
        "  topic: \"parrot\",\n",
        "});\n",
        "\n",
        "for await (const chunk of stream) {\n",
        "  console.log(`${chunk}|`)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-note}\n",
        "æ‚¨ä¸å¿…ä½¿ç”¨ `LangChain è¡¨è¾¾è¯­è¨€` æ¥ä½¿ç”¨ LangChainï¼Œè€Œæ˜¯å¯ä»¥é€šè¿‡ä»¥æ ‡å‡†çš„ **å‘½ä»¤å¼** ç¼–ç¨‹æ–¹å¼ï¼Œ\n",
        "å•ç‹¬è°ƒç”¨æ¯ä¸ªç»„ä»¶çš„ `invoke`ã€`batch` æˆ– `stream` æ–¹æ³•ï¼Œå°†ç»“æœèµ‹å€¼ç»™å˜é‡ï¼Œç„¶åæ ¹æ®éœ€è¦åœ¨åç»­æµç¨‹ä¸­ä½¿ç”¨è¿™äº›å˜é‡ã€‚\n",
        "\n",
        "å¦‚æœè¿™ç§æ–¹å¼èƒ½æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼Œé‚£å¯¹æˆ‘ä»¬æ¥è¯´å®Œå…¨æ²¡é—®é¢˜ ğŸ‘Œï¼\n",
        ":::\n",
        "\n",
        "### å¤„ç†è¾“å…¥æµ\n",
        "\n",
        "å¦‚æœæ‚¨æƒ³åœ¨ç”Ÿæˆ JSON æ•°æ®çš„åŒæ—¶å¯¹å…¶è¿›è¡Œæµå¼å¤„ç†ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\n",
        "\n",
        "å¦‚æœæ‚¨ä¾èµ– `JSON.parse` æ¥è§£æéƒ¨åˆ† JSON æ•°æ®ï¼Œè§£æä¼šå¤±è´¥ï¼Œå› ä¸ºéƒ¨åˆ† JSON å¹¶ä¸æ˜¯æœ‰æ•ˆçš„å®Œæ•´ JSONã€‚\n",
        "\n",
        "æ­¤æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šå®Œå…¨ä¸çŸ¥é“è¯¥å¦‚ä½•å¤„ç†ï¼Œå¹¶è®¤ä¸º JSON æµå¼ä¼ è¾“æ˜¯ä¸å¯èƒ½å®ç°çš„ã€‚\n",
        "\n",
        "å…¶å®ï¼Œæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹â€”â€”è§£æå™¨éœ€è¦åœ¨ **è¾“å…¥æµ** ä¸Šè¿›è¡Œæ“ä½œï¼Œå¹¶å°è¯•å°†éƒ¨åˆ† JSON \"è‡ªåŠ¨è¡¥å…¨\" æˆä¸ºä¸€ä¸ªæœ‰æ•ˆçš„çŠ¶æ€ã€‚\n",
        "\n",
        "è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ ·çš„è§£æå™¨æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥ä¾¿ç†è§£å…¶å«ä¹‰ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  countries: [\n",
            "    { name: 'France', population: 67390000 },\n",
            "    { name: 'Spain', population: 47350000 },\n",
            "    { name: 'Japan', population: 125800000 }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import { JsonOutputParser } from \"@langchain/core/output_parsers\"\n",
        "\n",
        "const chain = model.pipe(new JsonOutputParser());\n",
        "const stream = await chain.stream(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`\n",
        ");\n",
        "\n",
        "for await (const chunk of stream) {\n",
        "  console.log(chunk);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥**æ‰“ç ´**æµå¼ä¼ è¾“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å‰é¢çš„ä¾‹å­ï¼Œå¹¶åœ¨æœ«å°¾è¿½åŠ ä¸€ä¸ªæå–å‡½æ•°ï¼Œä»æœ€ç»ˆçš„ JSON ä¸­æå–å›½å®¶åç§°ã€‚ç”±äºè¿™ä¸ªæ–°çš„æœ€åä¸€æ­¥åªæ˜¯ä¸€ä¸ªæ²¡æœ‰å®šä¹‰æµå¼è¡Œä¸ºçš„å‡½æ•°è°ƒç”¨ï¼Œå› æ­¤å‰é¢æ­¥éª¤çš„æµå¼è¾“å‡ºä¼šè¢«èšåˆï¼Œç„¶åä½œä¸ºå•ä¸ªè¾“å…¥ä¼ é€’ç»™è¯¥å‡½æ•°ã€‚\n",
        "\n",
        ":::{.callout-warning}\n",
        "é“¾ä¸­ä»»ä½•å¯¹**æœ€ç»ˆè¾“å…¥**è€Œä¸æ˜¯å¯¹**è¾“å…¥æµ**è¿›è¡Œæ“ä½œçš„æ­¥éª¤ï¼Œéƒ½å¯èƒ½é€šè¿‡ `stream` æ‰“ç ´æµå¼ä¼ è¾“åŠŸèƒ½ã€‚\n",
        ":::\n",
        "\n",
        ":::{.callout-tip}\n",
        "ç¨åï¼Œæˆ‘ä»¬å°†è®¨è®º `streamEvents` APIï¼Œå®ƒå¯ä»¥æµå¼ä¼ è¾“ä¸­é—´æ­¥éª¤çš„ç»“æœã€‚å³ä½¿é“¾ä¸­åŒ…å«ä»…å¯¹**æœ€ç»ˆè¾“å…¥**è¿›è¡Œæ“ä½œçš„æ­¥éª¤ï¼Œè¯¥ API ä»èƒ½æµå¼ä¼ è¾“ä¸­é—´æ­¥éª¤çš„ç»“æœã€‚\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"France\",\"Spain\",\"Japan\"]\n"
          ]
        }
      ],
      "source": [
        "// A function that operates on finalized inputs\n",
        "// rather than on an input_stream\n",
        "\n",
        "// A function that does not operates on input streams and breaks streaming.\n",
        "const extractCountryNames = (inputs: Record<string, any>) => {\n",
        "  if (!Array.isArray(inputs.countries)) {\n",
        "    return \"\";\n",
        "  }\n",
        "  return JSON.stringify(inputs.countries.map((country) => country.name));\n",
        "}\n",
        "\n",
        "const chain = model.pipe(new JsonOutputParser()).pipe(extractCountryNames);\n",
        "\n",
        "const stream = await chain.stream(\n",
        "  `output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`\n",
        ");\n",
        "\n",
        "for await (const chunk of stream) {\n",
        "  console.log(chunk);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### éæµå¼ç»„ä»¶\n",
        "\n",
        "ä¸ä¸Šè¿°ç¤ºä¾‹ç±»ä¼¼ï¼Œä¸€äº›å†…ç½®ç»„ä»¶ï¼ˆå¦‚æ£€ç´¢å™¨ï¼‰ä¸æä¾›ä»»ä½•æµå¼ä¼ è¾“åŠŸèƒ½ã€‚å¦‚æœæˆ‘ä»¬å°è¯•å¯¹å®ƒä»¬è¿›è¡Œ `stream` æ“ä½œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  [\n",
            "    Document {\n",
            "      pageContent: 'mitochondria is the powerhouse of the cell',\n",
            "      metadata: {},\n",
            "      id: undefined\n",
            "    },\n",
            "    Document {\n",
            "      pageContent: 'buildings are made of brick',\n",
            "      metadata: {},\n",
            "      id: undefined\n",
            "    }\n",
            "  ]\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
        "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
        "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
        "\n",
        "const template = `Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "`;\n",
        "const prompt = ChatPromptTemplate.fromTemplate(template);\n",
        "\n",
        "const vectorstore = await MemoryVectorStore.fromTexts(\n",
        "  [\"mitochondria is the powerhouse of the cell\", \"buildings are made of brick\"],\n",
        "  [{}, {}],\n",
        "  new OpenAIEmbeddings(),\n",
        ");\n",
        "\n",
        "const retriever = vectorstore.asRetriever();\n",
        "\n",
        "const chunks = [];\n",
        "\n",
        "for await (const chunk of await retriever.stream(\"What is the powerhouse of the cell?\")) {\n",
        "  chunks.push(chunk);\n",
        "}\n",
        "\n",
        "console.log(chunks);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "æµåˆšåˆšä»è¯¥ç»„ä»¶ç”Ÿæˆæœ€ç»ˆç»“æœã€‚\n",
        "\n",
        "è¿™æ²¡é—®é¢˜ï¼å¹¶éæ‰€æœ‰ç»„ä»¶éƒ½å¿…é¡»å®ç°æµå¼ä¼ è¾“â€”â€”åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæµå¼ä¼ è¾“å¯èƒ½æ˜¯ä¸å¿…è¦çš„ã€å›°éš¾çš„ï¼Œæˆ–è€…æ ¹æœ¬æ²¡æœ‰æ„ä¹‰ã€‚\n",
        "\n",
        ":::{.callout-tip}\n",
        "ç”±æŸäº›éæµå¼ç»„ä»¶æ„å»ºçš„LCELé“¾åœ¨å¾ˆå¤šæƒ…å†µä¸‹ä»ç„¶èƒ½å¤Ÿè¿›è¡Œæµå¼ä¼ è¾“ï¼Œé“¾ä¸­æœ€åä¸€ä¸ªéæµå¼æ­¥éª¤ä¹‹åå°†å¼€å§‹éƒ¨åˆ†è¾“å‡ºçš„æµå¼ä¼ è¾“ã€‚\n",
        ":::\n",
        "\n",
        "ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|\n",
            "M|\n",
            "ito|\n",
            "ch|\n",
            "ond|\n",
            "ria|\n",
            " is|\n",
            " the|\n",
            " powerhouse|\n",
            " of|\n",
            " the|\n",
            " cell|\n",
            ".|\n",
            "|\n",
            "|\n"
          ]
        }
      ],
      "source": [
        "import { RunnablePassthrough, RunnableSequence } from \"@langchain/core/runnables\";\n",
        "import type { Document } from \"@langchain/core/documents\";\n",
        "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
        "\n",
        "const formatDocs = (docs: Document[]) => {\n",
        "  return docs.map((doc) => doc.pageContent).join(\"\\n-----\\n\")\n",
        "}\n",
        "\n",
        "const retrievalChain = RunnableSequence.from([\n",
        "  {\n",
        "    context: retriever.pipe(formatDocs),\n",
        "    question: new RunnablePassthrough()\n",
        "  },\n",
        "  prompt,\n",
        "  model,\n",
        "  new StringOutputParser(),\n",
        "]);\n",
        "\n",
        "const stream = await retrievalChain.stream(\"What is the powerhouse of the cell?\");\n",
        "\n",
        "for await (const chunk of stream) {\n",
        "  console.log(`${chunk}|`);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº† `stream` æ–¹æ³•çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬è¿›å…¥äº‹ä»¶æµçš„ä¸–ç•Œå§ï¼\n",
        "\n",
        "## ä½¿ç”¨æµäº‹ä»¶\n",
        "\n",
        "äº‹ä»¶æµæ˜¯ä¸€ä¸ª**æµ‹è¯•ç‰ˆ** APIã€‚è¯¥ API å¯èƒ½ä¼šæ ¹æ®åé¦ˆè¿›è¡Œä¸€äº›è°ƒæ•´ã€‚\n",
        "\n",
        ":::{.callout-note}\n",
        "åœ¨ @langchain/core **0.1.27** ä¸­å¼•å…¥ã€‚\n",
        ":::\n",
        "\n",
        "ä¸ºäº†è®© `streamEvents` æ–¹æ³•æ­£å¸¸å·¥ä½œï¼š\n",
        "\n",
        "* ä»»ä½•è‡ªå®šä¹‰å‡½æ•° / å¯è¿è¡Œå¯¹è±¡éƒ½å¿…é¡»ä¼ é€’å›è°ƒ\n",
        "* åœ¨æ¨¡å‹ä¸Šè®¾ç½®é€‚å½“çš„å‚æ•°ä»¥å¼ºåˆ¶ LLM æµå¼ä¼ è¾“ tokenã€‚\n",
        "* å¦‚æœæœ‰ä»»ä½•ä¸ç¬¦åˆé¢„æœŸçš„æƒ…å†µï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ï¼\n",
        "\n",
        "### äº‹ä»¶å‚è€ƒ\n",
        "\n",
        "ä»¥ä¸‹æ˜¯ä¸€ä¸ªå‚è€ƒè¡¨ï¼Œå±•ç¤ºäº†ä¸€äº›å¯è¿è¡Œå¯¹è±¡å¯èƒ½å‘å‡ºçš„äº‹ä»¶ã€‚\n",
        "\n",
        ":::{.callout-note}\n",
        "å½“æ­£ç¡®å®ç°æµå¼ä¼ è¾“æ—¶ï¼Œåœ¨è¾“å…¥æµå®Œå…¨è¢«æ¶ˆè´¹ä¹‹å‰ï¼Œå¯è¿è¡Œå¯¹è±¡çš„è¾“å…¥é€šå¸¸æ˜¯æœªçŸ¥çš„ã€‚è¿™æ„å‘³ç€ `inputs` é€šå¸¸åªä¼šåŒ…å«åœ¨ `end` äº‹ä»¶ä¸­ï¼Œè€Œä¸æ˜¯ `start` äº‹ä»¶ä¸­ã€‚\n",
        ":::\n",
        "\n",
        "| äº‹ä»¶                | åç§°             | æ•°æ®å—                           | è¾“å…¥                                         | è¾“å‡º                                          |\n",
        "|----------------------|------------------|---------------------------------|-----------------------------------------------|-------------------------------------------------|\n",
        "| on_llm_start         | [æ¨¡å‹åç§°]       |                                 | {'input': 'hello'}                            |                                                 |\n",
        "| on_llm_stream        | [æ¨¡å‹åç§°]       | 'Hello' `æˆ–` AIMessageChunk(content=\"hello\")  |                                               |                                   |\n",
        "| on_llm_end           | [æ¨¡å‹åç§°]       |                                 | 'Hello human!'                                | {\"ç”Ÿæˆå†…å®¹\": [...], \"æ¨¡å‹è¾“å‡º\": None, ...}  |\n",
        "| on_chain_start       | format_docs      |                                 |                                               |                                                 |\n",
        "| on_chain_stream      | format_docs      | \"hello world!, goodbye world!\"  |                                               |                                                 |\n",
        "| on_chain_end         | format_docs      |                                 | [Document(...)]                               | \"hello world!, goodbye world!\"                  |\n",
        "| on_tool_start        | some_tool        |                                 | {\"x\": 1, \"y\": \"2\"}                            |                                                 |\n",
        "| on_tool_stream       | some_tool        | {\"x\": 1, \"y\": \"2\"}              |                                               |                                                 |\n",
        "| on_tool_end          | some_tool        |                                 |                                               | {\"x\": 1, \"y\": \"2\"}                              |\n",
        "| on_retriever_start   | [æ£€ç´¢å™¨åç§°]     |                                 | {\"query\": \"hello\"}                            |                                                 |\n",
        "| on_retriever_chunk   | [æ£€ç´¢å™¨åç§°]     | {æ–‡æ¡£: [...]}                    |                                               |                                                 |\n",
        "| on_retriever_end     | [æ£€ç´¢å™¨åç§°]     |                                 | {\"query\": \"hello\"}                            | {æ–‡æ¡£: [...]}                              |\n",
        "| on_prompt_start      | [æ¨¡æ¿åç§°]       |                                 | {\"question\": \"hello\"}                         |                                                 |\n",
        "| on_prompt_end        | [æ¨¡æ¿åç§°]       |                                 | {\"question\": \"hello\"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |\n",
        "\n",
        "`streamEvents` åœ¨ `v2` ä¸­è¿˜å°†å‘å‡ºåˆ†å‘çš„è‡ªå®šä¹‰äº‹ä»¶ã€‚æ›´å¤šä¿¡æ¯è¯·å‚é˜…[æ­¤æŒ‡å—](/docs/how_to/callbacks_custom_events/)ã€‚\n",
        "\n",
        "### èŠå¤©æ¨¡å‹\n",
        "\n",
        "è®©æˆ‘ä»¬é¦–å…ˆçœ‹ä¸€ä¸‹èŠå¤©æ¨¡å‹äº§ç”Ÿçš„äº‹ä»¶ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n"
          ]
        }
      ],
      "source": [
        "const events = [];\n",
        "\n",
        "const eventStream = await model.streamEvents(\"hello\", { version: \"v2\" });\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  events.push(event);\n",
        "}\n",
        "\n",
        "console.log(events.length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-note}\n",
        "\n",
        "å˜¿ï¼ŒAPI ä¸­é‚£ä¸ªå¥‡æ€ªçš„ version=\"v2\" å‚æ•°æ˜¯ä»€ä¹ˆï¼Ÿï¼ ğŸ˜¾\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**æµ‹è¯•ç‰ˆ API**ï¼Œæˆ‘ä»¬å‡ ä¹è‚¯å®šä¼šå¯¹å…¶è¿›è¡Œä¸€äº›æ›´æ”¹ã€‚\n",
        "\n",
        "è¿™ä¸ªç‰ˆæœ¬å‚æ•°å°†å…è®¸æˆ‘ä»¬å°½é‡å‡å°‘å¯¹æ‚¨ä»£ç çš„ç ´åæ€§æ›´æ”¹ã€‚\n",
        "\n",
        "ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬ç°åœ¨æ‰“æ‰°ä¸€ä¸‹æ‚¨ï¼Œæ˜¯ä¸ºäº†ä»¥åä¸å†æ‰“æ‰°æ‚¨ã€‚\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹éƒ¨åˆ†å¼€å§‹äº‹ä»¶å’Œéƒ¨åˆ†ç»“æŸäº‹ä»¶ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    event: 'on_chat_model_start',\n",
            "    data: { input: 'hello' },\n",
            "    name: 'ChatOpenAI',\n",
            "    tags: [],\n",
            "    run_id: 'c983e634-9f1d-4916-97d8-63c3a86102c2',\n",
            "    metadata: {\n",
            "      ls_provider: 'openai',\n",
            "      ls_model_name: 'gpt-4o',\n",
            "      ls_model_type: 'chat',\n",
            "      ls_temperature: 1,\n",
            "      ls_max_tokens: undefined,\n",
            "      ls_stop: undefined\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    event: 'on_chat_model_stream',\n",
            "    data: { chunk: [AIMessageChunk] },\n",
            "    run_id: 'c983e634-9f1d-4916-97d8-63c3a86102c2',\n",
            "    name: 'ChatOpenAI',\n",
            "    tags: [],\n",
            "    metadata: {\n",
            "      ls_provider: 'openai',\n",
            "      ls_model_name: 'gpt-4o',\n",
            "      ls_model_type: 'chat',\n",
            "      ls_temperature: 1,\n",
            "      ls_max_tokens: undefined,\n",
            "      ls_stop: undefined\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    event: 'on_chat_model_stream',\n",
            "    run_id: 'c983e634-9f1d-4916-97d8-63c3a86102c2',\n",
            "    name: 'ChatOpenAI',\n",
            "    tags: [],\n",
            "    metadata: {\n",
            "      ls_provider: 'openai',\n",
            "      ls_model_name: 'gpt-4o',\n",
            "      ls_model_type: 'chat',\n",
            "      ls_temperature: 1,\n",
            "      ls_max_tokens: undefined,\n",
            "      ls_stop: undefined\n",
            "    },\n",
            "    data: { chunk: [AIMessageChunk] }\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "events.slice(0, 3);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    event: 'on_chat_model_stream',\n",
            "    run_id: 'c983e634-9f1d-4916-97d8-63c3a86102c2',\n",
            "    name: 'ChatOpenAI',\n",
            "    tags: [],\n",
            "    metadata: {\n",
            "      ls_provider: 'openai',\n",
            "      ls_model_name: 'gpt-4o',\n",
            "      ls_model_type: 'chat',\n",
            "      ls_temperature: 1,\n",
            "      ls_max_tokens: undefined,\n",
            "      ls_stop: undefined\n",
            "    },\n",
            "    data: { chunk: [AIMessageChunk] }\n",
            "  },\n",
            "  {\n",
            "    event: 'on_chat_model_end',\n",
            "    data: { output: [AIMessageChunk] },\n",
            "    run_id: 'c983e634-9f1d-4916-97d8-63c3a86102c2',\n",
            "    name: 'ChatOpenAI',\n",
            "    tags: [],\n",
            "    metadata: {\n",
            "      ls_provider: 'openai',\n",
            "      ls_model_name: 'gpt-4o',\n",
            "      ls_model_type: 'chat',\n",
            "      ls_temperature: 1,\n",
            "      ls_max_tokens: undefined,\n",
            "      ls_stop: undefined\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "events.slice(-2);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### é“¾å¼ç»“æ„\n",
        "\n",
        "è®©æˆ‘ä»¬é‡æ–°å®¡è§†è§£ææµå¼ JSON çš„ç¤ºä¾‹é“¾ï¼Œä»¥æ¢ç´¢æµå¼äº‹ä»¶ APIã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83\n"
          ]
        }
      ],
      "source": [
        "const chain = model.pipe(new JsonOutputParser());\n",
        "const eventStream = await chain.streamEvents(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "  { version: \"v2\" },\n",
        ");\n",
        "\n",
        "\n",
        "const events = [];\n",
        "for await (const event of eventStream) {\n",
        "  events.push(event);\n",
        "}\n",
        "\n",
        "console.log(events.length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "å¦‚æœæ‚¨æŸ¥çœ‹å‰å‡ ä¸ªäº‹ä»¶ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°æœ‰**3**ä¸ªä¸åŒçš„å¼€å§‹äº‹ä»¶ï¼Œè€Œä¸æ˜¯**2**ä¸ªå¼€å§‹äº‹ä»¶ã€‚\n",
        "\n",
        "è¿™ä¸‰ä¸ªå¼€å§‹äº‹ä»¶åˆ†åˆ«å¯¹åº”äºï¼š\n",
        "\n",
        "1. é“¾ï¼ˆæ¨¡å‹ + è§£æå™¨ï¼‰\n",
        "2. æ¨¡å‹\n",
        "3. è§£æå™¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    event: 'on_chain_start',\n",
            "    data: {\n",
            "      input: 'Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"'\n",
            "    },\n",
            "    name: 'RunnableSequence',\n",
            "    tags: [],\n",
            "    run_id: '5dd960b8-4341-4401-8993-7d04d49fcc08',\n",
            "    metadata: {}\n",
            "  },\n",
            "  {\n",
            "    event: 'on_chat_model_start',\n",
            "    data: { input: [Object] },\n",
            "    name: 'ChatOpenAI',\n",
            "    tags: [ 'seq:step:1' ],\n",
            "    run_id: '5d2917b1-886a-47a1-807d-8a0ba4cb4f65',\n",
            "    metadata: {\n",
            "      ls_provider: 'openai',\n",
            "      ls_model_name: 'gpt-4o',\n",
            "      ls_model_type: 'chat',\n",
            "      ls_temperature: 1,\n",
            "      ls_max_tokens: undefined,\n",
            "      ls_stop: undefined\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    event: 'on_parser_start',\n",
            "    data: {},\n",
            "    name: 'JsonOutputParser',\n",
            "    tags: [ 'seq:step:2' ],\n",
            "    run_id: '756c57d6-d455-484f-a556-79a82c4e1d40',\n",
            "    metadata: {}\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "events.slice(0, 3);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "å¦‚æœä½ æŸ¥çœ‹æœ€å3ä¸ªäº‹ä»¶ï¼Œä½ è§‰å¾—ä¼šçœ‹åˆ°ä»€ä¹ˆï¼Ÿä¸­é—´çš„äº‹ä»¶å‘¢ï¼Ÿ\n",
        "\n",
        "è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªAPIæ¥è¾“å‡ºæ¨¡å‹å’Œè§£æå™¨çš„æµäº‹ä»¶ã€‚æˆ‘ä»¬å¿½ç•¥å¼€å§‹äº‹ä»¶ã€ç»“æŸäº‹ä»¶ä»¥åŠæ¥è‡ªé“¾çš„äº‹ä»¶ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat model chunk: \n",
            "Chat model chunk: ```\n",
            "Chat model chunk: json\n",
            "Chat model chunk: \n",
            "\n",
            "Chat model chunk: {\n",
            "\n",
            "Chat model chunk:    \n",
            "Chat model chunk:  \"\n",
            "Chat model chunk: countries\n",
            "Chat model chunk: \":\n",
            "Chat model chunk:  [\n",
            "\n",
            "Chat model chunk:        \n",
            "Chat model chunk:  {\n",
            "\n",
            "Chat model chunk:            \n",
            "Chat model chunk:  \"\n",
            "Chat model chunk: name\n",
            "Chat model chunk: \":\n",
            "Chat model chunk:  \"\n",
            "Chat model chunk: France\n",
            "Chat model chunk: \",\n",
            "\n",
            "Chat model chunk:            \n",
            "Chat model chunk:  \"\n",
            "Chat model chunk: population\n",
            "Chat model chunk: \":\n",
            "Chat model chunk:  \n",
            "Chat model chunk: 652\n",
            "Chat model chunk: 735\n",
            "Chat model chunk: 11\n",
            "Chat model chunk: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "let eventCount = 0;\n",
        "\n",
        "const eventStream = await chain.streamEvents(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "  { version: \"v1\" },\n",
        ");\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  // Truncate the output\n",
        "  if (eventCount > 30) {\n",
        "    continue;\n",
        "  }\n",
        "  const eventType = event.event;\n",
        "  if (eventType === \"on_llm_stream\") {\n",
        "    console.log(`Chat model chunk: ${event.data.chunk.message.content}`);\n",
        "  } else if (eventType === \"on_parser_stream\") {\n",
        "    console.log(`Parser chunk: ${JSON.stringify(event.data.chunk)}`);\n",
        "  }\n",
        "  eventCount += 1;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ç”±äºæ¨¡å‹å’Œè§£æå™¨éƒ½æ”¯æŒæµå¼ä¼ è¾“ï¼Œæˆ‘ä»¬å¯ä»¥å®æ—¶çœ‹åˆ°æ¥è‡ªè¿™ä¸¤ä¸ªç»„ä»¶çš„æµå¼äº‹ä»¶ï¼å¾ˆæ•´æ´ï¼ğŸ¦œ\n",
        "\n",
        "### è¿‡æ»¤äº‹ä»¶\n",
        "\n",
        "ç”±äºæ­¤APIä¼šäº§ç”Ÿå¤§é‡äº‹ä»¶ï¼Œå› æ­¤èƒ½å¤ŸæŒ‰äº‹ä»¶è¿›è¡Œè¿‡æ»¤æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚\n",
        "\n",
        "ä½ å¯ä»¥é€šè¿‡ç»„ä»¶çš„`åç§°`ã€ç»„ä»¶çš„`æ ‡ç­¾`æˆ–ç»„ä»¶çš„`ç±»å‹`è¿›è¡Œè¿‡æ»¤ã€‚\n",
        "\n",
        "#### æŒ‰åç§°\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  event: 'on_parser_start',\n",
            "  data: {\n",
            "    input: 'Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"'\n",
            "  },\n",
            "  name: 'my_parser',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  run_id: '0a605976-a8f8-4259-8ef6-b3d7e52b3d4e',\n",
            "  metadata: {}\n",
            "}\n",
            "{\n",
            "  event: 'on_parser_stream',\n",
            "  run_id: '0a605976-a8f8-4259-8ef6-b3d7e52b3d4e',\n",
            "  name: 'my_parser',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {},\n",
            "  data: { chunk: { countries: [Array] } }\n",
            "}\n",
            "{\n",
            "  event: 'on_parser_end',\n",
            "  data: { output: { countries: [Array] } },\n",
            "  run_id: '0a605976-a8f8-4259-8ef6-b3d7e52b3d4e',\n",
            "  name: 'my_parser',\n",
            "  tags: [ 'seq:step:2' ],\n",
            "  metadata: {}\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const chain = model.withConfig({ runName: \"model\" })\n",
        "  .pipe(\n",
        "    new JsonOutputParser().withConfig({ runName: \"my_parser\" })\n",
        "  );\n",
        "\n",
        "\n",
        "const eventStream = await chain.streamEvents(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "  { version: \"v2\" },\n",
        "  { includeNames: [\"my_parser\"] },\n",
        ");\n",
        "\n",
        "let eventCount = 0;\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  // Truncate the output\n",
        "  if (eventCount > 10) {\n",
        "    continue;\n",
        "  }\n",
        "  console.log(event);\n",
        "  eventCount += 1;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### æŒ‰ç±»å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  event: 'on_chat_model_start',\n",
            "  data: {\n",
            "    input: 'Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"'\n",
            "  },\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '```',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'json',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '\\n',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '{\\n',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' ',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' \"',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'countries',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '\":',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' [\\n',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO98p55iuqUNwx4GZ6j2BkDak6Rr',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'fb6351eb-9537-445d-a1bd-24c2e11efd8e',\n",
            "  name: 'model',\n",
            "  tags: [ 'seq:step:1' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const chain = model.withConfig({ runName: \"model\" })\n",
        "  .pipe(\n",
        "    new JsonOutputParser().withConfig({ runName: \"my_parser\" })\n",
        "  );\n",
        "\n",
        "\n",
        "const eventStream = await chain.streamEvents(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "  { version: \"v2\" },\n",
        "  { includeTypes: [\"chat_model\"] },\n",
        ");\n",
        "\n",
        "let eventCount = 0;\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  // Truncate the output\n",
        "  if (eventCount > 10) {\n",
        "    continue;\n",
        "  }\n",
        "  console.log(event);\n",
        "  eventCount += 1;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### æŒ‰æ ‡ç­¾\n",
        "\n",
        ":::{.callout-caution}\n",
        "\n",
        "æ ‡ç­¾ä¼šè¢«ç»™å®šå¯è¿è¡Œç»„ä»¶çš„å­ç»„ä»¶ç»§æ‰¿ã€‚\n",
        "\n",
        "å¦‚æœæ‚¨ä½¿ç”¨æ ‡ç­¾è¿›è¡Œè¿‡æ»¤ï¼Œè¯·ç¡®ä¿è¿™æ˜¯æ‚¨æƒ³è¦çš„æ•ˆæœã€‚\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  event: 'on_chain_start',\n",
            "  data: {\n",
            "    input: 'Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"'\n",
            "  },\n",
            "  name: 'RunnableSequence',\n",
            "  tags: [ 'my_chain' ],\n",
            "  run_id: '1fed60d6-e0b7-4d5e-8ec7-cd7d3ee5c69f',\n",
            "  metadata: {}\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_start',\n",
            "  data: { input: { messages: [Array] } },\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_parser_start',\n",
            "  data: {},\n",
            "  name: 'my_parser',\n",
            "  tags: [ 'seq:step:2', 'my_chain' ],\n",
            "  run_id: 'caf24a1e-255c-4937-9f38-6e46275d854a',\n",
            "  metadata: {}\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: 'Certainly',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: '!',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: \" Here's\",\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' the',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' JSON',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' format',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n",
            "{\n",
            "  event: 'on_chat_model_stream',\n",
            "  data: {\n",
            "    chunk: AIMessageChunk {\n",
            "      lc_serializable: true,\n",
            "      lc_kwargs: [Object],\n",
            "      lc_namespace: [Array],\n",
            "      content: ' output',\n",
            "      name: undefined,\n",
            "      additional_kwargs: {},\n",
            "      response_metadata: [Object],\n",
            "      id: 'chatcmpl-9lO99nzUvCsZWCiq6vNtS1Soa1qNp',\n",
            "      tool_calls: [],\n",
            "      invalid_tool_calls: [],\n",
            "      tool_call_chunks: [],\n",
            "      usage_metadata: undefined\n",
            "    }\n",
            "  },\n",
            "  run_id: 'ecb99d6e-ce03-445f-aadf-73e6cbbc52fe',\n",
            "  name: 'ChatOpenAI',\n",
            "  tags: [ 'seq:step:1', 'my_chain' ],\n",
            "  metadata: {\n",
            "    ls_provider: 'openai',\n",
            "    ls_model_name: 'gpt-4o',\n",
            "    ls_model_type: 'chat',\n",
            "    ls_temperature: 1,\n",
            "    ls_max_tokens: undefined,\n",
            "    ls_stop: undefined\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "const chain = model\n",
        "  .pipe(new JsonOutputParser().withConfig({ runName: \"my_parser\" }))\n",
        "  .withConfig({ tags: [\"my_chain\"] });\n",
        "\n",
        "\n",
        "const eventStream = await chain.streamEvents(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "  { version: \"v2\" },\n",
        "  { includeTags: [\"my_chain\"] },\n",
        ");\n",
        "\n",
        "let eventCount = 0;\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  // Truncate the output\n",
        "  if (eventCount > 10) {\n",
        "    continue;\n",
        "  }\n",
        "  console.log(event);\n",
        "  eventCount += 1;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### é€šè¿‡HTTPæµå¼ä¼ è¾“äº‹ä»¶\n",
        "\n",
        "ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œ`streamEvents` æ”¯æŒå°†æµå¼ä¸­é—´äº‹ä»¶ç¼–ç ä¸ºHTTP [æœåŠ¡å™¨å‘é€äº‹ä»¶](https://developer.mozilla.org/zh-CN/docs/Web/API/Server-sent_events)ï¼Œä»¥å­—èŠ‚å½¢å¼è¿›è¡Œç¼–ç ã€‚ä»¥ä¸‹æ˜¯å…¶ä½¿ç”¨æ–¹å¼ï¼ˆä½¿ç”¨ [`TextDecoder`](https://developer.mozilla.org/zh-CN/docs/Web/API/TextDecoder) å°†äºŒè¿›åˆ¶æ•°æ®é‡æ–°è½¬æ¢ä¸ºå¯è¯»å­—ç¬¦ä¸²ï¼‰ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "event: data\n",
            "data: {\"event\":\"on_chain_start\",\"data\":{\"input\":\"Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \\\"countries\\\" which contains a list of countries. Each country should have the key \\\"name\\\" and \\\"population\\\"\"},\"name\":\"RunnableSequence\",\"tags\":[\"my_chain\"],\"run_id\":\"41cd92f8-9b8c-4365-8aa0-fda3abdae03d\",\"metadata\":{}}\n",
            "\n",
            "\n",
            "event: data\n",
            "data: {\"event\":\"on_chat_model_start\",\"data\":{\"input\":{\"messages\":[[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain_core\",\"messages\",\"HumanMessage\"],\"kwargs\":{\"content\":\"Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \\\"countries\\\" which contains a list of countries. Each country should have the key \\\"name\\\" and \\\"population\\\"\",\"additional_kwargs\":{},\"response_metadata\":{}}}]]}},\"name\":\"ChatOpenAI\",\"tags\":[\"seq:step:1\",\"my_chain\"],\"run_id\":\"a6c2bc61-c868-4570-a143-164e64529ee0\",\"metadata\":{\"ls_provider\":\"openai\",\"ls_model_name\":\"gpt-4o\",\"ls_model_type\":\"chat\",\"ls_temperature\":1}}\n",
            "\n",
            "\n",
            "event: data\n",
            "data: {\"event\":\"on_parser_start\",\"data\":{},\"name\":\"my_parser\",\"tags\":[\"seq:step:2\",\"my_chain\"],\"run_id\":\"402533c5-0e4e-425d-a556-c30a350972d0\",\"metadata\":{}}\n",
            "\n",
            "\n",
            "event: data\n",
            "data: {\"event\":\"on_chat_model_stream\",\"data\":{\"chunk\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain_core\",\"messages\",\"AIMessageChunk\"],\"kwargs\":{\"content\":\"\",\"tool_call_chunks\":[],\"additional_kwargs\":{},\"id\":\"chatcmpl-9lO9BAQwbKDy2Ou2RNFUVi0VunAsL\",\"tool_calls\":[],\"invalid_tool_calls\":[],\"response_metadata\":{\"prompt\":0,\"completion\":0,\"finish_reason\":null}}}},\"run_id\":\"a6c2bc61-c868-4570-a143-164e64529ee0\",\"name\":\"ChatOpenAI\",\"tags\":[\"seq:step:1\",\"my_chain\"],\"metadata\":{\"ls_provider\":\"openai\",\"ls_model_name\":\"gpt-4o\",\"ls_model_type\":\"chat\",\"ls_temperature\":1}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "const chain = model\n",
        "  .pipe(new JsonOutputParser().withConfig({ runName: \"my_parser\" }))\n",
        "  .withConfig({ tags: [\"my_chain\"] });\n",
        "\n",
        "\n",
        "const eventStream = await chain.streamEvents(\n",
        "  `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "  {\n",
        "    version: \"v2\",\n",
        "    encoding: \"text/event-stream\",\n",
        "  },\n",
        ");\n",
        "\n",
        "let eventCount = 0;\n",
        "\n",
        "const textDecoder = new TextDecoder();\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  // Truncate the output\n",
        "  if (eventCount > 3) {\n",
        "    continue;\n",
        "  }\n",
        "  console.log(textDecoder.decode(event));\n",
        "  eventCount += 1;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "è¿™ç§æ ¼å¼çš„ä¸€ä¸ª nice ç‰¹æ€§æ˜¯ï¼Œä½ å¯ä»¥å°†ç”Ÿæˆçš„æµç›´æ¥ä¼ é€’ç»™å¸¦æœ‰æ­£ç¡®å¤´éƒ¨çš„åŸç”Ÿ[HTTPå“åº”å¯¹è±¡](https://developer.mozilla.org/zh-CN/docs/Web/API/Response)ï¼ˆå¸¸è§äºåƒ[Hono](https://hono.dev/)å’Œ[Next.js](https://nextjs.org/)è¿™æ ·çš„æ¡†æ¶ä¸­ä½¿ç”¨ï¼‰ï¼Œç„¶ååœ¨å‰ç«¯è§£æè¯¥æµã€‚ä½ çš„æœåŠ¡ç«¯å¤„ç†ç¨‹åºçœ‹èµ·æ¥ä¼šåƒè¿™æ ·ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "const handler = async () => {\n",
        "  const eventStream = await chain.streamEvents(\n",
        "    `Output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`,\n",
        "    {\n",
        "      version: \"v2\",\n",
        "      encoding: \"text/event-stream\",\n",
        "    },\n",
        "  );\n",
        "  return new Response(eventStream, {\n",
        "    headers: {\n",
        "      \"content-type\": \"text/event-stream\",\n",
        "    }\n",
        "  });\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "è€Œä½ çš„å‰ç«¯å¯èƒ½çœ‹èµ·æ¥åƒè¿™æ ·ï¼ˆä½¿ç”¨ [`@microsoft/fetch-event-source`](https://www.npmjs.com/package/@microsoft/fetch-event-source) åŒ…æ¥è·å–å¹¶è§£æäº‹ä»¶æºï¼‰ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import { fetchEventSource } from \"@microsoft/fetch-event-source\";\n",
        "\n",
        "const makeChainRequest = async () => {\n",
        "  await fetchEventSource(\"https://your_url_here\", {\n",
        "    method: \"POST\",\n",
        "    body: JSON.stringify({\n",
        "      foo: 'bar'\n",
        "    }),\n",
        "    onmessage: (message) => {\n",
        "      if (message.event === \"data\") {\n",
        "        console.log(message.data);\n",
        "      }\n",
        "    },\n",
        "    onerror: (err) => {\n",
        "      console.log(err);\n",
        "    }\n",
        "  });\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### éæµå¼ç»„ä»¶\n",
        "\n",
        "è¿˜è®°å¾—ä¸€äº›ç»„ä»¶å› ä¸ºä¸æ“ä½œ**è¾“å…¥æµ**è€Œæ— æ³•å¾ˆå¥½åœ°è¿›è¡Œæµå¼ä¼ è¾“å—ï¼Ÿ\n",
        "\n",
        "è™½ç„¶è¿™äº›ç»„ä»¶åœ¨ä½¿ç”¨ `stream` æ—¶å¯èƒ½ä¼šä¸­æ–­æœ€ç»ˆè¾“å‡ºçš„æµå¼ä¼ è¾“ï¼Œä½† `streamEvents` ä»å°†ä»æ”¯æŒæµå¼ä¼ è¾“çš„ä¸­é—´æ­¥éª¤ä¸­äº§ç”Ÿæµå¼äº‹ä»¶ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"France\",\"Spain\",\"Japan\"]\n"
          ]
        }
      ],
      "source": [
        "// A function that operates on finalized inputs\n",
        "// rather than on an input_stream\n",
        "import { JsonOutputParser } from \"@langchain/core/output_parsers\"\n",
        "import { RunnablePassthrough } from \"@langchain/core/runnables\";\n",
        "\n",
        "// A function that does not operates on input streams and breaks streaming.\n",
        "const extractCountryNames = (inputs: Record<string, any>) => {\n",
        "  if (!Array.isArray(inputs.countries)) {\n",
        "    return \"\";\n",
        "  }\n",
        "  return JSON.stringify(inputs.countries.map((country) => country.name));\n",
        "}\n",
        "\n",
        "const chain = model.pipe(new JsonOutputParser()).pipe(extractCountryNames);\n",
        "\n",
        "const stream = await chain.stream(\n",
        "  `output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key \"name\" and \"population\"`\n",
        ");\n",
        "\n",
        "for await (const chunk of stream) {\n",
        "  console.log(chunk);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œ`stream` API æ— æ³•æ­£å¸¸å·¥ä½œï¼Œå› ä¸º `extractCountryNames` ä¸æ”¯æŒåœ¨æµä¸Šæ“ä½œã€‚\n",
        "\n",
        "ç°åœ¨ï¼Œæˆ‘ä»¬ç¡®è®¤ä¸€ä¸‹ä½¿ç”¨ `streamEvents` æ—¶ï¼Œæ˜¯å¦ä»ç„¶èƒ½çœ‹åˆ°æ¨¡å‹å’Œè§£æå™¨çš„æµå¼è¾“å‡ºã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const eventStream = await chain.streamEvents(\n",
        "  `output a list of the countries france, spain and japan and their populations in JSON format.\n",
        "Use a dict with an outer key of \"countries\" which contains a list of countries.\n",
        "Each country should have the key \"name\" and \"population\"\n",
        "Your output should ONLY contain valid JSON data. Do not include any other text or content in your output.`,\n",
        "  { version: \"v2\" },\n",
        ");\n",
        "\n",
        "let eventCount = 0;\n",
        "\n",
        "for await (const event of eventStream) {\n",
        "  // Truncate the output\n",
        "  if (eventCount > 30) {\n",
        "    continue;\n",
        "  }\n",
        "  const eventType = event.event;\n",
        "  if (eventType === \"on_chat_model_stream\") {\n",
        "    console.log(`Chat model chunk: ${event.data.chunk.message.content}`);\n",
        "  } else if (eventType === \"on_parser_stream\") {\n",
        "    console.log(`Parser chunk: ${JSON.stringify(event.data.chunk)}`);\n",
        "  } else {\n",
        "    console.log(eventType)\n",
        "  }\n",
        "  eventCount += 1;\n",
        "}"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Chat model chunk:\n",
        "Chat model chunk: Here's\n",
        "Chat model chunk:  how\n",
        "Chat model chunk:  you\n",
        "Chat model chunk:  can\n",
        "Chat model chunk:  represent\n",
        "Chat model chunk:  the\n",
        "Chat model chunk:  countries\n",
        "Chat model chunk:  France\n",
        "Chat model chunk: ,\n",
        "Chat model chunk:  Spain\n",
        "Chat model chunk: ,\n",
        "Chat model chunk:  and\n",
        "Chat model chunk:  Japan\n",
        "Chat model chunk: ,\n",
        "Chat model chunk:  along\n",
        "Chat model chunk:  with\n",
        "Chat model chunk:  their\n",
        "Chat model chunk:  populations\n",
        "Chat model chunk: ,\n",
        "Chat model chunk:  in\n",
        "Chat model chunk:  JSON\n",
        "Chat model chunk:  format\n",
        "Chat model chunk: :\n",
        "\n",
        "\n",
        "Chat model chunk: ```\n",
        "Chat model chunk: json\n",
        "Chat model chunk:\n",
        "\n",
        "Chat model chunk: {"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ç›¸å…³\n",
        "\n",
        "- [æ´¾å‘è‡ªå®šä¹‰äº‹ä»¶](/docs/how_to/callbacks_custom_events)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}