{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c298a5c9-b9af-481d-9eba-cbd65f987a8a",
      "metadata": {},
      "source": [
        "# 如何将 BaseChatMessageHistory 与 LangGraph 一起使用\n",
        "\n",
        ":::info 前提条件\n",
        "\n",
        "本指南假定您已熟悉以下概念：\n",
        "\n",
        "- [聊天历史](/docs/concepts/chat_history)\n",
        "- [RunnableWithMessageHistory](https://api.js.langchain.com/classes/_langchain_core.runnables.RunnableWithMessageHistory.html)\n",
        "- [LangGraph](https://langchain-ai.github.io/langgraphjs/concepts/high_level/)\n",
        "- [内存](https://langchain-ai.github.io/langgraphjs/concepts/agentic_concepts/#memory)\n",
        "\n",
        ":::\n",
        "\n",
        "我们建议新的 LangChain 应用程序利用 [LangGraph 内置的持久化功能](https://langchain-ai.github.io/langgraphjs/concepts/persistence/) 来实现内存管理。\n",
        "\n",
        "在某些情况下，用户可能需要继续使用现有的聊天消息历史持久化解决方案。\n",
        "\n",
        "在这里，我们将展示如何将 [LangChain 聊天消息历史](/docs/integrations/memory/)（[BaseChatMessageHistory](https://api.js.langchain.com/classes/_langchain_core.chat_history.BaseChatMessageHistory.html) 的实现）与 LangGraph 结合使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548bc988-167b-43f1-860a-d247e28b2b42",
      "metadata": {},
      "source": [
        "## 设置\n",
        "\n",
        "```typescript\n",
        "process.env.ANTHROPIC_API_KEY = 'YOUR_API_KEY'\n",
        "```\n",
        "\n",
        "```{=mdx}\n",
        "import Npm2Yarn from \"@theme/Npm2Yarn\"\n",
        "\n",
        "<Npm2Yarn>\n",
        "  @langchain/core @langchain/langgraph @langchain/anthropic\n",
        "</Npm2Yarn>\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c5e08659-b68c-48f2-8b33-e79b0c6999e1",
      "metadata": {},
      "source": [
        "## 聊天消息历史\n",
        "\n",
        "消息历史需要通过对话ID或者可能是（用户ID，对话ID）的二元组来进行参数化。\n",
        "\n",
        "许多[LangChain聊天消息历史](/docs/integrations/memory/)将具有一个`sessionId`或者某个`namespace`，以便跟踪不同的对话。请参考具体的实现以查看其参数化方式。\n",
        "\n",
        "内置的`InMemoryChatMessageHistory`不包含这种参数化功能，因此我们将创建一个字典来跟踪消息历史。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "28049308-2543-48e6-90d0-37a88951a637",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { InMemoryChatMessageHistory } from \"@langchain/core/chat_history\";\n",
        "\n",
        "const chatsBySessionId: Record<string, InMemoryChatMessageHistory> = {}\n",
        "\n",
        "const getChatHistory = (sessionId: string) => {\n",
        "    let chatHistory: InMemoryChatMessageHistory | undefined = chatsBySessionId[sessionId]\n",
        "    if (!chatHistory) {\n",
        "      chatHistory = new InMemoryChatMessageHistory()\n",
        "      chatsBySessionId[sessionId] = chatHistory\n",
        "    }\n",
        "    return chatHistory\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "94c53ce3-4212-41e6-8ad3-f0ab5df6130f",
      "metadata": {},
      "source": [
        "## 与 LangGraph 一起使用\n",
        "\n",
        "接下来，我们将使用 LangGraph 设置一个基本的聊天机器人。如果你不熟悉 LangGraph，可以查看以下 [快速入门教程](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/)。\n",
        "\n",
        "我们将为聊天模型创建一个 [LangGraph 节点](https://langchain-ai.github.io/langgraphjs/concepts/low_level/#nodes)，并手动管理对话历史，同时考虑作为 RunnableConfig 一部分传递的对话 ID。\n",
        "\n",
        "对话 ID 可以作为 RunnableConfig 的一部分传递（如本例所示），也可以作为 [图状态](https://langchain-ai.github.io/langgraphjs/concepts/low_level/#state) 的一部分传递。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d818e23f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hi! I'm bob\n",
            "Hello Bob! It's nice to meet you. How can I assist you today?\n",
            "what was my name?\n",
            "You said your name is Bob.\n"
          ]
        }
      ],
      "source": [
        "import { v4 as uuidv4 } from \"uuid\";\n",
        "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
        "import { StateGraph, MessagesAnnotation, END, START } from \"@langchain/langgraph\";\n",
        "import { HumanMessage } from \"@langchain/core/messages\";\n",
        "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
        "\n",
        "// Define a chat model\n",
        "const model = new ChatAnthropic({ modelName: \"claude-3-haiku-20240307\" });\n",
        "\n",
        "// Define the function that calls the model\n",
        "const callModel = async (\n",
        "  state: typeof MessagesAnnotation.State,\n",
        "  config: RunnableConfig\n",
        "): Promise<Partial<typeof MessagesAnnotation.State>> => {\n",
        "  if (!config.configurable?.sessionId) {\n",
        "    throw new Error(\n",
        "      \"Make sure that the config includes the following information: {'configurable': {'sessionId': 'some_value'}}\"\n",
        "    );\n",
        "  }\n",
        "\n",
        "  const chatHistory = getChatHistory(config.configurable.sessionId as string);\n",
        "\n",
        "  let messages = [...(await chatHistory.getMessages()), ...state.messages];\n",
        "\n",
        "  if (state.messages.length === 1) {\n",
        "    // First message, ensure it's in the chat history\n",
        "    await chatHistory.addMessage(state.messages[0]);\n",
        "  }\n",
        "\n",
        "  const aiMessage = await model.invoke(messages);\n",
        "\n",
        "  // Update the chat history\n",
        "  await chatHistory.addMessage(aiMessage);\n",
        "\n",
        "  return { messages: [aiMessage] };\n",
        "};\n",
        "\n",
        "// Define a new graph\n",
        "const workflow = new StateGraph(MessagesAnnotation)\n",
        "  .addNode(\"model\", callModel)\n",
        "  .addEdge(START, \"model\")\n",
        "  .addEdge(\"model\", END);\n",
        "\n",
        "const app = workflow.compile();\n",
        "\n",
        "// Create a unique session ID to identify the conversation\n",
        "const sessionId = uuidv4();\n",
        "const config = { configurable: { sessionId }, streamMode: \"values\" as const };\n",
        "\n",
        "const inputMessage = new HumanMessage(\"hi! I'm bob\");\n",
        "\n",
        "for await (const event of await app.stream({ messages: [inputMessage] }, config)) {\n",
        "  const lastMessage = event.messages[event.messages.length - 1];\n",
        "  console.log(lastMessage.content);\n",
        "}\n",
        "\n",
        "// Here, let's confirm that the AI remembers our name!\n",
        "const followUpMessage = new HumanMessage(\"what was my name?\");\n",
        "\n",
        "for await (const event of await app.stream({ messages: [followUpMessage] }, config)) {\n",
        "  const lastMessage = event.messages[event.messages.length - 1];\n",
        "  console.log(lastMessage.content);\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "da0536dd-9a0b-49e3-b0b6-e8c7abf3b1f9",
      "metadata": {},
      "source": [
        "## 与 RunnableWithMessageHistory 一起使用\n",
        "\n",
        "本指南直接使用了 `BaseChatMessageHistory` 的 `messages` 和 `addMessages` 接口。\n",
        "\n",
        "或者，你可以使用 [RunnableWithMessageHistory](https://api.js.langchain.com/classes/_langchain_core.runnables.RunnableWithMessageHistory.html)，因为 [LCEL](/docs/concepts/lcel/) 可以在任何 [LangGraph 节点](https://langchain-ai.github.io/langgraphjs/concepts/low_level/#nodes) 中使用。\n",
        "\n",
        "为此，请将以下代码替换为：\n",
        "\n",
        "```typescript\n",
        "const callModel = async (\n",
        "  state: typeof MessagesAnnotation.State,\n",
        "  config: RunnableConfig\n",
        "): Promise<Partial<typeof MessagesAnnotation.State>> => {\n",
        "  // highlight-start\n",
        "  if (!config.configurable?.sessionId) {\n",
        "    throw new Error(\n",
        "      \"确保配置包含以下信息: {'configurable': {'sessionId': 'some_value'}}\"\n",
        "    );\n",
        "  }\n",
        "\n",
        "  const chatHistory = getChatHistory(config.configurable.sessionId as string);\n",
        "\n",
        "  let messages = [...(await chatHistory.getMessages()), ...state.messages];\n",
        "\n",
        "  if (state.messages.length === 1) {\n",
        "    // 首条消息，确保其在聊天记录中\n",
        "    await chatHistory.addMessage(state.messages[0]);\n",
        "  }\n",
        "\n",
        "  const aiMessage = await model.invoke(messages);\n",
        "\n",
        "  // 更新聊天记录\n",
        "  await chatHistory.addMessage(aiMessage);\n",
        "  // highlight-end\n",
        "  return { messages: [aiMessage] };\n",
        "};\n",
        "```\n",
        "\n",
        "使用当前应用程序中定义的 `RunnableWithMessageHistory` 相应实例。\n",
        "\n",
        "```typescript\n",
        "const runnable = new RunnableWithMessageHistory({\n",
        "  // ... 来自现有代码的配置\n",
        "});\n",
        "\n",
        "const callModel = async (\n",
        "  state: typeof MessagesAnnotation.State,\n",
        "  config: RunnableConfig\n",
        "): Promise<Partial<typeof MessagesAnnotation.State>> => {\n",
        "  // RunnableWithMessageHistory 负责读取消息历史\n",
        "  // 并使用新的人类消息和 AI 响应更新它。\n",
        "  const aiMessage = await runnable.invoke(state.messages, config);\n",
        "  return {\n",
        "    messages: [aiMessage]\n",
        "  };\n",
        "};\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}